{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "domain_shift_robustnes-kmnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saptarshidatta96/MTech_Sem3/blob/main/domain_shift_robustnes_kmnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmN0mZpoTu7x",
        "outputId": "a0bf43d3-cb4b-44b4-f0de-be4ce57a30dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.12.0a`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.12.0a\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"User Current Version:-\", sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ_RznGYT3yv",
        "outputId": "7119cdeb-5575-4b57-b515-13122fcc5f65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Current Version:- 3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxGW3kZ6T6nP",
        "outputId": "4792ef1f-08eb-4d57-ddd7-c9438e183c96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipix1hPLT9L3",
        "outputId": "2d9e8728-2b10-46b0-be0d-511a9d97d026"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib import slim\n",
        "import _pickle as cPickle"
      ],
      "metadata": {
        "id": "qcnMHhIIT_x_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8c3Rg8ZbswC",
        "outputId": "596493cd-202e-44fe-b6db-91aed1236a7d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.15.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7917 sha256=9121b49ca4906cd73f0e84a2ec63276a56350461e721e5cbe032ad1764a15c94\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/ce/ad/d5e95a35cfe34149aade5e500f2edd535c0566d79e9a8e1d8a\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    tqdm = lambda x, total, unit: x  # If tqdm doesn't exist, replace it with a function that does nothing\n",
        "    print('**** Could not import tqdm. Please install tqdm for download progressbars! (pip install tqdm) ****')\n",
        "\n",
        "# Python2 compatibility\n",
        "try:\n",
        "    input = raw_input\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "download_dict = {\n",
        "    '1) Kuzushiji-MNIST (10 classes, 28x28, 70k examples)': {\n",
        "        '1) MNIST data format (ubyte.gz)':\n",
        "            ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz'],\n",
        "        '2) NumPy data format (.npz)':\n",
        "            ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz'],\n",
        "    },\n",
        "    '2) Kuzushiji-49 (49 classes, 28x28, 270k examples)': {\n",
        "        '1) NumPy data format (.npz)':\n",
        "            ['http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz'],\n",
        "    },\n",
        "    '3) Kuzushiji-Kanji (3832 classes, 64x64, 140k examples)': {\n",
        "        '1) Folders of images (.tar)':\n",
        "            ['http://codh.rois.ac.jp/kmnist/dataset/kkanji/kkanji.tar'],\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "# Download a list of files\n",
        "def download_list(url_list):\n",
        "    for url in url_list:\n",
        "        path = url.split('/')[-1]\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(path, 'wb') as f:\n",
        "            total_length = int(r.headers.get('content-length'))\n",
        "            print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
        "\n",
        "            for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "    print('All dataset files downloaded!')\n",
        "\n",
        "# Ask the user about which path to take down the dict\n",
        "def traverse_dict(d):\n",
        "    print('Please select a download option:')\n",
        "    keys = sorted(d.keys())  # Print download options\n",
        "    for key in keys:\n",
        "        print(key)\n",
        "\n",
        "    userinput = input('> ').strip()\n",
        "\n",
        "    try:\n",
        "        selection = int(userinput) - 1\n",
        "    except ValueError:\n",
        "        print('Your selection was not valid')\n",
        "        traverse_dict(d)  # Try again if input was not valid\n",
        "        return\n",
        "\n",
        "    selected = keys[selection]\n",
        "\n",
        "    next_level = d[selected]\n",
        "    if isinstance(next_level, list):  # If we've hit a list of downloads, download that list\n",
        "        download_list(next_level)\n",
        "    else:\n",
        "        traverse_dict(next_level)     # Otherwise, repeat with the next level\n",
        "\n",
        "traverse_dict(download_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udX6y933UQLH",
        "outputId": "e15d2d5a-7285-40d8-a1e3-b77e97b64277"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select a download option:\n",
            "1) Kuzushiji-MNIST (10 classes, 28x28, 70k examples)\n",
            "2) Kuzushiji-49 (49 classes, 28x28, 270k examples)\n",
            "3) Kuzushiji-Kanji (3832 classes, 64x64, 140k examples)\n",
            "> 1\n",
            "Please select a download option:\n",
            "1) MNIST data format (ubyte.gz)\n",
            "2) NumPy data format (.npz)\n",
            "> 2\n",
            "Downloading kmnist-train-imgs.npz - 18.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17954/17954 [00:02<00:00, 7422.81KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading kmnist-train-labels.npz - 0.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 417.92KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading kmnist-test-imgs.npz - 3.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3008/3008 [00:00<00:00, 3744.53KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading kmnist-test-labels.npz - 0.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 13911.46KB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataset files downloaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "def resize_images(image_arrays, size=[32,32]):\n",
        "    image_arrays = (image_arrays * 255).astype('uint8')\n",
        "    \n",
        "    resized_image_arrays = np.zeros([image_arrays.shape[0]]+size)\n",
        "    for i, image_array in enumerate(image_arrays):\n",
        "        image = Image.fromarray(image_array)\n",
        "        resized_image = image.resize(size=size, resample=Image.ANTIALIAS)\n",
        "        \n",
        "        resized_image_arrays[i] = np.asarray(resized_image)\n",
        "    \n",
        "    return np.expand_dims(resized_image_arrays, 3) \n",
        "\n",
        "\n",
        "def download_and_process_mnist():\n",
        "    \n",
        "    \n",
        "    if not os.path.exists('./data/kmnist'):\n",
        "      os.makedirs('./data/kmnist')\n",
        "    \n",
        "    with np.load('/content/kmnist-train-imgs.npz') as data:\n",
        "      lst = data.files\n",
        "      for item in lst:\n",
        "        train_data = resize_images(data[item].reshape(-1, 28, 28))\n",
        "\n",
        "    with np.load('/content/kmnist-train-labels.npz') as data:\n",
        "      lst = data.files\n",
        "      for item in lst:\n",
        "        train_label = data[item]\n",
        "\n",
        "    train = {'X': train_data,\n",
        "         'y': train_label}   \n",
        "\n",
        "    with np.load('/content/kmnist-test-imgs.npz') as data:\n",
        "      lst = data.files\n",
        "      for item in lst:\n",
        "        test_data = resize_images(data[item].reshape(-1, 28, 28))\n",
        "\n",
        "    with np.load('/content/kmnist-test-labels.npz') as data:\n",
        "      lst = data.files\n",
        "      for item in lst:\n",
        "        test_label = data[item]\n",
        "\n",
        "    test = {'X': test_data,\n",
        "         'y': test_label}   \n",
        "\n",
        "\n",
        "    with open('./data/kmnist/train.pkl','wb') as f:\n",
        "      cPickle.dump(train,f)  \n",
        "    \n",
        "    with open('./data/kmnist/test.pkl','wb') as f:\n",
        "      cPickle.dump(test,f)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    download_and_process_mnist()"
      ],
      "metadata": {
        "id": "xFNQeeO2aWh3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "from configparser import *\n",
        "import os\n",
        "\n",
        "import scipy.io\n",
        "import sys\n",
        "import glob\n",
        "from numpy.linalg import norm\n",
        "from scipy import misc\n",
        "import skimage.transform\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "\n",
        "\n",
        "class SearchOps(object):\n",
        "\t\n",
        "\t'''\n",
        "\tClass to handle all the search procedures.\n",
        "\tCurrently implemented: random search and evolution search\n",
        "\t'''\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.transf_ops = TransfOps()\n",
        "\n",
        "\tdef random_search(self, no_iters, string_length, save_file_name, compute_fitness_f, original_images, *args):\n",
        "\n",
        "\t\t'''\n",
        "\t\tSampling random image transformations and testing them on a provided model.\n",
        "\t\tReferring to the paper, this is Algorithm 1.\n",
        "\t\t\n",
        "\t\t\tno_iters: number of iterations.\n",
        "\t\t\tstring_length: number of transformations to be concatenated.\n",
        "\t\t\tsave_file_name: file name used to save .png and .pkl outputs.\n",
        "\t\t\tcompute_fitness_f: test function associated with the desired model.\n",
        "\t\t\toriginal_images: images to give in input to compute_fitness_f.\n",
        "\t\t\targs: other input eventually required by compute_fitness_f (e.g., ground truth labels, sess, etc.)\n",
        "\n",
        "\t\t'''\n",
        "\n",
        "\t\tall_accuracies = []\n",
        "\t\tall_best_accuracies = []\n",
        "\t\tall_transformations = []\n",
        "\t\tall_levels = []\n",
        "\t\tall_images = []\n",
        "\t\tcurrent_minimum = 1.\n",
        "\t\t\n",
        "\t\tnumber_fitness_evals = 0\t\t\n",
        "\t\t\n",
        "\t\tfor t in range(no_iters):\n",
        "\n",
        "\t\t\tif (t%100)==0:\n",
        "\t\t\t\tprint('Iter #',str(t))\n",
        "\n",
        "\t\t\ttr_images, transformations, levels = self.transf_ops.transform_dataset(original_images * 255., transf_string='random_'+str(string_length))\n",
        "\t\t\t\n",
        "\t\t\ttr_images /= 255.\n",
        "\t\t\t\n",
        "\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\ttarget_accuracy = 0\n",
        "\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\tnumber_fitness_evals += 1\n",
        "\n",
        "\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\n",
        "\t\t\tall_accuracies.append(target_accuracy)\n",
        "\n",
        "\t\t\tif target_accuracy < current_minimum:\n",
        "\t\t\t\tprint ('%d Current minimum: [%.4f], # fitness evals: [%d]'%(t, target_accuracy, number_fitness_evals))\n",
        "\t\t\t\tcurrent_minimum=target_accuracy\t\t\t\t\n",
        "\t\t\t\n",
        "\t\t\t\tall_best_accuracies.append(target_accuracy)\n",
        "\t\t\t\tall_transformations.append(transformations)\n",
        "\t\t\t\tall_levels.append(levels)\n",
        "\n",
        "\t\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\t\tall_images.append(conc_images)\n",
        "\n",
        "\n",
        "\t\tprint('Saving output in \"images\" folder')\n",
        "\t\tPIL.Image.fromarray(conc_images.astype('uint8')).save(save_file_name+'_acc_%.3f.png'%(current_minimum))\n",
        "\t\t\t\t\n",
        "\t\twith open(save_file_name+'_acc_%.3f.pkl'%(current_minimum), 'wb') as f:\n",
        "\t\t\tcPickle.dump((all_accuracies, all_best_accuracies, all_transformations, all_levels, number_fitness_evals), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\t\treturn all_best_accuracies[-1], all_transformations[-1].tolist(), all_levels[-1], all_images[-1]\n",
        "\t\t\t\n",
        "\tdef genetic_algorithm(self, no_iters, pop_size, string_length, mutation_rate, save_file_name, compute_fitness_f, original_images, *args):\n",
        "\n",
        "\t\t'''\n",
        "\t\tSampling random image transformations and testing them on a provided model.\n",
        "\t\tReferring to the paper, this is Algorithm 2.\n",
        "\t\t\n",
        "\t\t\tno_iters: number of iterations.\n",
        "\t\t\tstring_length: number of transformations to be concatenated.\n",
        "\t\t\tmutation_rate: a value in [0.0,1.0]\n",
        "\t\t\tsave_file_name: file name used to save .png and .pkl outputs.\n",
        "\t\t\tcompute_fitness_f: test function associated with the desired model.\n",
        "\t\t\toriginal_images: images to give in input to compute_fitness_f.\n",
        "\t\t\targs: other input eventually required by compute_fitness_f (e.g., ground truth labels, sess, etc.)\n",
        "\n",
        "\t\t'''\n",
        "\n",
        "\t\tmin_accuracy = 1.0 # initialized with the maximum value\n",
        "\t\tcurrent_minimum = 1.0 # initialized with the maximum value\n",
        "\n",
        "\t\tnumber_fitness_evals = 0\n",
        "\t\tnumber_fitness_needed = pop_size\n",
        "\n",
        "\t\tpop_accuracies = []\n",
        "\t\tpop_probabilities = []\n",
        "\t\tpop_transformations = []\n",
        "\t\tpop_levels = []\n",
        "\t\tpop_images = []\n",
        "\n",
        "\t\tmin_accs = []\n",
        "\t\tmin_transfs = []\n",
        "\t\tmin_levels = []\n",
        "\t\tmin_images = []\n",
        "\n",
        "\t\tall_fitnesses = []\n",
        "\n",
        "\t\tprint('Initializing population')\n",
        "\t\t\t\n",
        "\t\tfor p in range(pop_size): # number of items in the population\n",
        "\n",
        "\t\t\ttr_images, transformations, levels = self.transf_ops.transform_dataset(original_images * 255., transf_string='random_'+str(string_length))\n",
        "\t\t\ttr_images /= 255.\n",
        "\n",
        "\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\ttarget_accuracy = 0\n",
        "\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\tnumber_fitness_evals += 1\n",
        "\t\t\t\n",
        "\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\n",
        "\t\t\tpop_accuracies.append(target_accuracy)\n",
        "\t\t\tpop_transformations.append(transformations)\n",
        "\t\t\tpop_levels.append(levels)\n",
        "\t\t\t\n",
        "\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\t\t\t\n",
        "\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\tpop_images.append(conc_images)\n",
        "\t\t\t\n",
        "\t\tpop_probabilities = (1. - np.array(pop_accuracies))/np.sum(1. - np.array(pop_accuracies)) \n",
        "\n",
        "\t\tcurrent_minimum = np.min(pop_accuracies)\n",
        "\t\tprint('Current minimum:',str(current_minimum), '# fitness evals', str(number_fitness_evals))\n",
        "\n",
        "\t\tmin_accs.append(current_minimum)\n",
        "\n",
        "\t\tall_fitnesses.append(current_minimum)\n",
        "\t\t\n",
        "\t\tpop_transformations = [arr.tolist() for arr in pop_transformations]\t\t\t\n",
        "\n",
        "\t\tmin_transfs.append(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\tmin_levels.append(pop_levels[np.argmin(pop_accuracies)])\n",
        "\t\tmin_images.append(pop_images[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\tprint('Running evolution search')\n",
        "\n",
        "\t\tfor step in range(no_iters): # number of iters for the evolution search\n",
        "\n",
        "\t\t\tif current_minimum == 0.0:\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\t\tnew_pop_accuracies = []\n",
        "\t\t\tnew_pop_images = []\n",
        "\t\t\tnew_pop_transformations = [None for i in range(pop_size)]\n",
        "\t\t\tnew_pop_levels = [None for i in range(pop_size)]\n",
        "\n",
        "\t\t\tfor p in range(pop_size/2):\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t# randomly choose two parents to be mated <3\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tidx_1 = npr.choice(pop_size, p=pop_probabilities)\n",
        "\t\t\t\tidx_2 = npr.choice(pop_size, p=pop_probabilities)\n",
        "\n",
        "\t\t\t\ttransformations_1 = pop_transformations[idx_1]\n",
        "\t\t\t\ttransformations_2 = pop_transformations[idx_2]\n",
        "\t\t\t\tlevels_1 = pop_levels[idx_1]\n",
        "\t\t\t\tlevels_2 = pop_levels[idx_2]\n",
        "\t\t\t\t\n",
        "\t\t\t\t# cutting transformations/levels on a random point and \n",
        "\t\t\t\t\t\n",
        "\t\t\t\tcrossover_point = npr.randint(string_length)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tnew_transformations_1 = transformations_1[:crossover_point] + transformations_2[crossover_point:]\n",
        "\t\t\t\tnew_levels_1 = levels_1[:crossover_point] + levels_2[crossover_point:]\n",
        "\t\t\t\tnew_transformations_2 = transformations_2[:crossover_point] + transformations_1[crossover_point:]\n",
        "\t\t\t\tnew_levels_2 = levels_2[:crossover_point] + levels_1[crossover_point:]\n",
        "\t\t\t\t\n",
        "\t\t\t\t# adding the new offspring to the new population\t\t\t\t\n",
        "\n",
        "\t\t\t\tnew_pop_transformations[p] = new_transformations_1\n",
        "\t\t\t\tnew_pop_levels[p] = new_levels_1\n",
        "\t\t\t\tnew_pop_transformations[p+pop_size/2] = new_transformations_2\n",
        "\t\t\t\tnew_pop_levels[p+pop_size/2] = new_levels_2\n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t# mutating some genes\n",
        "\t\t\t\t\n",
        "\t\t\tfor i, transformations in enumerate(new_pop_transformations):\n",
        "\t\t\t\tfor j, transf in enumerate(transformations):\n",
        "\t\t\t\t\tif npr.rand() < mutation_rate: \n",
        "\t\t\t\t\t\tnew_pop_transformations[i][j] = npr.choice(self.transf_ops.transformation_list, 1)[0]\n",
        "\t\t\t\t\t\tnew_pop_levels[i][j] = npr.choice(self.transf_ops.code_to_level_dict[new_pop_transformations[i][j]].values(), 1)[0]\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t# computing accuracies (\"fitness\" values)\n",
        "\n",
        "\t\t\tfor transformations, levels in zip(new_pop_transformations, new_pop_levels): \n",
        "\n",
        "\t\t\t\ttr_images, _, _ = self.transf_ops.transform_dataset(original_images * 255., transformations=transformations, levels=levels)\n",
        "\t\t\t\ttr_images /= 255.\n",
        "\t\t\t\t\n",
        "\t\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\t\ttarget_accuracy = 0\n",
        "\t\t\t\ttarget_loss = 0\n",
        "\t\t\t\n",
        "\t\t\t\tnumber_fitness_evals += 1\n",
        "\t\t\t\n",
        "\t\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\t\t\t\t\n",
        "\t\t\t\tnew_pop_accuracies.append(target_accuracy)\n",
        "\n",
        "\n",
        "\t\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\n",
        "\t\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\t\tnew_pop_images.append(conc_images)\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\tpop_transformations = new_pop_transformations\n",
        "\t\t\tpop_levels = new_pop_levels\n",
        "\t\t\tpop_accuracies = new_pop_accuracies\n",
        "\n",
        "\t\t\tpop_images = new_pop_images\n",
        "\t\t\tpop_probabilities = (1. - np.array(pop_accuracies))/np.sum(1. - np.array(pop_accuracies)) \n",
        "\n",
        "\t\t\tif np.min(pop_accuracies) < current_minimum:\n",
        "\t\t\t\tcurrent_minimum = np.min(pop_accuracies)\n",
        "\t\t\t\tprint(str(step), '- Current minimum:', str(current_minimum), '#number fitness evals', str(number_fitness_evals))\n",
        "\t\t\t\tprint(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tprint(pop_levels[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\t\t\tnumber_fitness_needed = number_fitness_evals\n",
        "\n",
        "\t\t\t\tmin_accs.append(current_minimum)\n",
        "\t\t\t\tmin_transfs.append(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tmin_levels.append(pop_levels[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tmin_images.append(pop_images[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\tall_fitnesses.append(current_minimum)\n",
        "\n",
        "\t\tPIL.Image.fromarray(pop_images[np.argmin(pop_accuracies)].astype('uint8')).save(save_file_name+'_acc_%.3f.png'%(current_minimum))\n",
        "\t\t\n",
        "\t\twith open(save_file_name+'_acc_%.3f.pkl'%(current_minimum), 'wb') as f:\n",
        "\t\t\tcPickle.dump((min_accs,min_transfs, min_levels, number_fitness_needed, all_fitnesses), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\t\treturn min_accs[np.argmin(min_accs)], min_transfs[np.argmin(min_accs)], min_levels[np.argmin(min_accs)], min_images[np.argmin(min_accs)]\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    print('...')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ2bSEBLVH1v",
        "outputId": "8cba7ef9-9164-47e9-d315-d616994e18e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import PIL\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageEnhance\n",
        "import PIL.Image\n",
        "import matplotlib\n",
        "\n",
        "class TransfOps(object):\n",
        "\n",
        "\t'''\n",
        "\tClass to handle the decoding of the strings used with the genetic\n",
        "\talgorithm and all the data transformations.\n",
        "\t'''\n",
        "\t\n",
        "\tdef __init__(self):\n",
        "\t\t\t\t\n",
        "\t\tself.transformation_list = ['autocontrast', 'brightness', 'color', 'contrast', 'sharpness', 'solarize', 'grayscale', 'Renhancer', 'Genhancer', 'Benhancer']\n",
        "\t\tself.define_code_correspondances()\n",
        "\t\t\n",
        "\tdef decode_string(self, transf_string):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tCode to decode the string used by the genetic algorithm\n",
        "\t\tString example: 't1,l1_3,t4,l4_0,t0,l0_1'. First transformation is the one \n",
        "\t\tassociated with index '1', with level set to '3', and so on.\n",
        "\t\t'random_N' with N integer gives N rnd transformations with rnd levels.\n",
        "\t\t'''\n",
        "\t\t\n",
        "\t\tif 'random' in transf_string:\n",
        "\t\t\ttransformations = npr.choice(self.transformation_list, int(transf_string.split('_')[-1])) # the string is 'random_N'\n",
        "\t\t\tlevels = [npr.choice(list(self.code_to_level_dict[t].values()), 1)[0] for t in transformations] # list() to make it compatible with Python3\n",
        "\t\telse:\n",
        "\t\t\ttransformation_codes = transf_string.split(',')[0::2] \n",
        "\t\t\tlevel_codes = transf_string.split(',')[1::2]\n",
        "\t\t\t\n",
        "\t\t\ttransformations = [self.code_to_transf(code) for code in transformation_codes] \t\n",
        "\t\t\tlevels = [self.code_to_level(transf,level) for transf,level in zip(transformations, level_codes)] \t\n",
        "\n",
        "\t\treturn transformations, levels\t\t\n",
        "\n",
        "\tdef transform_dataset(self, dataset, transf_string = 't0,l0_0', transformations=None, levels=None):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tdataset: set of images, shape should be N x width x height x #channels\n",
        "\t\ttransf_string: transformations and levels encoded in a string \n",
        "\t\t'''\n",
        "\n",
        "\t\t#print 'Dataset size:',dataset.shape\n",
        "\t\t\n",
        "\t\tif len(dataset.shape) == 3: # if 'dataset' is a single image\n",
        "\t\t\tdataset = np.expand_dims(dataset, 0) \n",
        "\t\t\n",
        "\t\tif dataset.shape[-1] != 3:\n",
        "\t\t\tprint('Input shape:', str(dataset.shape))\n",
        "\t\t\traise Exception('The images must be in RGB format')\n",
        "\n",
        "\t\ttr_dataset = np.zeros((dataset.shape))\n",
        "\t\t\n",
        "\t\tif transformations is None:\n",
        "\t\t\t# decoding transformation string\n",
        "\t\t\ttransformations, levels = self.decode_string(transf_string)\t\n",
        "\t\t\n",
        "\t\tfor n,img in enumerate(dataset):\n",
        "\t\t\tpil_img = PIL.Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "\t\t\tfor transf,level in zip(transformations, levels): \n",
        "\t\t\t\tpil_img = self.apply_transformation(pil_img, transf, level)\n",
        "\t\t\ttr_dataset[n] = np.array(pil_img)\n",
        "\n",
        "\t\treturn tr_dataset, transformations, levels\n",
        "\n",
        "\tdef apply_transformation(self, image, transformation, level):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\timage: image to be tranformed, shape should be 1 x width x height x #channels\n",
        "\t\ttransformation: type of transformation to be applied\n",
        "\t\tlevel: level of the perturbation to be applied \n",
        "\t\t'''\n",
        "\n",
        "\t\tif transformation == 'identity':\n",
        "\t\t\treturn image \n",
        "\n",
        "\t\telif transformation == 'autocontrast':\n",
        "\t\t\treturn PIL.ImageOps.autocontrast(image, cutoff=level)\n",
        "\n",
        "\t\telif transformation == 'brightness':\n",
        "\t\t\treturn PIL.ImageEnhance.Brightness(image).enhance(level)\n",
        "\n",
        "\t\telif transformation == 'color':\n",
        "\t\t\treturn PIL.ImageEnhance.Color(image).enhance(level)\n",
        "\t\t\t\n",
        "\t\telif transformation == 'contrast':\n",
        "\t\t\treturn PIL.ImageEnhance.Contrast(image).enhance(level)\n",
        "\n",
        "\t\telif transformation == 'sharpness':\n",
        "\t\t\treturn PIL.ImageEnhance.Sharpness(image).enhance(level)\n",
        "\t\t\t\n",
        "\t\telif transformation == 'solarize':\n",
        "\t\t\treturn PIL.ImageOps.solarize(image, threshold=level)\n",
        "\n",
        "\t\telif transformation == 'grayscale':\n",
        "\t\t\timage = PIL.ImageOps.grayscale(image).convert('RGB')\n",
        "\t\t\treturn image\t\t\n",
        "\n",
        "\t\telif transformation == 'Renhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,0] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\t\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\t\telif transformation == 'Genhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,1] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\t\telif transformation == 'Benhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,2] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\tdef code_to_transf(self, code):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tTakes in input a code (e.g., 't0', 't1', ...) and gives in output \n",
        "\t\tthe related transformation.\n",
        "\t\t'''\n",
        "\n",
        "\t\treturn self.code_to_transf_dict[code]\n",
        "\n",
        "\n",
        "\tdef code_to_level(self, transformation, code):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tTakes in input a transfotmation (e.g., 'invert', 'colorize', ...) and \n",
        "\t\ta level code (e.g., 'l0_1', 'l1_3', ...) and gives in output the related level.\n",
        "\t\t'''\n",
        "\t\t\n",
        "\t\treturn self.code_to_level_dict[transformation][code]\n",
        "\t\t\t\t\n",
        "\tdef define_code_correspondances(self):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tDefine the correpondances between transformation/level codes\n",
        "\t\tand the actual types and values.\n",
        "\t\t'''\n",
        "\t\t\t\n",
        "\t\tself.code_to_transf_dict = dict()\n",
        "\t\t\n",
        "\t\tself.code_to_transf_dict['t1'] = 'autocontrast'\n",
        "\t\tself.code_to_transf_dict['t2'] = 'brightness'\n",
        "\t\tself.code_to_transf_dict['t3'] = 'color'\n",
        "\t\tself.code_to_transf_dict['t4'] = 'contrast'\n",
        "\t\tself.code_to_transf_dict['t5'] = 'sharpness'\n",
        "\t\tself.code_to_transf_dict['t6'] = 'solarize'\n",
        "\t\tself.code_to_transf_dict['t7'] = 'grayscale'\n",
        "\t\tself.code_to_transf_dict['t8'] = 'Renhancer'\n",
        "\t\tself.code_to_transf_dict['t9'] = 'Genhancer'\n",
        "\t\tself.code_to_transf_dict['t10'] = 'Benhancer'\n",
        "\n",
        "\t\tself.code_to_level_dict = dict()\n",
        "\t\t\n",
        "\t\tfor k in self.transformation_list:\n",
        "\t\t\tself.code_to_level_dict[k] = dict()\n",
        "\t\t\t\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['autocontrast'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.0,0.3,20)):\n",
        "\t\t\tself.code_to_level_dict['autocontrast']['l1_'+str(n)] = l\n",
        "\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['brightness'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['brightness']['l2_'+str(n)] = l\n",
        "\t\t\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['color'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['color']['l3_'+str(n)] = l\n",
        "\t\t\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['contrast'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['contrast']['l4_'+str(n)] = l\n",
        "\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['sharpness'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['sharpness']['l5_'+str(n)] = l\n",
        "\t\t\n",
        "\t\tself.code_to_level_dict['solarize'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0,20,20).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['solarize']['l6_'+str(n)] = l\n",
        "\n",
        "\t\tself.code_to_level_dict['grayscale']['l7_0'] = None\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Renhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Renhancer']['l8_'+str(n)] = l\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Genhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Genhancer']['l9_'+str(n)] = l\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Benhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Benhancer']['l10_'+str(n)] = l\n",
        "\n",
        "if __name__=='__main__':\n",
        "\tpass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qHuPgIoKVOCX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import configparser\n",
        "import os\n",
        "#import cPickle\n",
        "import scipy.io\n",
        "import sys\n",
        "import glob\n",
        "from numpy.linalg import norm\n",
        "from scipy import misc\n",
        "import skimage.transform\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "sys.path.insert(0,'../')\n",
        "\n",
        "\n",
        "class TrainOps(object):\n",
        "\n",
        "\tdef __init__(self, model, exp_dir):\n",
        "\n",
        "\t\tself.model = model\n",
        "\t\tself.exp_dir = exp_dir\n",
        "\n",
        "\t\tself.config = tf.ConfigProto()\n",
        "\t\tself.config.gpu_options.allow_growth=False\n",
        "\n",
        "\t\tself.data_dir = './data'\n",
        "\n",
        "\tdef load_exp_config(self):\n",
        "\n",
        "\t\tprint(self.exp_dir)\n",
        "\n",
        "\t\tconfig = configparser.ConfigParser()\n",
        "\n",
        "\t\tprint('LOADING CONFIG FILE')\n",
        "\t\tconfig.read(os.path.join(self.exp_dir,'exp_config'))\n",
        "\t\tself.source_dataset = config.get('EXPERIMENT_SETTINGS', 'source_dataset')\n",
        "\n",
        "\t\tself.model.source_dataset = self.source_dataset\n",
        "\t\t\t\n",
        "\t\tself.model.no_classes = 10\n",
        "\t\tself.model.img_size = 32\n",
        "\n",
        "\t\tself.log_dir = os.path.join(self.exp_dir,'logs')\n",
        "\t\tself.model_save_path = os.path.join(self.exp_dir,'model')\n",
        "\t\tself.images_dir = os.path.join(self.exp_dir,'images')\n",
        "\n",
        "\t\tif not os.path.exists(self.log_dir):\n",
        "\t\t\tos.makedirs(self.log_dir)\n",
        "\n",
        "\t\tif not os.path.exists(self.model_save_path):\n",
        "\t\t\tos.makedirs(self.model_save_path)\n",
        "\n",
        "\t\tif not os.path.exists(os.path.join(self.images_dir)):\n",
        "\t\t\tos.makedirs(os.path.join(self.images_dir))\n",
        "\n",
        "\n",
        "\t\tself.train_iters = config.getint('MAIN_SETTINGS', 'train_iters')\n",
        "\t\tself.batch_size = config.getint('MAIN_SETTINGS', 'batch_size')\n",
        "\t\tself.model.batch_size = self.batch_size\n",
        "\t\tself.model.learning_rate = config.getfloat('MAIN_SETTINGS', 'learning_rate')\n",
        "\n",
        "\t\tself.transf_string = config.get('MAIN_SETTINGS', 'transf_string')\n",
        "\t\tself.sub_train_iters = config.getint('MAIN_SETTINGS', 'sub_train_iters')\n",
        "\t\tself.string_length = config.getint('MAIN_SETTINGS', 'string_length')\n",
        "\n",
        "\t\tself.transf_ops = TransfOps()\n",
        "\t\tself.search_ops = SearchOps()\n",
        "\n",
        "\tdef load_svhn(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading SVHN dataset.')\n",
        "\n",
        "\t\timage_file = 'train_32x32.mat' if split=='train' else 'test_32x32.mat'\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir, 'svhn', image_file)\n",
        "\t\tsvhn = scipy.io.loadmat(image_dir)\n",
        "\t\timages = np.transpose(svhn['X'], [3, 0, 1, 2])\n",
        "\t\tlabels = svhn['y'].reshape(-1)\n",
        "\t\tlabels[np.where(labels==10)] = 0\n",
        "\t\timages = images/255.\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_mnist(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading KMNIST dataset.')\n",
        "\t\timage_file = 'train.pkl' if split=='train' else 'test.pkl'\n",
        "\t\timage_dir = os.path.join(self.data_dir, 'kmnist', image_file)\n",
        "\t\twith open(image_dir, 'rb') as f:\n",
        "\t\t\tkmnist = cPickle.load(f)\n",
        "\t\t\n",
        "\t\timages = kmnist['X'] \n",
        "\t\tlabels = kmnist['y']\n",
        "\n",
        "\t\timages = images\n",
        "\t\timages = images/255. # better generalization performance if [0,1]\n",
        "\n",
        "\t\timages = np.stack((images,images,images), axis=3) # grayscale to rgb\n",
        "\n",
        "\t\treturn np.squeeze(images), labels\n",
        "\n",
        "\tdef load_mnist_m(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading KMNIST_M dataset.')\n",
        "\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir,'mnist_m')\n",
        "\n",
        "\t\tif split == 'train':\n",
        "\t\t\tdata_dir = os.path.join(image_dir,'mnist_m_train')\n",
        "\t\t\twith open(os.path.join(image_dir,'mnist_m_train_labels.txt')) as f:\n",
        "\t\t\t\tcontent = f.readlines()\n",
        "\t\t\t\t\n",
        "\t\telif split == 'test':\n",
        "\t\t\tdata_dir = os.path.join(image_dir,'mnist_m_test')\n",
        "\t\t\twith open(os.path.join(image_dir,'mnist_m_test_labels.txt')) as f:\n",
        "\t\t\t\tcontent = f.readlines()\n",
        "\n",
        "\n",
        "\t\tcontent = [c.split('\\n')[0] for c in content]\n",
        "\t\timages_files = [c.split(' ')[0] for c in content]\n",
        "\t\tlabels = np.array([int(c.split(' ')[1]) for c in content]).reshape(-1)\n",
        "\n",
        "\t\timages = np.zeros((len(labels), 32, 32, 3))\n",
        "\n",
        "\t\tfor no_img,img in enumerate(images_files):\n",
        "\t\t\timg_dir = os.path.join(data_dir, img)\n",
        "\t\t\tim = misc.imread(img_dir)\n",
        "\t\t\tim = np.expand_dims(im, axis=0)\n",
        "\t\t\timages[no_img] = im\n",
        "\n",
        "\t\timages = images \n",
        "\t\timages = images/255.\n",
        "\t\t\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_syn(self, split='train'):\n",
        "\t\tprint ('Loading SYN dataset.')\n",
        "\n",
        "\t\timage_file = 'synth_train_32x32.mat' if split=='train' else 'synth_test_32x32.mat'\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir,'syn', image_file)\n",
        "\t\tsyn = scipy.io.loadmat(image_dir)\n",
        "\t\timages = np.transpose(syn['X'], [3, 0, 1, 2])\n",
        "\t\tlabels = syn['y'].reshape(-1)\n",
        "\t\tlabels[np.where(labels==10)] = 0\n",
        "\t\t\n",
        "\t\timages = images/255.\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_usps(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading USPS dataset.')\n",
        "\t\timage_file = 'usps_32x32.pkl'\n",
        "\t\timage_dir = os.path.join(self.data_dir,'usps', image_file)\n",
        "\t\t\n",
        "\t\twith open(image_dir, 'rb') as f:\n",
        "\t\t\tusps = cPickle.load(f)\n",
        "\t\t\n",
        "\t\timages = usps['X']\n",
        "\t\tlabels = usps['y']\n",
        "\t\tlabels -= 1\n",
        "\t\tlabels[labels==255] = 9\n",
        "\n",
        "\t\timages=np.squeeze(images)\n",
        "\t\timages = np.stack((images,images,images), axis=3) # grayscale to rgb\n",
        "\t\timages = images/255.\n",
        "\n",
        "\t\tif split == 'train':\n",
        "\t\t\treturn images[:6562], np.squeeze(labels[:6562]).astype(int)\n",
        "\t\telif split == 'validation':\n",
        "\t\t\treturn images[6562:7291], np.squeeze(labels[6562:7291]).astype(int)\n",
        "\t\telif split == 'test':\t    \n",
        "\t\t\treturn images[7291:], np.squeeze(labels[7291:]).astype(int)\n",
        "\t\n",
        "\tdef load_test_data(self, target):\n",
        "\n",
        "\t\tif target=='mnist_m':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_mnist_m(split='test')\n",
        "\t\telif target=='svhn':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_svhn(split='test')\n",
        "\t\telif target=='syn':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_syn(split='test')\n",
        "\t\telif target=='usps':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_usps(split='test')\n",
        "\t\telif target=='mnist':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\treturn self.target_test_images,self.target_test_labels\n",
        "\n",
        "\tdef train(self, random_transf=False): \n",
        "\n",
        "\t\t'''\n",
        "\t\tThis method allows to train ERM and RDA models.\n",
        "\t\t\n",
        "\t\t\trandom_transf: if set to True, RDA is used, o.w. ERM.\n",
        "\t\t\n",
        "\t\tThe number of transformations to be concatenated needs be to\n",
        "\t\tset in the file exp_config.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tprint('Loading data')\n",
        "\n",
        "\t\tsource_train_images, source_train_labels = self.load_mnist(split='train')\n",
        "\t\ttarget_test_images, target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\twith tf.Session(config=self.config) as sess:\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n",
        "\n",
        "\t\t\tprint('Training')\n",
        "\t\t\t\n",
        "\t\t\tfor t in range(self.train_iters):\n",
        "\n",
        "\t\t\t\ti = t % int(source_train_images.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\t\t#current batch of images and labels\n",
        "\t\t\t\tbatch_images = source_train_images[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\t\t\t\tbatch_labels = source_train_labels[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\n",
        "\t\t\t\tif random_transf:\n",
        "\t\t\t\t\tbatch_images, _, _ = self.transf_ops.transform_dataset(batch_images * 255., transf_string = self.transf_string)\n",
        "\t\t\t\t\tbatch_images /= 255.\n",
        "\t\t\t\t\n",
        "\t\t\t\tfeed_dict = {self.model.images: batch_images, self.model.labels: batch_labels} \n",
        "\n",
        "\t\t\t\t#running a step of gradient descent\n",
        "\t\t\t\tsess.run([self.model.min_train_op, self.model.min_loss], feed_dict) \n",
        "\n",
        "\t\t\t\t#evaluating the model\n",
        "\t\t\t\tif t % 2500 == 0:\n",
        "\n",
        "\t\t\t\t\tsummary, min_l, acc = sess.run([self.model.summary_op, self.model.min_loss, self.model.accuracy], feed_dict)\n",
        "\n",
        "\t\t\t\t\ttrain_rand_idxs = np.random.permutation(source_train_images.shape[0])[:100]\n",
        "\t\t\t\t\ttest_rand_idxs = np.random.permutation(target_test_images.shape[0])[:100]\n",
        "\n",
        "\t\t\t\t\ttrain_acc, train_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: source_train_images[train_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: source_train_labels[train_rand_idxs]})\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\ttest_acc, test_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: target_test_images[test_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: target_test_labels[test_rand_idxs]})\n",
        "\t\t\t\t\t  \n",
        "\t\t\t\t\tsummary_writer.add_summary(summary, t)\n",
        "\t\t\t\t\tprint ('Step: [%d/%d] train_min_loss: [%.4f] train_acc: [%.4f] test_min_loss: [%.4f] test_acc: [%.4f]'%(t+1, self.train_iters, train_min_loss, train_acc, test_min_loss, test_acc))\n",
        "\t\t\t\n",
        "\t\t\t\tif t % 10000 == 0:\n",
        "\t\t\t\t\tprint('Saving')\n",
        "\t\t\t\t\tsaver.save(sess, os.path.join(self.model_save_path, 'encoder'))\n",
        "\n",
        "\tdef train_search(self, search_algorithm='random_search'): \n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tThis method allows to train models using RSDA and ESDA algorithms.\n",
        "\t\tReferring to the paper, this is Algorithm 3.\n",
        "\n",
        "\t\t\tsearch_algorithm: 'random_search' or 'evolution_search', \n",
        "\t\t\t\t\t\t\t  accordingly to the desired search procedure.\n",
        "\n",
        "\t\tThe number of transformations to be concatenated needs be to\n",
        "\t\tset in the file exp_config.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tprint('Loading data')\n",
        "\n",
        "\t\tsource_train_images, source_train_labels = self.load_mnist(split='train')\n",
        "\t\ttarget_test_images, target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\t# initializing the set of data augmentation rules.\n",
        "\n",
        "\t\ttransformations = [['identity']]\n",
        "\t\tlevels = [[None]]\t\t\n",
        "\n",
        "\t\twith tf.Session(config=self.config) as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n",
        "\n",
        "\t\t\tprint('Training')\n",
        "\t\t\t\n",
        "\t\t\tfor t in range(self.train_iters):\n",
        "\n",
        "\t\t\t\ti = t % int(source_train_images.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\t\t# current batch of images and labels\n",
        "\t\t\t\tbatch_images = source_train_images[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\t\t\t\tbatch_labels = source_train_labels[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\n",
        "\t\t\t\t# sampling uniformly a transformation and its level, and applying it to the batch\n",
        "\t\t\t\trnd_transf_idx = npr.randint(len(transformations))\n",
        "\t\t\t\t\n",
        "\t\t\t\tif transformations[rnd_transf_idx] == ['identity']: # do nothing for 'identity', namely use original images\n",
        "\t\t\t\t\tpass\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t# TransfOps requires [0,255] pixel ranges, while here images [0,1]\n",
        "\t\t\t\t\tbatch_images, _, _ = self.transf_ops.transform_dataset(batch_images * 255., transformations=transformations[rnd_transf_idx], levels=levels[rnd_transf_idx])\n",
        "\t\t\t\t\tbatch_images /= 255.\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t# running a step of gradient descent\n",
        "\t\t\t\tfeed_dict = {self.model.images: batch_images, self.model.labels: batch_labels} \n",
        "\t\t\t\tsess.run([self.model.min_train_op, self.model.min_loss], feed_dict) \n",
        "\n",
        "\t\t\t\t#evaluating the model\n",
        "\t\t\t\tif t % 2500 == 0:\n",
        "\n",
        "\t\t\t\t\tsummary, min_l, acc = sess.run([self.model.summary_op, self.model.min_loss, self.model.accuracy], feed_dict)\n",
        "\n",
        "\t\t\t\t\ttrain_rand_idxs = np.random.permutation(source_train_images.shape[0])[:100]\n",
        "\t\t\t\t\ttest_rand_idxs = np.random.permutation(target_test_images.shape[0])[:100]\n",
        "\n",
        "\t\t\t\t\ttrain_acc, train_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: source_train_images[train_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: source_train_labels[train_rand_idxs]})\n",
        "\t\t\t\t\ttest_acc, test_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: target_test_images[test_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: target_test_labels[test_rand_idxs]})\n",
        "\t\t\t\t\t  \n",
        "\t\t\t\t\tsummary_writer.add_summary(summary, t)\n",
        "\t\t\t\t\tprint('Step: [%d/%d] train_min_loss: [%.4f] train_acc: [%.4f] test_min_loss: [%.4f] test_acc: [%.4f]'%(t+1, self.train_iters, train_min_loss, train_acc, test_min_loss, test_acc))\n",
        "\n",
        "\t\t\t\tif (t+1)%self.sub_train_iters == 0:\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif search_algorithm == 'random_search':\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tprint('\\n\\nRunning Random Search')\n",
        "\t\t\t\t\t\tsave_file_name=os.path.join(self.images_dir,'Random_string_length_'+str(self.string_length)+'_iter_'+str(t+1))\n",
        "\t\t\t\t\t\tmin_tr_accuracy, _transformations, _levels, _image = self.search_ops.random_search(100, self.string_length, save_file_name,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.test, source_train_images[:1000],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_train_labels[:1000], sess) \n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\telif search_algorithm == 'evolution_search':\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tprint('\\n\\nRunning Evolution Search')\n",
        "\t\t\t\t\t\tsave_file_name=os.path.join(self.images_dir,'Evolution_string_length_'+str(self.string_length)+'_iter_'+str(t+1))\n",
        "\t\t\t\t\t\tmin_tr_accuracy, _transformations, _levels, _image = self.search_ops.genetic_algorithm(10, 10, self.string_length, 0.1,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsave_file_name, self.test, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_train_images[:1000],\tsource_train_labels[:1000], sess) \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\ttransformations.append(_transformations)\n",
        "\t\t\t\t\tlevels.append(_levels)\n",
        "\n",
        "\t\t\t\t\tprint('Target accuracy: [%.4f]'%(min_tr_accuracy))\n",
        "\t\t\t\t\tprint('_'.join(_transformations))\n",
        "\t\t\t\t\tprint('\\n\\n')\t\t\n",
        "\n",
        "\t\t\t\tif (t+1) % 25000 == 0:\n",
        "\t\t\t\t\tprint('Saving')\n",
        "\t\t\t\t\tsaver.save(sess, os.path.join(self.model_save_path, 'encoder'))\n",
        "\n",
        "\n",
        "\tdef test(self, images, labels, sess):\n",
        "\n",
        "\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\ttarget_accuracy = 0\n",
        "\t\ttarget_loss = 0\n",
        "\t\tpreds = []\n",
        "\n",
        "\t\tfor test_images_batch, test_labels_batch in zip(np.array_split(images, N), np.array_split(labels, N)):\n",
        "\t\t\tfeed_dict = {self.model.images: test_images_batch, self.model.labels: test_labels_batch} \n",
        "\t\t\ttarget_accuracy_tmp, target_loss_tmp, pred = sess.run([self.model.accuracy, self.model.min_loss, self.model.pred], feed_dict) \n",
        "\t\t\ttarget_accuracy += target_accuracy_tmp/float(N)\n",
        "\t\t\ttarget_loss += target_loss_tmp/float(N)\n",
        "\t\t\tpreds.append(pred.tolist())\n",
        "\n",
        "\t\tcorrect_guesses = (np.array(preds)==labels).astype(int)[0]\n",
        "\t\t\n",
        "\t\treturn target_accuracy, correct_guesses\n",
        "\t\n",
        "\tdef test_all(self):\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tres_dict = dict()\n",
        "\t\tres_dict['exp_dir'] = self.exp_dir\n",
        "\n",
        "\t\tprint('Testing ALL')\n",
        "\n",
        "\t\ttargets = ['mnist', 'svhn']# add 'usps', 'syn', 'mnist_m'\n",
        "\n",
        "\t\tfor target in targets:\n",
        "\n",
        "\t\t\tprint('\\n\\n\\n...........................................................................')\n",
        "\n",
        "\t\t\ttest_images, test_labels = self.load_test_data(target=target)\n",
        "\n",
        "\t\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\t\tprint('...........................................................................')\n",
        "\n",
        "\t\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\t\tprint('Loading pre-trained model.')\n",
        "\t\t\t\tvariables_to_restore = slim.get_model_variables()\n",
        "\t\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\t\t\t\t\n",
        "\t\t\t\tN = 100\n",
        "\t\t\t\ttarget_accuracy = 0\n",
        "\t\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\t\tprint('Calculating accuracy')\n",
        "\n",
        "\t\t\t\tfor test_images_batch, test_labels_batch in zip(np.array_split(test_images, N), np.array_split(test_labels, N)):\n",
        "\t\t\t\t\tfeed_dict = {self.model.images: test_images_batch, self.model.labels: test_labels_batch} \n",
        "\t\t\t\t\ttarget_accuracy_tmp, target_loss_tmp, target_pred = sess.run([self.model.accuracy, self.model.min_loss, self.model.pred], feed_dict) \n",
        "\t\t\t\t\ttarget_accuracy += target_accuracy_tmp/float(N)\n",
        "\t\t\t\t\ttarget_loss += target_loss_tmp/float(N)\n",
        "\n",
        "\t\t\tprint('Target accuracy: [%.4f] target loss: [%.4f]'%(target_accuracy, target_loss))\n",
        "\n",
        "\t\t\tres_dict[target] = target_accuracy\n",
        "\n",
        "\t\twith open(os.path.join(self.exp_dir, 'domain_generalization_performance.pkl'), 'w') as f:\n",
        "\t\t\tcPickle.dump(res_dict, f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "\tdef test_random_search(self, run, seed, no_iters, string_length):\n",
        "\n",
        "\t\ttest_images, test_labels = self.load_test_data(target='mnist')\n",
        "\t\t\n",
        "\t\tnpr.seed(213)\n",
        "\t\trnd_idx = list(range(len(test_images)))\n",
        "\t\tnpr.shuffle(rnd_idx)\t\t\n",
        "\n",
        "\t\ttest_images = test_images[rnd_idx]\n",
        "\t\ttest_labels = test_labels[rnd_idx]\n",
        "\n",
        "\t\ttest_images = test_images[:1000]\n",
        "\t\ttest_labels = test_labels[:1000]\n",
        "\n",
        "\t\tnpr.seed(seed)\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.mode='train_encoder'\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tprint ('Loading pre-trained model.')\n",
        "\t\t\tvariables_to_restore = slim.get_model_variables(scope='encoder')\n",
        "\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\n",
        "\t\t\tif not os.path.exists(os.path.join(self.exp_dir,'images')):\n",
        "\t\t\t\tos.makedirs(os.path.join(self.exp_dir,'images'))\n",
        "\n",
        "\t\t\t# perform random search\n",
        "\t\t\t\n",
        "\t\t\tsave_search_file_name=os.path.join(self.images_dir,'TEST_Random_test_string_length_'+str(string_length))\n",
        "\n",
        "\t\t\tall_accuracies, all_transformations, all_levels, all_images = self.search_ops.random_search(5000, string_length, save_search_file_name,\tself.test, test_images, test_labels, sess) \n",
        "\t\t\t# save output\n",
        "\n",
        "\t\t\twith open(os.path.join(self.exp_dir, 'worst_case_accuracies.pkl'), 'w') as f:\n",
        "\t\t\t\tcPickle.dump((all_accuracies, all_transformations, all_levels), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\tdef test_evolution_search(self, run='0', seed=123, no_iters=100, string_length=3, pop_size=10, mutation_rate=0.1):\n",
        "\n",
        "\t\ttest_images, test_labels = self.load_mnist(split='test')\n",
        "\t\t\n",
        "\t\tnpr.seed(213)\n",
        "\t\trnd_idx = range(len(test_images))\n",
        "\t\tnpr.shuffle(rnd_idx)\t\t\n",
        "\n",
        "\t\ttest_images = test_images[rnd_idx]\n",
        "\t\ttest_labels = test_labels[rnd_idx]\n",
        "\n",
        "\t\ttest_images = test_images[:1000]\n",
        "\t\ttest_labels = test_labels[:1000]\n",
        "\n",
        "\t\tnpr.seed(seed)\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.mode='train_encoder'\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tprint ('Loading pre-trained model.')\n",
        "\t\t\tvariables_to_restore = slim.get_model_variables()\n",
        "\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\n",
        "\t\t\tif not os.path.exists(os.path.join(self.exp_dir,'GA_images')):\n",
        "\t\t\t\tos.makedirs(os.path.join(self.exp_dir,'GA_images'))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\tsave_search_file_name=os.path.join(self.images_dir,'TEST_Evolution_test_string_length_'+str(string_length))\n",
        "\n",
        "\t\t\tself.search_ops.genetic_algorithm(100, pop_size, string_length, mutation_rate, save_search_file_name, self.test, test_images, test_labels, sess)\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    print('...')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnbuZhGRVd6o",
        "outputId": "0d80d505-cf06-41f1-cc86-decc828c94e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "    \n",
        "    def __init__(self, mode='train'):\n",
        "\n",
        "        self.no_classes = 10\n",
        "        self.img_size = 32\n",
        "        self.no_channels = 3\n",
        "\n",
        "    def encoder(self, images, reuse=False):\n",
        "\n",
        "        with tf.variable_scope('encoder', reuse=reuse):\n",
        "            with slim.arg_scope([slim.fully_connected], activation_fn=tf.nn.relu):\n",
        "                with slim.arg_scope([slim.conv2d], activation_fn=tf.nn.relu, padding='VALID'):\n",
        "\n",
        "                    net = slim.conv2d(images, 64, 5, scope='conv1')\n",
        "                    net = slim.max_pool2d(net, 2, stride=2, scope='pool1')\n",
        "                    net = slim.conv2d(net, 128, 5, scope='conv2')\n",
        "                    net = slim.max_pool2d(net, 2, stride=2, scope='pool2')\n",
        "                    net = tf.layers.flatten(net)\n",
        "                    net = slim.fully_connected(net, 1024, scope='fc1')\n",
        "                    net = slim.fully_connected(net, 1024, scope='fc2')\n",
        "                    net = slim.fully_connected(net, self.no_classes, activation_fn=None, scope='fco')\n",
        "                    \n",
        "                    return net\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        # images placeholder\n",
        "        self.images = tf.placeholder(tf.float32, [None, self.img_size, self.img_size, self.no_channels], 'images')\n",
        "        # labels placeholder\n",
        "        self.labels = tf.placeholder(tf.int64, [None], 'labels')\n",
        "                \n",
        "        self.logits = tf.squeeze(self.encoder(self.images))\n",
        "\n",
        "        #for evaluation\n",
        "        self.pred = tf.argmax(self.logits, 1)\n",
        "        self.correct_pred = tf.equal(self.pred, self.labels)\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
        "\n",
        "        #variables for the minimizer are the net weights, variables for the maxmizer are the images' pixels\n",
        "        min_vars = tf.trainable_variables()\n",
        "                \n",
        "        #loss for the minimizer\n",
        "        self.min_loss = slim.losses.sparse_softmax_cross_entropy(self.logits, self.labels)\n",
        "\n",
        "        #we use Adam for the minimizer and vanilla gradient ascent for the maximizer \n",
        "        self.min_optimizer = tf.train.AdamOptimizer(self.learning_rate) \n",
        "\n",
        "        #minimizer\n",
        "        self.min_train_op = slim.learning.create_train_op(self.min_loss, self.min_optimizer, variables_to_train = min_vars)\n",
        "\n",
        "        min_loss_summary = tf.summary.scalar('min_loss', self.min_loss)\n",
        "\n",
        "        accuracy_summary = tf.summary.scalar('accuracy', self.accuracy)\n",
        "        self.summary_op = tf.summary.merge([min_loss_summary, accuracy_summary])\t\t\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wpeLT6ZTVkEo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = 0\n",
        "exp_dir = '/content/'\n",
        "mode = 'train_ERM'\n",
        "run = 0\n",
        "seed = 123\n",
        "transf_string_length = 5\n",
        "search_no_iters = 100\n",
        "pop_size = 10\n",
        "mutation_rate = 0.1"
      ],
      "metadata": {
        "id": "tHYvjWw0Vmw3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy.random as npr\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "\n",
        "def main(_):\n",
        "\n",
        "\n",
        "\tGPU_ID = gpu\n",
        "\tos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152 on stackoverflow\n",
        "\tos.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_ID)\n",
        "\n",
        "\tEXP_DIR = exp_dir\n",
        "\n",
        "\tmodel = Model()\n",
        "\ttr_ops = TrainOps(model, EXP_DIR)\n",
        "\n",
        "\tif 'train' in mode:\n",
        "\t\tnpr.seed(int(seed))\n",
        "\n",
        "\t\n",
        "\tif mode=='train_ERM':\n",
        "\t\tprint('Training model with standard ERM')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train()      \n",
        "\t\t\n",
        "\tif mode=='train_RDA':\n",
        "\t\tprint('Training model with RDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train(random_transf=True)\n",
        "\t\t\n",
        "\tif mode=='train_RSDA':\n",
        "\t\tprint('Training model with RSDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train_search(search_algorithm='random_search')\n",
        "\t\t\n",
        "\tif mode=='train_ESDA':\n",
        "\t\tprint('Training model with ESDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train_search(search_algorithm='evolution_search')\n",
        "\n",
        "\t\t\n",
        "\telif mode=='test_all':\n",
        "\t\tprint('Testing all')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_all()\n",
        "\n",
        "\telif mode=='test_RS':\n",
        "\t\tprint('Random search')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_random_search(run=str(run), seed=int(seed), no_iters=int(search_no_iters), string_length=int(transf_string_length)) \n",
        "\n",
        "\telif mode=='test_ES':\n",
        "\t\tprint('Evolution search')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_evolution_search(run=str(run), seed=int(seed), no_iters=int(search_no_iters),string_length=int(transf_string_length), \n",
        "\t\t\t\t\t\t\t\t\t\tpop_size=int(pop_size), mutation_rate=float(mutation_rate))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttf.app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H13Dhi7tVqjX",
        "outputId": "85dde951-3c39-4faf-fb69-8257156b7bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with standard ERM\n",
            "/content/\n",
            "LOADING CONFIG FILE\n",
            "Building model\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 13:20:19.615038 140573857834880 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-905eaf5cb5a2>:22: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 13:20:19.664870 140573857834880 deprecation.py:323] From <ipython-input-12-905eaf5cb5a2>:22: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-905eaf5cb5a2>:47: sparse_softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.sparse_softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 13:20:19.718055 140573857834880 deprecation.py:323] From <ipython-input-12-905eaf5cb5a2>:47: sparse_softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.sparse_softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:409: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.compute_weighted_loss instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 13:20:19.859088 140573857834880 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:409: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.compute_weighted_loss instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 13:20:19.873044 140573857834880 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:154: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 13:20:19.880676 140573857834880 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:154: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.add_loss instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 13:20:19.892500 140573857834880 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.add_loss instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built\n",
            "Loading data\n",
            "Loading KMNIST dataset.\n",
            "Loading KMNIST dataset.\n",
            "Training\n",
            "Step: [1/100001] train_min_loss: [2.2908] train_acc: [0.2000] test_min_loss: [2.2942] test_acc: [0.1800]\n",
            "Saving\n",
            "Step: [2501/100001] train_min_loss: [0.1898] train_acc: [0.9200] test_min_loss: [0.4266] test_acc: [0.8600]\n",
            "Step: [5001/100001] train_min_loss: [0.0233] train_acc: [1.0000] test_min_loss: [0.4695] test_acc: [0.8800]\n",
            "Step: [7501/100001] train_min_loss: [0.0154] train_acc: [0.9900] test_min_loss: [0.4195] test_acc: [0.8900]\n",
            "Step: [10001/100001] train_min_loss: [0.0164] train_acc: [0.9900] test_min_loss: [0.2482] test_acc: [0.9200]\n",
            "Saving\n",
            "Step: [12501/100001] train_min_loss: [0.0265] train_acc: [0.9900] test_min_loss: [0.6222] test_acc: [0.8600]\n",
            "Step: [15001/100001] train_min_loss: [0.0034] train_acc: [1.0000] test_min_loss: [0.4736] test_acc: [0.9000]\n",
            "Step: [17501/100001] train_min_loss: [0.0032] train_acc: [1.0000] test_min_loss: [0.2764] test_acc: [0.9200]\n",
            "Step: [20001/100001] train_min_loss: [0.0029] train_acc: [1.0000] test_min_loss: [0.2675] test_acc: [0.9400]\n",
            "Saving\n",
            "Step: [22501/100001] train_min_loss: [0.0321] train_acc: [0.9900] test_min_loss: [0.2797] test_acc: [0.9500]\n",
            "Step: [25001/100001] train_min_loss: [0.0006] train_acc: [1.0000] test_min_loss: [0.4858] test_acc: [0.9000]\n",
            "Step: [27501/100001] train_min_loss: [0.0002] train_acc: [1.0000] test_min_loss: [0.3325] test_acc: [0.9600]\n",
            "Step: [30001/100001] train_min_loss: [0.0043] train_acc: [1.0000] test_min_loss: [0.3571] test_acc: [0.9600]\n",
            "Saving\n",
            "Step: [32501/100001] train_min_loss: [0.0001] train_acc: [1.0000] test_min_loss: [0.3236] test_acc: [0.9300]\n",
            "Step: [35001/100001] train_min_loss: [0.0038] train_acc: [1.0000] test_min_loss: [0.4031] test_acc: [0.9300]\n"
          ]
        }
      ]
    }
  ]
}