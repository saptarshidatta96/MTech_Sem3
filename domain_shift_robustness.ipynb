{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "domain_shift_robustness.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saptarshidatta96/MTech_Sem3/blob/main/domain_shift_robustness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0AhMQL3ujEk",
        "outputId": "8aad6d01-ce37-4dcd-e12c-75e8c70f0a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.12.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"User Current Version:-\", sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiiuj1boZ6aY",
        "outputId": "fac6c929-c511-49ee-9737-7f82676d405a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Current Version:- 3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1akyQFlGurwB",
        "outputId": "f6328209-768d-4f00-8860-0ff0a49974b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "jzYL8jNBhPzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7605be-234e-452a-e886-962e94137b11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib import slim"
      ],
      "metadata": {
        "id": "orc7I9m8iDwz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import _pickle as cPickle"
      ],
      "metadata": {
        "id": "ISSqwKuFahEn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def resize_images(image_arrays, size=[32,32]):\n",
        "    image_arrays = (image_arrays * 255).astype('uint8')\n",
        "    \n",
        "    resized_image_arrays = np.zeros([image_arrays.shape[0]]+size)\n",
        "    for i, image_array in enumerate(image_arrays):\n",
        "        image = Image.fromarray(image_array)\n",
        "        resized_image = image.resize(size=size, resample=Image.ANTIALIAS)\n",
        "        \n",
        "        resized_image_arrays[i] = np.asarray(resized_image)\n",
        "    \n",
        "    return np.expand_dims(resized_image_arrays, 3)  \n",
        "\n",
        "def download_and_process_mnist():\n",
        "    \n",
        "    \n",
        "    if not os.path.exists('./data/mnist'):\n",
        "      os.makedirs('./data/mnist')\n",
        "    \n",
        "    mnist = input_data.read_data_sets(train_dir='./data/mnist')\n",
        "\n",
        "    train = {'X': resize_images(mnist.train.images.reshape(-1, 28, 28)),\n",
        "             'y': mnist.train.labels}\n",
        "    \n",
        "    test = {'X': resize_images(mnist.test.images.reshape(-1, 28, 28)),\n",
        "            'y': mnist.test.labels}\n",
        "        \n",
        "    with open('./data/mnist/train.pkl','wb') as f:\n",
        "      cPickle.dump(train,f)\n",
        "    \n",
        "    with open('./data/mnist/test.pkl','wb') as f:\n",
        "      cPickle.dump(test,f)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    download_and_process_mnist()\n",
        "    \n"
      ],
      "metadata": {
        "id": "9fc7b-jb6xdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d860e3-54f0-4bf6-aef2-d6047918772e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-8ea67d6d525b>:27: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "search ops"
      ],
      "metadata": {
        "id": "KKYjUm2lbVkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "from configparser import *\n",
        "import os\n",
        "\n",
        "import scipy.io\n",
        "import sys\n",
        "import glob\n",
        "from numpy.linalg import norm\n",
        "from scipy import misc\n",
        "import skimage.transform\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "\n",
        "\n",
        "class SearchOps(object):\n",
        "\t\n",
        "\t'''\n",
        "\tClass to handle all the search procedures.\n",
        "\tCurrently implemented: random search and evolution search\n",
        "\t'''\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.transf_ops = TransfOps()\n",
        "\n",
        "\tdef random_search(self, no_iters, string_length, save_file_name, compute_fitness_f, original_images, *args):\n",
        "\n",
        "\t\t'''\n",
        "\t\tSampling random image transformations and testing them on a provided model.\n",
        "\t\tReferring to the paper, this is Algorithm 1.\n",
        "\t\t\n",
        "\t\t\tno_iters: number of iterations.\n",
        "\t\t\tstring_length: number of transformations to be concatenated.\n",
        "\t\t\tsave_file_name: file name used to save .png and .pkl outputs.\n",
        "\t\t\tcompute_fitness_f: test function associated with the desired model.\n",
        "\t\t\toriginal_images: images to give in input to compute_fitness_f.\n",
        "\t\t\targs: other input eventually required by compute_fitness_f (e.g., ground truth labels, sess, etc.)\n",
        "\n",
        "\t\t'''\n",
        "\n",
        "\t\tall_accuracies = []\n",
        "\t\tall_best_accuracies = []\n",
        "\t\tall_transformations = []\n",
        "\t\tall_levels = []\n",
        "\t\tall_images = []\n",
        "\t\tcurrent_minimum = 1.\n",
        "\t\t\n",
        "\t\tnumber_fitness_evals = 0\t\t\n",
        "\t\t\n",
        "\t\tfor t in range(no_iters):\n",
        "\n",
        "\t\t\tif (t%100)==0:\n",
        "\t\t\t\tprint('Iter #',str(t))\n",
        "\n",
        "\t\t\ttr_images, transformations, levels = self.transf_ops.transform_dataset(original_images * 255., transf_string='random_'+str(string_length))\n",
        "\t\t\t\n",
        "\t\t\ttr_images /= 255.\n",
        "\t\t\t\n",
        "\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\ttarget_accuracy = 0\n",
        "\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\tnumber_fitness_evals += 1\n",
        "\n",
        "\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\n",
        "\t\t\tall_accuracies.append(target_accuracy)\n",
        "\n",
        "\t\t\tif target_accuracy < current_minimum:\n",
        "\t\t\t\tprint ('%d Current minimum: [%.4f], # fitness evals: [%d]'%(t, target_accuracy, number_fitness_evals))\n",
        "\t\t\t\tcurrent_minimum=target_accuracy\t\t\t\t\n",
        "\t\t\t\n",
        "\t\t\t\tall_best_accuracies.append(target_accuracy)\n",
        "\t\t\t\tall_transformations.append(transformations)\n",
        "\t\t\t\tall_levels.append(levels)\n",
        "\n",
        "\t\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\t\tall_images.append(conc_images)\n",
        "\n",
        "\n",
        "\t\tprint('Saving output in \"images\" folder')\n",
        "\t\tPIL.Image.fromarray(conc_images.astype('uint8')).save(save_file_name+'_acc_%.3f.png'%(current_minimum))\n",
        "\t\t\t\t\n",
        "\t\twith open(save_file_name+'_acc_%.3f.pkl'%(current_minimum), 'wb') as f:\n",
        "\t\t\tcPickle.dump((all_accuracies, all_best_accuracies, all_transformations, all_levels, number_fitness_evals), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\t\treturn all_best_accuracies[-1], all_transformations[-1].tolist(), all_levels[-1], all_images[-1]\n",
        "\t\t\t\n",
        "\tdef genetic_algorithm(self, no_iters, pop_size, string_length, mutation_rate, save_file_name, compute_fitness_f, original_images, *args):\n",
        "\n",
        "\t\t'''\n",
        "\t\tSampling random image transformations and testing them on a provided model.\n",
        "\t\tReferring to the paper, this is Algorithm 2.\n",
        "\t\t\n",
        "\t\t\tno_iters: number of iterations.\n",
        "\t\t\tstring_length: number of transformations to be concatenated.\n",
        "\t\t\tmutation_rate: a value in [0.0,1.0]\n",
        "\t\t\tsave_file_name: file name used to save .png and .pkl outputs.\n",
        "\t\t\tcompute_fitness_f: test function associated with the desired model.\n",
        "\t\t\toriginal_images: images to give in input to compute_fitness_f.\n",
        "\t\t\targs: other input eventually required by compute_fitness_f (e.g., ground truth labels, sess, etc.)\n",
        "\n",
        "\t\t'''\n",
        "\n",
        "\t\tmin_accuracy = 1.0 # initialized with the maximum value\n",
        "\t\tcurrent_minimum = 1.0 # initialized with the maximum value\n",
        "\n",
        "\t\tnumber_fitness_evals = 0\n",
        "\t\tnumber_fitness_needed = pop_size\n",
        "\n",
        "\t\tpop_accuracies = []\n",
        "\t\tpop_probabilities = []\n",
        "\t\tpop_transformations = []\n",
        "\t\tpop_levels = []\n",
        "\t\tpop_images = []\n",
        "\n",
        "\t\tmin_accs = []\n",
        "\t\tmin_transfs = []\n",
        "\t\tmin_levels = []\n",
        "\t\tmin_images = []\n",
        "\n",
        "\t\tall_fitnesses = []\n",
        "\n",
        "\t\tprint('Initializing population')\n",
        "\t\t\t\n",
        "\t\tfor p in range(pop_size): # number of items in the population\n",
        "\n",
        "\t\t\ttr_images, transformations, levels = self.transf_ops.transform_dataset(original_images * 255., transf_string='random_'+str(string_length))\n",
        "\t\t\ttr_images /= 255.\n",
        "\n",
        "\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\ttarget_accuracy = 0\n",
        "\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\tnumber_fitness_evals += 1\n",
        "\t\t\t\n",
        "\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\n",
        "\t\t\tpop_accuracies.append(target_accuracy)\n",
        "\t\t\tpop_transformations.append(transformations)\n",
        "\t\t\tpop_levels.append(levels)\n",
        "\t\t\t\n",
        "\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\t\t\t\n",
        "\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\tpop_images.append(conc_images)\n",
        "\t\t\t\n",
        "\t\tpop_probabilities = (1. - np.array(pop_accuracies))/np.sum(1. - np.array(pop_accuracies)) \n",
        "\n",
        "\t\tcurrent_minimum = np.min(pop_accuracies)\n",
        "\t\tprint('Current minimum:',str(current_minimum), '# fitness evals', str(number_fitness_evals))\n",
        "\n",
        "\t\tmin_accs.append(current_minimum)\n",
        "\n",
        "\t\tall_fitnesses.append(current_minimum)\n",
        "\t\t\n",
        "\t\tpop_transformations = [arr.tolist() for arr in pop_transformations]\t\t\t\n",
        "\n",
        "\t\tmin_transfs.append(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\tmin_levels.append(pop_levels[np.argmin(pop_accuracies)])\n",
        "\t\tmin_images.append(pop_images[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\tprint('Running evolution search')\n",
        "\n",
        "\t\tfor step in range(no_iters): # number of iters for the evolution search\n",
        "\n",
        "\t\t\tif current_minimum == 0.0:\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\t\tnew_pop_accuracies = []\n",
        "\t\t\tnew_pop_images = []\n",
        "\t\t\tnew_pop_transformations = [None for i in range(pop_size)]\n",
        "\t\t\tnew_pop_levels = [None for i in range(pop_size)]\n",
        "\n",
        "\t\t\tfor p in range(pop_size/2):\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t# randomly choose two parents to be mated <3\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tidx_1 = npr.choice(pop_size, p=pop_probabilities)\n",
        "\t\t\t\tidx_2 = npr.choice(pop_size, p=pop_probabilities)\n",
        "\n",
        "\t\t\t\ttransformations_1 = pop_transformations[idx_1]\n",
        "\t\t\t\ttransformations_2 = pop_transformations[idx_2]\n",
        "\t\t\t\tlevels_1 = pop_levels[idx_1]\n",
        "\t\t\t\tlevels_2 = pop_levels[idx_2]\n",
        "\t\t\t\t\n",
        "\t\t\t\t# cutting transformations/levels on a random point and \n",
        "\t\t\t\t\t\n",
        "\t\t\t\tcrossover_point = npr.randint(string_length)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tnew_transformations_1 = transformations_1[:crossover_point] + transformations_2[crossover_point:]\n",
        "\t\t\t\tnew_levels_1 = levels_1[:crossover_point] + levels_2[crossover_point:]\n",
        "\t\t\t\tnew_transformations_2 = transformations_2[:crossover_point] + transformations_1[crossover_point:]\n",
        "\t\t\t\tnew_levels_2 = levels_2[:crossover_point] + levels_1[crossover_point:]\n",
        "\t\t\t\t\n",
        "\t\t\t\t# adding the new offspring to the new population\t\t\t\t\n",
        "\n",
        "\t\t\t\tnew_pop_transformations[p] = new_transformations_1\n",
        "\t\t\t\tnew_pop_levels[p] = new_levels_1\n",
        "\t\t\t\tnew_pop_transformations[p+pop_size/2] = new_transformations_2\n",
        "\t\t\t\tnew_pop_levels[p+pop_size/2] = new_levels_2\n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t# mutating some genes\n",
        "\t\t\t\t\n",
        "\t\t\tfor i, transformations in enumerate(new_pop_transformations):\n",
        "\t\t\t\tfor j, transf in enumerate(transformations):\n",
        "\t\t\t\t\tif npr.rand() < mutation_rate: \n",
        "\t\t\t\t\t\tnew_pop_transformations[i][j] = npr.choice(self.transf_ops.transformation_list, 1)[0]\n",
        "\t\t\t\t\t\tnew_pop_levels[i][j] = npr.choice(self.transf_ops.code_to_level_dict[new_pop_transformations[i][j]].values(), 1)[0]\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t# computing accuracies (\"fitness\" values)\n",
        "\n",
        "\t\t\tfor transformations, levels in zip(new_pop_transformations, new_pop_levels): \n",
        "\n",
        "\t\t\t\ttr_images, _, _ = self.transf_ops.transform_dataset(original_images * 255., transformations=transformations, levels=levels)\n",
        "\t\t\t\ttr_images /= 255.\n",
        "\t\t\t\t\n",
        "\t\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\t\ttarget_accuracy = 0\n",
        "\t\t\t\ttarget_loss = 0\n",
        "\t\t\t\n",
        "\t\t\t\tnumber_fitness_evals += 1\n",
        "\t\t\t\n",
        "\t\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\t\t\t\t\n",
        "\t\t\t\tnew_pop_accuracies.append(target_accuracy)\n",
        "\n",
        "\n",
        "\t\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\n",
        "\t\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\t\tnew_pop_images.append(conc_images)\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\tpop_transformations = new_pop_transformations\n",
        "\t\t\tpop_levels = new_pop_levels\n",
        "\t\t\tpop_accuracies = new_pop_accuracies\n",
        "\n",
        "\t\t\tpop_images = new_pop_images\n",
        "\t\t\tpop_probabilities = (1. - np.array(pop_accuracies))/np.sum(1. - np.array(pop_accuracies)) \n",
        "\n",
        "\t\t\tif np.min(pop_accuracies) < current_minimum:\n",
        "\t\t\t\tcurrent_minimum = np.min(pop_accuracies)\n",
        "\t\t\t\tprint(str(step), '- Current minimum:', str(current_minimum), '#number fitness evals', str(number_fitness_evals))\n",
        "\t\t\t\tprint(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tprint(pop_levels[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\t\t\tnumber_fitness_needed = number_fitness_evals\n",
        "\n",
        "\t\t\t\tmin_accs.append(current_minimum)\n",
        "\t\t\t\tmin_transfs.append(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tmin_levels.append(pop_levels[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tmin_images.append(pop_images[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\tall_fitnesses.append(current_minimum)\n",
        "\n",
        "\t\tPIL.Image.fromarray(pop_images[np.argmin(pop_accuracies)].astype('uint8')).save(save_file_name+'_acc_%.3f.png'%(current_minimum))\n",
        "\t\t\n",
        "\t\twith open(save_file_name+'_acc_%.3f.pkl'%(current_minimum), 'wb') as f:\n",
        "\t\t\tcPickle.dump((min_accs,min_transfs, min_levels, number_fitness_needed, all_fitnesses), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\t\treturn min_accs[np.argmin(min_accs)], min_transfs[np.argmin(min_accs)], min_levels[np.argmin(min_accs)], min_images[np.argmin(min_accs)]\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    print('...')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjXMPhX3bTl-",
        "outputId": "f85c2e3e-1fd8-408e-e39a-46849c521ad9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tranf ops"
      ],
      "metadata": {
        "id": "uESW4nkibRuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import PIL\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageEnhance\n",
        "import PIL.Image\n",
        "import matplotlib\n",
        "\n",
        "class TransfOps(object):\n",
        "\n",
        "\t'''\n",
        "\tClass to handle the decoding of the strings used with the genetic\n",
        "\talgorithm and all the data transformations.\n",
        "\t'''\n",
        "\t\n",
        "\tdef __init__(self):\n",
        "\t\t\t\t\n",
        "\t\tself.transformation_list = ['autocontrast', 'brightness', 'color', 'contrast', 'sharpness', 'solarize', 'grayscale', 'Renhancer', 'Genhancer', 'Benhancer']\n",
        "\t\tself.define_code_correspondances()\n",
        "\t\t\n",
        "\tdef decode_string(self, transf_string):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tCode to decode the string used by the genetic algorithm\n",
        "\t\tString example: 't1,l1_3,t4,l4_0,t0,l0_1'. First transformation is the one \n",
        "\t\tassociated with index '1', with level set to '3', and so on.\n",
        "\t\t'random_N' with N integer gives N rnd transformations with rnd levels.\n",
        "\t\t'''\n",
        "\t\t\n",
        "\t\tif 'random' in transf_string:\n",
        "\t\t\ttransformations = npr.choice(self.transformation_list, int(transf_string.split('_')[-1])) # the string is 'random_N'\n",
        "\t\t\tlevels = [npr.choice(list(self.code_to_level_dict[t].values()), 1)[0] for t in transformations] # list() to make it compatible with Python3\n",
        "\t\telse:\n",
        "\t\t\ttransformation_codes = transf_string.split(',')[0::2] \n",
        "\t\t\tlevel_codes = transf_string.split(',')[1::2]\n",
        "\t\t\t\n",
        "\t\t\ttransformations = [self.code_to_transf(code) for code in transformation_codes] \t\n",
        "\t\t\tlevels = [self.code_to_level(transf,level) for transf,level in zip(transformations, level_codes)] \t\n",
        "\n",
        "\t\treturn transformations, levels\t\t\n",
        "\n",
        "\tdef transform_dataset(self, dataset, transf_string = 't0,l0_0', transformations=None, levels=None):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tdataset: set of images, shape should be N x width x height x #channels\n",
        "\t\ttransf_string: transformations and levels encoded in a string \n",
        "\t\t'''\n",
        "\n",
        "\t\t#print 'Dataset size:',dataset.shape\n",
        "\t\t\n",
        "\t\tif len(dataset.shape) == 3: # if 'dataset' is a single image\n",
        "\t\t\tdataset = np.expand_dims(dataset, 0) \n",
        "\t\t\n",
        "\t\tif dataset.shape[-1] != 3:\n",
        "\t\t\tprint('Input shape:', str(dataset.shape))\n",
        "\t\t\traise Exception('The images must be in RGB format')\n",
        "\n",
        "\t\ttr_dataset = np.zeros((dataset.shape))\n",
        "\t\t\n",
        "\t\tif transformations is None:\n",
        "\t\t\t# decoding transformation string\n",
        "\t\t\ttransformations, levels = self.decode_string(transf_string)\t\n",
        "\t\t\n",
        "\t\tfor n,img in enumerate(dataset):\n",
        "\t\t\tpil_img = PIL.Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "\t\t\tfor transf,level in zip(transformations, levels): \n",
        "\t\t\t\tpil_img = self.apply_transformation(pil_img, transf, level)\n",
        "\t\t\ttr_dataset[n] = np.array(pil_img)\n",
        "\n",
        "\t\treturn tr_dataset, transformations, levels\n",
        "\n",
        "\tdef apply_transformation(self, image, transformation, level):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\timage: image to be tranformed, shape should be 1 x width x height x #channels\n",
        "\t\ttransformation: type of transformation to be applied\n",
        "\t\tlevel: level of the perturbation to be applied \n",
        "\t\t'''\n",
        "\n",
        "\t\tif transformation == 'identity':\n",
        "\t\t\treturn image \n",
        "\n",
        "\t\telif transformation == 'autocontrast':\n",
        "\t\t\treturn PIL.ImageOps.autocontrast(image, cutoff=level)\n",
        "\n",
        "\t\telif transformation == 'brightness':\n",
        "\t\t\treturn PIL.ImageEnhance.Brightness(image).enhance(level)\n",
        "\n",
        "\t\telif transformation == 'color':\n",
        "\t\t\treturn PIL.ImageEnhance.Color(image).enhance(level)\n",
        "\t\t\t\n",
        "\t\telif transformation == 'contrast':\n",
        "\t\t\treturn PIL.ImageEnhance.Contrast(image).enhance(level)\n",
        "\n",
        "\t\telif transformation == 'sharpness':\n",
        "\t\t\treturn PIL.ImageEnhance.Sharpness(image).enhance(level)\n",
        "\t\t\t\n",
        "\t\telif transformation == 'solarize':\n",
        "\t\t\treturn PIL.ImageOps.solarize(image, threshold=level)\n",
        "\n",
        "\t\telif transformation == 'grayscale':\n",
        "\t\t\timage = PIL.ImageOps.grayscale(image).convert('RGB')\n",
        "\t\t\treturn image\t\t\n",
        "\n",
        "\t\telif transformation == 'Renhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,0] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\t\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\t\telif transformation == 'Genhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,1] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\t\telif transformation == 'Benhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,2] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\tdef code_to_transf(self, code):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tTakes in input a code (e.g., 't0', 't1', ...) and gives in output \n",
        "\t\tthe related transformation.\n",
        "\t\t'''\n",
        "\n",
        "\t\treturn self.code_to_transf_dict[code]\n",
        "\n",
        "\n",
        "\tdef code_to_level(self, transformation, code):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tTakes in input a transfotmation (e.g., 'invert', 'colorize', ...) and \n",
        "\t\ta level code (e.g., 'l0_1', 'l1_3', ...) and gives in output the related level.\n",
        "\t\t'''\n",
        "\t\t\n",
        "\t\treturn self.code_to_level_dict[transformation][code]\n",
        "\t\t\t\t\n",
        "\tdef define_code_correspondances(self):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tDefine the correpondances between transformation/level codes\n",
        "\t\tand the actual types and values.\n",
        "\t\t'''\n",
        "\t\t\t\n",
        "\t\tself.code_to_transf_dict = dict()\n",
        "\t\t\n",
        "\t\tself.code_to_transf_dict['t1'] = 'autocontrast'\n",
        "\t\tself.code_to_transf_dict['t2'] = 'brightness'\n",
        "\t\tself.code_to_transf_dict['t3'] = 'color'\n",
        "\t\tself.code_to_transf_dict['t4'] = 'contrast'\n",
        "\t\tself.code_to_transf_dict['t5'] = 'sharpness'\n",
        "\t\tself.code_to_transf_dict['t6'] = 'solarize'\n",
        "\t\tself.code_to_transf_dict['t7'] = 'grayscale'\n",
        "\t\tself.code_to_transf_dict['t8'] = 'Renhancer'\n",
        "\t\tself.code_to_transf_dict['t9'] = 'Genhancer'\n",
        "\t\tself.code_to_transf_dict['t10'] = 'Benhancer'\n",
        "\n",
        "\t\tself.code_to_level_dict = dict()\n",
        "\t\t\n",
        "\t\tfor k in self.transformation_list:\n",
        "\t\t\tself.code_to_level_dict[k] = dict()\n",
        "\t\t\t\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['autocontrast'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.0,0.3,20)):\n",
        "\t\t\tself.code_to_level_dict['autocontrast']['l1_'+str(n)] = l\n",
        "\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['brightness'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['brightness']['l2_'+str(n)] = l\n",
        "\t\t\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['color'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['color']['l3_'+str(n)] = l\n",
        "\t\t\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['contrast'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['contrast']['l4_'+str(n)] = l\n",
        "\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['sharpness'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['sharpness']['l5_'+str(n)] = l\n",
        "\t\t\n",
        "\t\tself.code_to_level_dict['solarize'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0,20,20).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['solarize']['l6_'+str(n)] = l\n",
        "\n",
        "\t\tself.code_to_level_dict['grayscale']['l7_0'] = None\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Renhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Renhancer']['l8_'+str(n)] = l\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Genhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Genhancer']['l9_'+str(n)] = l\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Benhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Benhancer']['l10_'+str(n)] = l\n",
        "\n",
        "if __name__=='__main__':\n",
        "\tpass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ofPhxacqbHjM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import configparser\n",
        "import os\n",
        "#import cPickle\n",
        "import scipy.io\n",
        "import sys\n",
        "import glob\n",
        "from numpy.linalg import norm\n",
        "from scipy import misc\n",
        "import skimage.transform\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "sys.path.insert(0,'../')\n",
        "\n",
        "\n",
        "class TrainOps(object):\n",
        "\n",
        "\tdef __init__(self, model, exp_dir):\n",
        "\n",
        "\t\tself.model = model\n",
        "\t\tself.exp_dir = exp_dir\n",
        "\n",
        "\t\tself.config = tf.ConfigProto()\n",
        "\t\tself.config.gpu_options.allow_growth=False\n",
        "\n",
        "\t\tself.data_dir = './data'\n",
        "\n",
        "\tdef load_exp_config(self):\n",
        "\n",
        "\t\tprint(self.exp_dir)\n",
        "\n",
        "\t\tconfig = configparser.ConfigParser()\n",
        "\n",
        "\t\tprint('LOADING CONFIG FILE')\n",
        "\t\tconfig.read(os.path.join(self.exp_dir,'exp_config'))\n",
        "\t\tself.source_dataset = config.get('EXPERIMENT_SETTINGS', 'source_dataset')\n",
        "\n",
        "\t\tself.model.source_dataset = self.source_dataset\n",
        "\t\t\t\n",
        "\t\tself.model.no_classes = 10\n",
        "\t\tself.model.img_size = 32\n",
        "\n",
        "\t\tself.log_dir = os.path.join(self.exp_dir,'logs')\n",
        "\t\tself.model_save_path = os.path.join(self.exp_dir,'model')\n",
        "\t\tself.images_dir = os.path.join(self.exp_dir,'images')\n",
        "\n",
        "\t\tif not os.path.exists(self.log_dir):\n",
        "\t\t\tos.makedirs(self.log_dir)\n",
        "\n",
        "\t\tif not os.path.exists(self.model_save_path):\n",
        "\t\t\tos.makedirs(self.model_save_path)\n",
        "\n",
        "\t\tif not os.path.exists(os.path.join(self.images_dir)):\n",
        "\t\t\tos.makedirs(os.path.join(self.images_dir))\n",
        "\n",
        "\n",
        "\t\tself.train_iters = config.getint('MAIN_SETTINGS', 'train_iters')\n",
        "\t\tself.batch_size = config.getint('MAIN_SETTINGS', 'batch_size')\n",
        "\t\tself.model.batch_size = self.batch_size\n",
        "\t\tself.model.learning_rate = config.getfloat('MAIN_SETTINGS', 'learning_rate')\n",
        "\n",
        "\t\tself.transf_string = config.get('MAIN_SETTINGS', 'transf_string')\n",
        "\t\tself.sub_train_iters = config.getint('MAIN_SETTINGS', 'sub_train_iters')\n",
        "\t\tself.string_length = config.getint('MAIN_SETTINGS', 'string_length')\n",
        "\n",
        "\t\tself.transf_ops = TransfOps()\n",
        "\t\tself.search_ops = SearchOps()\n",
        "\n",
        "\tdef load_svhn(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading SVHN dataset.')\n",
        "\n",
        "\t\timage_file = 'train_32x32.mat' if split=='train' else 'test_32x32.mat'\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir, 'svhn', image_file)\n",
        "\t\tsvhn = scipy.io.loadmat(image_dir)\n",
        "\t\timages = np.transpose(svhn['X'], [3, 0, 1, 2])\n",
        "\t\tlabels = svhn['y'].reshape(-1)\n",
        "\t\tlabels[np.where(labels==10)] = 0\n",
        "\t\timages = images/255.\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_mnist(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading MNIST dataset.')\n",
        "\t\timage_file = 'train.pkl' if split=='train' else 'test.pkl'\n",
        "\t\timage_dir = os.path.join(self.data_dir, 'mnist', image_file)\n",
        "\t\twith open(image_dir, 'rb') as f:\n",
        "\t\t\tmnist = cPickle.load(f)\n",
        "\t\t\n",
        "\t\timages = mnist['X'] \n",
        "\t\tlabels = mnist['y']\n",
        "\n",
        "\t\timages = images\n",
        "\t\timages = images/255. # better generalization performance if [0,1]\n",
        "\n",
        "\t\timages = np.stack((images,images,images), axis=3) # grayscale to rgb\n",
        "\n",
        "\t\treturn np.squeeze(images), labels\n",
        "\n",
        "\tdef load_mnist_m(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading MNIST_M dataset.')\n",
        "\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir,'mnist_m')\n",
        "\n",
        "\t\tif split == 'train':\n",
        "\t\t\tdata_dir = os.path.join(image_dir,'mnist_m_train')\n",
        "\t\t\twith open(os.path.join(image_dir,'mnist_m_train_labels.txt')) as f:\n",
        "\t\t\t\tcontent = f.readlines()\n",
        "\t\t\t\t\n",
        "\t\telif split == 'test':\n",
        "\t\t\tdata_dir = os.path.join(image_dir,'mnist_m_test')\n",
        "\t\t\twith open(os.path.join(image_dir,'mnist_m_test_labels.txt')) as f:\n",
        "\t\t\t\tcontent = f.readlines()\n",
        "\n",
        "\n",
        "\t\tcontent = [c.split('\\n')[0] for c in content]\n",
        "\t\timages_files = [c.split(' ')[0] for c in content]\n",
        "\t\tlabels = np.array([int(c.split(' ')[1]) for c in content]).reshape(-1)\n",
        "\n",
        "\t\timages = np.zeros((len(labels), 32, 32, 3))\n",
        "\n",
        "\t\tfor no_img,img in enumerate(images_files):\n",
        "\t\t\timg_dir = os.path.join(data_dir, img)\n",
        "\t\t\tim = misc.imread(img_dir)\n",
        "\t\t\tim = np.expand_dims(im, axis=0)\n",
        "\t\t\timages[no_img] = im\n",
        "\n",
        "\t\timages = images \n",
        "\t\timages = images/255.\n",
        "\t\t\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_syn(self, split='train'):\n",
        "\t\tprint ('Loading SYN dataset.')\n",
        "\n",
        "\t\timage_file = 'synth_train_32x32.mat' if split=='train' else 'synth_test_32x32.mat'\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir,'syn', image_file)\n",
        "\t\tsyn = scipy.io.loadmat(image_dir)\n",
        "\t\timages = np.transpose(syn['X'], [3, 0, 1, 2])\n",
        "\t\tlabels = syn['y'].reshape(-1)\n",
        "\t\tlabels[np.where(labels==10)] = 0\n",
        "\t\t\n",
        "\t\timages = images/255.\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_usps(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading USPS dataset.')\n",
        "\t\timage_file = 'usps_32x32.pkl'\n",
        "\t\timage_dir = os.path.join(self.data_dir,'usps', image_file)\n",
        "\t\t\n",
        "\t\twith open(image_dir, 'rb') as f:\n",
        "\t\t\tusps = cPickle.load(f)\n",
        "\t\t\n",
        "\t\timages = usps['X']\n",
        "\t\tlabels = usps['y']\n",
        "\t\tlabels -= 1\n",
        "\t\tlabels[labels==255] = 9\n",
        "\n",
        "\t\timages=np.squeeze(images)\n",
        "\t\timages = np.stack((images,images,images), axis=3) # grayscale to rgb\n",
        "\t\timages = images/255.\n",
        "\n",
        "\t\tif split == 'train':\n",
        "\t\t\treturn images[:6562], np.squeeze(labels[:6562]).astype(int)\n",
        "\t\telif split == 'validation':\n",
        "\t\t\treturn images[6562:7291], np.squeeze(labels[6562:7291]).astype(int)\n",
        "\t\telif split == 'test':\t    \n",
        "\t\t\treturn images[7291:], np.squeeze(labels[7291:]).astype(int)\n",
        "\t\n",
        "\tdef load_test_data(self, target):\n",
        "\n",
        "\t\tif target=='mnist_m':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_mnist_m(split='test')\n",
        "\t\telif target=='svhn':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_svhn(split='test')\n",
        "\t\telif target=='syn':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_syn(split='test')\n",
        "\t\telif target=='usps':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_usps(split='test')\n",
        "\t\telif target=='mnist':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\treturn self.target_test_images,self.target_test_labels\n",
        "\n",
        "\tdef train(self, random_transf=False): \n",
        "\n",
        "\t\t'''\n",
        "\t\tThis method allows to train ERM and RDA models.\n",
        "\t\t\n",
        "\t\t\trandom_transf: if set to True, RDA is used, o.w. ERM.\n",
        "\t\t\n",
        "\t\tThe number of transformations to be concatenated needs be to\n",
        "\t\tset in the file exp_config.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tprint('Loading data')\n",
        "\n",
        "\t\tsource_train_images, source_train_labels = self.load_mnist(split='train')\n",
        "\t\ttarget_test_images, target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\twith tf.Session(config=self.config) as sess:\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n",
        "\n",
        "\t\t\tprint('Training')\n",
        "\t\t\t\n",
        "\t\t\tfor t in range(self.train_iters):\n",
        "\n",
        "\t\t\t\ti = t % int(source_train_images.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\t\t#current batch of images and labels\n",
        "\t\t\t\tbatch_images = source_train_images[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\t\t\t\tbatch_labels = source_train_labels[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\n",
        "\t\t\t\tif random_transf:\n",
        "\t\t\t\t\tbatch_images, _, _ = self.transf_ops.transform_dataset(batch_images * 255., transf_string = self.transf_string)\n",
        "\t\t\t\t\tbatch_images /= 255.\n",
        "\t\t\t\t\n",
        "\t\t\t\tfeed_dict = {self.model.images: batch_images, self.model.labels: batch_labels} \n",
        "\n",
        "\t\t\t\t#running a step of gradient descent\n",
        "\t\t\t\tsess.run([self.model.min_train_op, self.model.min_loss], feed_dict) \n",
        "\n",
        "\t\t\t\t#evaluating the model\n",
        "\t\t\t\tif t % 2500 == 0:\n",
        "\n",
        "\t\t\t\t\tsummary, min_l, acc = sess.run([self.model.summary_op, self.model.min_loss, self.model.accuracy], feed_dict)\n",
        "\n",
        "\t\t\t\t\ttrain_rand_idxs = np.random.permutation(source_train_images.shape[0])[:100]\n",
        "\t\t\t\t\ttest_rand_idxs = np.random.permutation(target_test_images.shape[0])[:100]\n",
        "\n",
        "\t\t\t\t\ttrain_acc, train_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: source_train_images[train_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: source_train_labels[train_rand_idxs]})\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\ttest_acc, test_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: target_test_images[test_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: target_test_labels[test_rand_idxs]})\n",
        "\t\t\t\t\t  \n",
        "\t\t\t\t\tsummary_writer.add_summary(summary, t)\n",
        "\t\t\t\t\tprint ('Step: [%d/%d] train_min_loss: [%.4f] train_acc: [%.4f] test_min_loss: [%.4f] test_acc: [%.4f]'%(t+1, self.train_iters, train_min_loss, train_acc, test_min_loss, test_acc))\n",
        "\t\t\t\n",
        "\t\t\t\tif t % 10000 == 0:\n",
        "\t\t\t\t\tprint('Saving')\n",
        "\t\t\t\t\tsaver.save(sess, os.path.join(self.model_save_path, 'encoder'))\n",
        "\n",
        "\tdef train_search(self, search_algorithm='random_search'): \n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tThis method allows to train models using RSDA and ESDA algorithms.\n",
        "\t\tReferring to the paper, this is Algorithm 3.\n",
        "\n",
        "\t\t\tsearch_algorithm: 'random_search' or 'evolution_search', \n",
        "\t\t\t\t\t\t\t  accordingly to the desired search procedure.\n",
        "\n",
        "\t\tThe number of transformations to be concatenated needs be to\n",
        "\t\tset in the file exp_config.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tprint('Loading data')\n",
        "\n",
        "\t\tsource_train_images, source_train_labels = self.load_mnist(split='train')\n",
        "\t\ttarget_test_images, target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\t# initializing the set of data augmentation rules.\n",
        "\n",
        "\t\ttransformations = [['identity']]\n",
        "\t\tlevels = [[None]]\t\t\n",
        "\n",
        "\t\twith tf.Session(config=self.config) as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n",
        "\n",
        "\t\t\tprint('Training')\n",
        "\t\t\t\n",
        "\t\t\tfor t in range(self.train_iters):\n",
        "\n",
        "\t\t\t\ti = t % int(source_train_images.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\t\t# current batch of images and labels\n",
        "\t\t\t\tbatch_images = source_train_images[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\t\t\t\tbatch_labels = source_train_labels[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\n",
        "\t\t\t\t# sampling uniformly a transformation and its level, and applying it to the batch\n",
        "\t\t\t\trnd_transf_idx = npr.randint(len(transformations))\n",
        "\t\t\t\t\n",
        "\t\t\t\tif transformations[rnd_transf_idx] == ['identity']: # do nothing for 'identity', namely use original images\n",
        "\t\t\t\t\tpass\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t# TransfOps requires [0,255] pixel ranges, while here images [0,1]\n",
        "\t\t\t\t\tbatch_images, _, _ = self.transf_ops.transform_dataset(batch_images * 255., transformations=transformations[rnd_transf_idx], levels=levels[rnd_transf_idx])\n",
        "\t\t\t\t\tbatch_images /= 255.\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t# running a step of gradient descent\n",
        "\t\t\t\tfeed_dict = {self.model.images: batch_images, self.model.labels: batch_labels} \n",
        "\t\t\t\tsess.run([self.model.min_train_op, self.model.min_loss], feed_dict) \n",
        "\n",
        "\t\t\t\t#evaluating the model\n",
        "\t\t\t\tif t % 2500 == 0:\n",
        "\n",
        "\t\t\t\t\tsummary, min_l, acc = sess.run([self.model.summary_op, self.model.min_loss, self.model.accuracy], feed_dict)\n",
        "\n",
        "\t\t\t\t\ttrain_rand_idxs = np.random.permutation(source_train_images.shape[0])[:100]\n",
        "\t\t\t\t\ttest_rand_idxs = np.random.permutation(target_test_images.shape[0])[:100]\n",
        "\n",
        "\t\t\t\t\ttrain_acc, train_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: source_train_images[train_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: source_train_labels[train_rand_idxs]})\n",
        "\t\t\t\t\ttest_acc, test_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: target_test_images[test_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: target_test_labels[test_rand_idxs]})\n",
        "\t\t\t\t\t  \n",
        "\t\t\t\t\tsummary_writer.add_summary(summary, t)\n",
        "\t\t\t\t\tprint('Step: [%d/%d] train_min_loss: [%.4f] train_acc: [%.4f] test_min_loss: [%.4f] test_acc: [%.4f]'%(t+1, self.train_iters, train_min_loss, train_acc, test_min_loss, test_acc))\n",
        "\n",
        "\t\t\t\tif (t+1)%self.sub_train_iters == 0:\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif search_algorithm == 'random_search':\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tprint('\\n\\nRunning Random Search')\n",
        "\t\t\t\t\t\tsave_file_name=os.path.join(self.images_dir,'Random_string_length_'+str(self.string_length)+'_iter_'+str(t+1))\n",
        "\t\t\t\t\t\tmin_tr_accuracy, _transformations, _levels, _image = self.search_ops.random_search(100, self.string_length, save_file_name,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.test, source_train_images[:1000],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_train_labels[:1000], sess) \n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\telif search_algorithm == 'evolution_search':\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tprint('\\n\\nRunning Evolution Search')\n",
        "\t\t\t\t\t\tsave_file_name=os.path.join(self.images_dir,'Evolution_string_length_'+str(self.string_length)+'_iter_'+str(t+1))\n",
        "\t\t\t\t\t\tmin_tr_accuracy, _transformations, _levels, _image = self.search_ops.genetic_algorithm(10, 10, self.string_length, 0.1,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsave_file_name, self.test, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_train_images[:1000],\tsource_train_labels[:1000], sess) \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\ttransformations.append(_transformations)\n",
        "\t\t\t\t\tlevels.append(_levels)\n",
        "\n",
        "\t\t\t\t\tprint('Target accuracy: [%.4f]'%(min_tr_accuracy))\n",
        "\t\t\t\t\tprint('_'.join(_transformations))\n",
        "\t\t\t\t\tprint('\\n\\n')\t\t\n",
        "\n",
        "\t\t\t\tif (t+1) % 25000 == 0:\n",
        "\t\t\t\t\tprint('Saving')\n",
        "\t\t\t\t\tsaver.save(sess, os.path.join(self.model_save_path, 'encoder'))\n",
        "\n",
        "\n",
        "\tdef test(self, images, labels, sess):\n",
        "\n",
        "\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\ttarget_accuracy = 0\n",
        "\t\ttarget_loss = 0\n",
        "\t\tpreds = []\n",
        "\n",
        "\t\tfor test_images_batch, test_labels_batch in zip(np.array_split(images, N), np.array_split(labels, N)):\n",
        "\t\t\tfeed_dict = {self.model.images: test_images_batch, self.model.labels: test_labels_batch} \n",
        "\t\t\ttarget_accuracy_tmp, target_loss_tmp, pred = sess.run([self.model.accuracy, self.model.min_loss, self.model.pred], feed_dict) \n",
        "\t\t\ttarget_accuracy += target_accuracy_tmp/float(N)\n",
        "\t\t\ttarget_loss += target_loss_tmp/float(N)\n",
        "\t\t\tpreds.append(pred.tolist())\n",
        "\n",
        "\t\tcorrect_guesses = (np.array(preds)==labels).astype(int)[0]\n",
        "\t\t\n",
        "\t\treturn target_accuracy, correct_guesses\n",
        "\t\n",
        "\tdef test_all(self):\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tres_dict = dict()\n",
        "\t\tres_dict['exp_dir'] = self.exp_dir\n",
        "\n",
        "\t\tprint('Testing ALL')\n",
        "\n",
        "\t\ttargets = ['mnist', 'svhn']# add 'usps', 'syn', 'mnist_m'\n",
        "\n",
        "\t\tfor target in targets:\n",
        "\n",
        "\t\t\tprint('\\n\\n\\n...........................................................................')\n",
        "\n",
        "\t\t\ttest_images, test_labels = self.load_test_data(target=target)\n",
        "\n",
        "\t\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\t\tprint('...........................................................................')\n",
        "\n",
        "\t\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\t\tprint('Loading pre-trained model.')\n",
        "\t\t\t\tvariables_to_restore = slim.get_model_variables()\n",
        "\t\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\t\t\t\t\n",
        "\t\t\t\tN = 100\n",
        "\t\t\t\ttarget_accuracy = 0\n",
        "\t\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\t\tprint('Calculating accuracy')\n",
        "\n",
        "\t\t\t\tfor test_images_batch, test_labels_batch in zip(np.array_split(test_images, N), np.array_split(test_labels, N)):\n",
        "\t\t\t\t\tfeed_dict = {self.model.images: test_images_batch, self.model.labels: test_labels_batch} \n",
        "\t\t\t\t\ttarget_accuracy_tmp, target_loss_tmp, target_pred = sess.run([self.model.accuracy, self.model.min_loss, self.model.pred], feed_dict) \n",
        "\t\t\t\t\ttarget_accuracy += target_accuracy_tmp/float(N)\n",
        "\t\t\t\t\ttarget_loss += target_loss_tmp/float(N)\n",
        "\n",
        "\t\t\tprint('Target accuracy: [%.4f] target loss: [%.4f]'%(target_accuracy, target_loss))\n",
        "\n",
        "\t\t\tres_dict[target] = target_accuracy\n",
        "\n",
        "\t\twith open(os.path.join(self.exp_dir, 'domain_generalization_performance.pkl'), 'w') as f:\n",
        "\t\t\tcPickle.dump(res_dict, f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "\tdef test_random_search(self, run, seed, no_iters, string_length):\n",
        "\n",
        "\t\ttest_images, test_labels = self.load_test_data(target='mnist')\n",
        "\t\t\n",
        "\t\tnpr.seed(213)\n",
        "\t\trnd_idx = range(len(test_images))\n",
        "\t\tnpr.shuffle(rnd_idx)\t\t\n",
        "\n",
        "\t\ttest_images = test_images[rnd_idx]\n",
        "\t\ttest_labels = test_labels[rnd_idx]\n",
        "\n",
        "\t\ttest_images = test_images[:1000]\n",
        "\t\ttest_labels = test_labels[:1000]\n",
        "\n",
        "\t\tnpr.seed(seed)\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.mode='train_encoder'\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tprint ('Loading pre-trained model.')\n",
        "\t\t\tvariables_to_restore = slim.get_model_variables(scope='encoder')\n",
        "\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\n",
        "\t\t\tif not os.path.exists(os.path.join(self.exp_dir,'images')):\n",
        "\t\t\t\tos.makedirs(os.path.join(self.exp_dir,'images'))\n",
        "\n",
        "\t\t\t# perform random search\n",
        "\t\t\t\n",
        "\t\t\tsave_search_file_name=os.path.join(self.images_dir,'TEST_Random_test_string_length_'+str(string_length))\n",
        "\n",
        "\t\t\tall_accuracies, all_transformations, all_levels, all_images = self.search_ops.random_search(5000, string_length, save_search_file_name,\tself.test, test_images, test_labels, sess) \n",
        "\t\t\t# save output\n",
        "\n",
        "\t\t\twith open(os.path.join(self.exp_dir, 'worst_case_accuracies.pkl'), 'w') as f:\n",
        "\t\t\t\tcPickle.dump((all_accuracies, all_transformations, all_levels), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\tdef test_evolution_search(self, run='0', seed=123, no_iters=100, string_length=3, pop_size=10, mutation_rate=0.1):\n",
        "\n",
        "\t\ttest_images, test_labels = self.load_mnist(split='test')\n",
        "\t\t\n",
        "\t\tnpr.seed(213)\n",
        "\t\trnd_idx = range(len(test_images))\n",
        "\t\tnpr.shuffle(rnd_idx)\t\t\n",
        "\n",
        "\t\ttest_images = test_images[rnd_idx]\n",
        "\t\ttest_labels = test_labels[rnd_idx]\n",
        "\n",
        "\t\ttest_images = test_images[:1000]\n",
        "\t\ttest_labels = test_labels[:1000]\n",
        "\n",
        "\t\tnpr.seed(seed)\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.mode='train_encoder'\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tprint ('Loading pre-trained model.')\n",
        "\t\t\tvariables_to_restore = slim.get_model_variables()\n",
        "\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\n",
        "\t\t\tif not os.path.exists(os.path.join(self.exp_dir,'GA_images')):\n",
        "\t\t\t\tos.makedirs(os.path.join(self.exp_dir,'GA_images'))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\tsave_search_file_name=os.path.join(self.images_dir,'TEST_Evolution_test_string_length_'+str(string_length))\n",
        "\n",
        "\t\t\tself.search_ops.genetic_algorithm(100, pop_size, string_length, mutation_rate, save_search_file_name, self.test, test_images, test_labels, sess)\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    print('...')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqJtmrzJVslw",
        "outputId": "43391486-3530-4dc6-c64c-96cd3cdfe083"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "    \n",
        "    def __init__(self, mode='train'):\n",
        "\n",
        "        self.no_classes = 10\n",
        "        self.img_size = 32\n",
        "        self.no_channels = 3\n",
        "\n",
        "    def encoder(self, images, reuse=False):\n",
        "\n",
        "        with tf.variable_scope('encoder', reuse=reuse):\n",
        "            with slim.arg_scope([slim.fully_connected], activation_fn=tf.nn.relu):\n",
        "                with slim.arg_scope([slim.conv2d], activation_fn=tf.nn.relu, padding='VALID'):\n",
        "\n",
        "                    net = slim.conv2d(images, 64, 5, scope='conv1')\n",
        "                    net = slim.max_pool2d(net, 2, stride=2, scope='pool1')\n",
        "                    net = slim.conv2d(net, 128, 5, scope='conv2')\n",
        "                    net = slim.max_pool2d(net, 2, stride=2, scope='pool2')\n",
        "                    net = tf.contrib.layers.flatten(net)\n",
        "                    net = slim.fully_connected(net, 1024, scope='fc1')\n",
        "                    net = slim.fully_connected(net, 1024, scope='fc2')\n",
        "                    net = slim.fully_connected(net, self.no_classes, activation_fn=None, scope='fco')\n",
        "                    \n",
        "                    return net\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        # images placeholder\n",
        "        self.images = tf.placeholder(tf.float32, [None, self.img_size, self.img_size, self.no_channels], 'images')\n",
        "        # labels placeholder\n",
        "        self.labels = tf.placeholder(tf.int64, [None], 'labels')\n",
        "                \n",
        "        self.logits = tf.squeeze(self.encoder(self.images))\n",
        "\n",
        "        #for evaluation\n",
        "        self.pred = tf.argmax(self.logits, 1)\n",
        "        self.correct_pred = tf.equal(self.pred, self.labels)\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
        "\n",
        "        #variables for the minimizer are the net weights, variables for the maxmizer are the images' pixels\n",
        "        min_vars = tf.trainable_variables()\n",
        "                \n",
        "        #loss for the minimizer\n",
        "        self.min_loss = slim.losses.sparse_softmax_cross_entropy(self.logits, self.labels)\n",
        "\n",
        "        #we use Adam for the minimizer and vanilla gradient ascent for the maximizer \n",
        "        self.min_optimizer = tf.train.AdamOptimizer(self.learning_rate) \n",
        "\n",
        "        #minimizer\n",
        "        self.min_train_op = slim.learning.create_train_op(self.min_loss, self.min_optimizer, variables_to_train = min_vars)\n",
        "\n",
        "        min_loss_summary = tf.summary.scalar('min_loss', self.min_loss)\n",
        "\n",
        "        accuracy_summary = tf.summary.scalar('accuracy', self.accuracy)\n",
        "        self.summary_op = tf.summary.merge([min_loss_summary, accuracy_summary])\t\t\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N-KLrXpcAKqr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.py"
      ],
      "metadata": {
        "id": "pYq44fphcnvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5PIi0o995cct"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ev3DVf3t5D3E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = 0\n",
        "exp_dir = '/content/'\n",
        "mode = 'train_ERM'\n",
        "run = 0\n",
        "seed = 123\n",
        "transf_string_length = 5\n",
        "search_no_iters = 100\n",
        "pop_size = 10\n",
        "mutation_rate = 0.1"
      ],
      "metadata": {
        "id": "8DdlcOBxAP2w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy.random as npr\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "\n",
        "def main(_):\n",
        "\n",
        "\t#npr.seed(int(FLAGS.seed))\n",
        "\n",
        "\tGPU_ID = gpu\n",
        "\tos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152 on stackoverflow\n",
        "\tos.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_ID)\n",
        "\n",
        "\tEXP_DIR = exp_dir\n",
        "\n",
        "\tmodel = Model()\n",
        "\ttr_ops = TrainOps(model, EXP_DIR)\n",
        "\n",
        "\tif 'train' in mode:\n",
        "\t\tnpr.seed(int(seed))\n",
        "\n",
        "\t\n",
        "\tif mode=='train_ERM':\n",
        "\t\tprint('Training model with standard ERM')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train()      \n",
        "\t\t\n",
        "\tif mode=='train_RDA':\n",
        "\t\tprint('Training model with RDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train(random_transf=True)\n",
        "\t\t\n",
        "\tif mode=='train_RSDA':\n",
        "\t\tprint('Training model with RSDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train_search(search_algorithm='random_search')\n",
        "\t\t\n",
        "\tif mode=='train_ESDA':\n",
        "\t\tprint('Training model with ESDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train_search(search_algorithm='evolution_search')\n",
        "\n",
        "\t\t\n",
        "\telif mode=='test_all':\n",
        "\t\tprint('Testing all')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_all()\n",
        "\n",
        "\telif mode=='test_RS':\n",
        "\t\tprint('Random search')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_random_search(run=str(run), seed=int(seed), no_iters=int(search_no_iters), string_length=int(transf_string_length)) \n",
        "\n",
        "\telif mode=='test_ES':\n",
        "\t\tprint('Evolution search')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_evolution_search(run=str(run), seed=int(seed), no_iters=int(search_no_iters),string_length=int(transf_string_length), \n",
        "\t\t\t\t\t\t\t\t\t\tpop_size=int(pop_size), mutation_rate=float(mutation_rate))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttf.app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "esz-jEkt_1hs",
        "outputId": "29ab9cab-376a-4f4d-ed7b-fd093f16e65e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with standard ERM\n",
            "/content/\n",
            "LOADING CONFIG FILE\n",
            "Building model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b2c1f71e981d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b2c1f71e981d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model with standard ERM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtr_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_exp_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mtr_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train_RDA'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-b9d6cbbce155>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, random_transf)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;31m# build a graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Built'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-10300c810b82>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#for evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-10300c810b82>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(self, images, reuse)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VALID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pool1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution2d\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m   1157\u001b[0m       \u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m       conv_dims=2)\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope, conv_dims)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0m_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         _reuse=reuse)\n\u001b[0;32m-> 1057\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;31m# Add variables to collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1698\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \"\"\"\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       self.bias = self.add_weight(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    530\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    548\u001b[0m           function_utils.has_kwargs(custom_getter)):\n\u001b[1;32m    549\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constraint\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m       return _true_getter(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mlayer_variable_getter\u001b[0;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_model_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36m_model_variable_getter\u001b[0;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, synchronization, aggregation, **_)\u001b[0m\n\u001b[1;32m   1750\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mmodel_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m    352\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 868\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable encoder/conv1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "It1GZavC2Pf8",
        "outputId": "bc4c3e10-0490-4fe0-b961-b77c623364ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "NfeZu-985IRV",
        "outputId": "c587adb0-be64-4154-ae07-d2760c7757c5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b2c1f71e981d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b2c1f71e981d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model with standard ERM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtr_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_exp_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mtr_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train_RDA'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-b9d6cbbce155>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, random_transf)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;31m# build a graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Built'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-10300c810b82>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#for evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-10300c810b82>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(self, images, reuse)\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pool2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.compat.v1' has no attribute 'contrib'"
          ]
        }
      ]
    }
  ]
}