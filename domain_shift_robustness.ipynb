{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "domain_shift_robustness.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saptarshidatta96/MTech_Sem3/blob/main/domain_shift_robustness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0AhMQL3ujEk",
        "outputId": "bc4f70d4-1cca-4383-8dd1-b2641fe85d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.12.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"User Current Version:-\", sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiiuj1boZ6aY",
        "outputId": "39d22c0c-b49e-45ce-b92e-45e4a38fb748"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Current Version:- 3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1akyQFlGurwB",
        "outputId": "5a398519-a5be-4da7-e748-4d1c995fe9f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf"
      ],
      "metadata": {
        "id": "jzYL8jNBhPzl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib import slim"
      ],
      "metadata": {
        "id": "orc7I9m8iDwz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4jGHvyBu9YV",
        "outputId": "22e2d716-1cf7-4490-e955-888a9acf87c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import _pickle as cPickle"
      ],
      "metadata": {
        "id": "ISSqwKuFahEn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import os\n",
        "import sys\n",
        "import struct\n",
        "import numpy as np\n",
        "\n",
        "def read_image(fi):\n",
        "    magic, n, rows, columns = struct.unpack(\">IIII\", fi.read(16))\n",
        "    assert magic == 0x00000803\n",
        "    assert rows == 28\n",
        "    assert columns == 28\n",
        "    rawbuffer = fi.read()\n",
        "    assert len(rawbuffer) == n * rows * columns\n",
        "    rawdata = np.frombuffer(rawbuffer, dtype='>u1', count=n*rows*columns)\n",
        "    return rawdata.reshape(n, rows, columns).astype(np.float32) / 255.0\n",
        "\n",
        "def read_label(fi):\n",
        "    magic, n = struct.unpack(\">II\", fi.read(8))\n",
        "    assert magic == 0x00000801\n",
        "    rawbuffer = fi.read()\n",
        "    assert len(rawbuffer) == n\n",
        "    return np.frombuffer(rawbuffer, dtype='>u1', count=n)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.system('wget -N http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')\n",
        "    os.system('wget -N http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')\n",
        "    os.system('wget -N http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')\n",
        "    os.system('wget -N http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')\n",
        "    \n",
        "    np.savez_compressed(\n",
        "        'mnist',\n",
        "        train_x=read_image(gzip.open('train-images-idx3-ubyte.gz', 'rb')),\n",
        "        train_y=read_label(gzip.open('train-labels-idx1-ubyte.gz', 'rb')),\n",
        "        test_x=read_image(gzip.open('t10k-images-idx3-ubyte.gz', 'rb')),\n",
        "        test_y=read_label(gzip.open('t10k-labels-idx1-ubyte.gz', 'rb'))\n",
        "    )"
      ],
      "metadata": {
        "id": "9fc7b-jb6xdS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = np.load('mnist.npz')\n",
        "\n",
        "print(data['train_x'].shape, data['train_x'].dtype)\n",
        "print(data['train_y'].shape, data['train_y'].dtype)\n",
        "print(data['test_x'].shape, data['test_x'].dtype)\n",
        "print(data['test_y'].shape, data['test_y'].dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbf7RwSI7CGK",
        "outputId": "c741d883-206f-4efe-9c16-b7d822e13e38"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) float32\n",
            "(60000,) uint8\n",
            "(10000, 28, 28) float32\n",
            "(10000,) uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "search ops"
      ],
      "metadata": {
        "id": "KKYjUm2lbVkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "from configparser import *\n",
        "import os\n",
        "\n",
        "import scipy.io\n",
        "import sys\n",
        "import glob\n",
        "from numpy.linalg import norm\n",
        "from scipy import misc\n",
        "import skimage.transform\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "\n",
        "\n",
        "class SearchOps(object):\n",
        "\t\n",
        "\t'''\n",
        "\tClass to handle all the search procedures.\n",
        "\tCurrently implemented: random search and evolution search\n",
        "\t'''\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.transf_ops = TransfOps()\n",
        "\n",
        "\tdef random_search(self, no_iters, string_length, save_file_name, compute_fitness_f, original_images, *args):\n",
        "\n",
        "\t\t'''\n",
        "\t\tSampling random image transformations and testing them on a provided model.\n",
        "\t\tReferring to the paper, this is Algorithm 1.\n",
        "\t\t\n",
        "\t\t\tno_iters: number of iterations.\n",
        "\t\t\tstring_length: number of transformations to be concatenated.\n",
        "\t\t\tsave_file_name: file name used to save .png and .pkl outputs.\n",
        "\t\t\tcompute_fitness_f: test function associated with the desired model.\n",
        "\t\t\toriginal_images: images to give in input to compute_fitness_f.\n",
        "\t\t\targs: other input eventually required by compute_fitness_f (e.g., ground truth labels, sess, etc.)\n",
        "\n",
        "\t\t'''\n",
        "\n",
        "\t\tall_accuracies = []\n",
        "\t\tall_best_accuracies = []\n",
        "\t\tall_transformations = []\n",
        "\t\tall_levels = []\n",
        "\t\tall_images = []\n",
        "\t\tcurrent_minimum = 1.\n",
        "\t\t\n",
        "\t\tnumber_fitness_evals = 0\t\t\n",
        "\t\t\n",
        "\t\tfor t in range(no_iters):\n",
        "\n",
        "\t\t\tif (t%100)==0:\n",
        "\t\t\t\tprint('Iter #',str(t))\n",
        "\n",
        "\t\t\ttr_images, transformations, levels = self.transf_ops.transform_dataset(original_images * 255., transf_string='random_'+str(string_length))\n",
        "\t\t\t\n",
        "\t\t\ttr_images /= 255.\n",
        "\t\t\t\n",
        "\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\ttarget_accuracy = 0\n",
        "\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\tnumber_fitness_evals += 1\n",
        "\n",
        "\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\n",
        "\t\t\tall_accuracies.append(target_accuracy)\n",
        "\n",
        "\t\t\tif target_accuracy < current_minimum:\n",
        "\t\t\t\tprint ('%d Current minimum: [%.4f], # fitness evals: [%d]'%(t, target_accuracy, number_fitness_evals))\n",
        "\t\t\t\tcurrent_minimum=target_accuracy\t\t\t\t\n",
        "\t\t\t\n",
        "\t\t\t\tall_best_accuracies.append(target_accuracy)\n",
        "\t\t\t\tall_transformations.append(transformations)\n",
        "\t\t\t\tall_levels.append(levels)\n",
        "\n",
        "\t\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\t\tall_images.append(conc_images)\n",
        "\n",
        "\n",
        "\t\tprint('Saving output in \"images\" folder')\n",
        "\t\tPIL.Image.fromarray(conc_images.astype('uint8')).save(save_file_name+'_acc_%.3f.png'%(current_minimum))\n",
        "\t\t\t\t\n",
        "\t\twith open(save_file_name+'_acc_%.3f.pkl'%(current_minimum), 'wb') as f:\n",
        "\t\t\tcPickle.dump((all_accuracies, all_best_accuracies, all_transformations, all_levels, number_fitness_evals), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\t\treturn all_best_accuracies[-1], all_transformations[-1].tolist(), all_levels[-1], all_images[-1]\n",
        "\t\t\t\n",
        "\tdef genetic_algorithm(self, no_iters, pop_size, string_length, mutation_rate, save_file_name, compute_fitness_f, original_images, *args):\n",
        "\n",
        "\t\t'''\n",
        "\t\tSampling random image transformations and testing them on a provided model.\n",
        "\t\tReferring to the paper, this is Algorithm 2.\n",
        "\t\t\n",
        "\t\t\tno_iters: number of iterations.\n",
        "\t\t\tstring_length: number of transformations to be concatenated.\n",
        "\t\t\tmutation_rate: a value in [0.0,1.0]\n",
        "\t\t\tsave_file_name: file name used to save .png and .pkl outputs.\n",
        "\t\t\tcompute_fitness_f: test function associated with the desired model.\n",
        "\t\t\toriginal_images: images to give in input to compute_fitness_f.\n",
        "\t\t\targs: other input eventually required by compute_fitness_f (e.g., ground truth labels, sess, etc.)\n",
        "\n",
        "\t\t'''\n",
        "\n",
        "\t\tmin_accuracy = 1.0 # initialized with the maximum value\n",
        "\t\tcurrent_minimum = 1.0 # initialized with the maximum value\n",
        "\n",
        "\t\tnumber_fitness_evals = 0\n",
        "\t\tnumber_fitness_needed = pop_size\n",
        "\n",
        "\t\tpop_accuracies = []\n",
        "\t\tpop_probabilities = []\n",
        "\t\tpop_transformations = []\n",
        "\t\tpop_levels = []\n",
        "\t\tpop_images = []\n",
        "\n",
        "\t\tmin_accs = []\n",
        "\t\tmin_transfs = []\n",
        "\t\tmin_levels = []\n",
        "\t\tmin_images = []\n",
        "\n",
        "\t\tall_fitnesses = []\n",
        "\n",
        "\t\tprint('Initializing population')\n",
        "\t\t\t\n",
        "\t\tfor p in range(pop_size): # number of items in the population\n",
        "\n",
        "\t\t\ttr_images, transformations, levels = self.transf_ops.transform_dataset(original_images * 255., transf_string='random_'+str(string_length))\n",
        "\t\t\ttr_images /= 255.\n",
        "\n",
        "\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\ttarget_accuracy = 0\n",
        "\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\tnumber_fitness_evals += 1\n",
        "\t\t\t\n",
        "\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\n",
        "\t\t\tpop_accuracies.append(target_accuracy)\n",
        "\t\t\tpop_transformations.append(transformations)\n",
        "\t\t\tpop_levels.append(levels)\n",
        "\t\t\t\n",
        "\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\t\t\t\n",
        "\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\tpop_images.append(conc_images)\n",
        "\t\t\t\n",
        "\t\tpop_probabilities = (1. - np.array(pop_accuracies))/np.sum(1. - np.array(pop_accuracies)) \n",
        "\n",
        "\t\tcurrent_minimum = np.min(pop_accuracies)\n",
        "\t\tprint('Current minimum:',str(current_minimum), '# fitness evals', str(number_fitness_evals))\n",
        "\n",
        "\t\tmin_accs.append(current_minimum)\n",
        "\n",
        "\t\tall_fitnesses.append(current_minimum)\n",
        "\t\t\n",
        "\t\tpop_transformations = [arr.tolist() for arr in pop_transformations]\t\t\t\n",
        "\n",
        "\t\tmin_transfs.append(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\tmin_levels.append(pop_levels[np.argmin(pop_accuracies)])\n",
        "\t\tmin_images.append(pop_images[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\tprint('Running evolution search')\n",
        "\n",
        "\t\tfor step in range(no_iters): # number of iters for the evolution search\n",
        "\n",
        "\t\t\tif current_minimum == 0.0:\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\t\tnew_pop_accuracies = []\n",
        "\t\t\tnew_pop_images = []\n",
        "\t\t\tnew_pop_transformations = [None for i in range(pop_size)]\n",
        "\t\t\tnew_pop_levels = [None for i in range(pop_size)]\n",
        "\n",
        "\t\t\tfor p in range(pop_size/2):\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t# randomly choose two parents to be mated <3\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tidx_1 = npr.choice(pop_size, p=pop_probabilities)\n",
        "\t\t\t\tidx_2 = npr.choice(pop_size, p=pop_probabilities)\n",
        "\n",
        "\t\t\t\ttransformations_1 = pop_transformations[idx_1]\n",
        "\t\t\t\ttransformations_2 = pop_transformations[idx_2]\n",
        "\t\t\t\tlevels_1 = pop_levels[idx_1]\n",
        "\t\t\t\tlevels_2 = pop_levels[idx_2]\n",
        "\t\t\t\t\n",
        "\t\t\t\t# cutting transformations/levels on a random point and \n",
        "\t\t\t\t\t\n",
        "\t\t\t\tcrossover_point = npr.randint(string_length)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tnew_transformations_1 = transformations_1[:crossover_point] + transformations_2[crossover_point:]\n",
        "\t\t\t\tnew_levels_1 = levels_1[:crossover_point] + levels_2[crossover_point:]\n",
        "\t\t\t\tnew_transformations_2 = transformations_2[:crossover_point] + transformations_1[crossover_point:]\n",
        "\t\t\t\tnew_levels_2 = levels_2[:crossover_point] + levels_1[crossover_point:]\n",
        "\t\t\t\t\n",
        "\t\t\t\t# adding the new offspring to the new population\t\t\t\t\n",
        "\n",
        "\t\t\t\tnew_pop_transformations[p] = new_transformations_1\n",
        "\t\t\t\tnew_pop_levels[p] = new_levels_1\n",
        "\t\t\t\tnew_pop_transformations[p+pop_size/2] = new_transformations_2\n",
        "\t\t\t\tnew_pop_levels[p+pop_size/2] = new_levels_2\n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t# mutating some genes\n",
        "\t\t\t\t\n",
        "\t\t\tfor i, transformations in enumerate(new_pop_transformations):\n",
        "\t\t\t\tfor j, transf in enumerate(transformations):\n",
        "\t\t\t\t\tif npr.rand() < mutation_rate: \n",
        "\t\t\t\t\t\tnew_pop_transformations[i][j] = npr.choice(self.transf_ops.transformation_list, 1)[0]\n",
        "\t\t\t\t\t\tnew_pop_levels[i][j] = npr.choice(self.transf_ops.code_to_level_dict[new_pop_transformations[i][j]].values(), 1)[0]\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t# computing accuracies (\"fitness\" values)\n",
        "\n",
        "\t\t\tfor transformations, levels in zip(new_pop_transformations, new_pop_levels): \n",
        "\n",
        "\t\t\t\ttr_images, _, _ = self.transf_ops.transform_dataset(original_images * 255., transformations=transformations, levels=levels)\n",
        "\t\t\t\ttr_images /= 255.\n",
        "\t\t\t\t\n",
        "\t\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\t\ttarget_accuracy = 0\n",
        "\t\t\t\ttarget_loss = 0\n",
        "\t\t\t\n",
        "\t\t\t\tnumber_fitness_evals += 1\n",
        "\t\t\t\n",
        "\t\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\t\t\t\t\n",
        "\t\t\t\tnew_pop_accuracies.append(target_accuracy)\n",
        "\n",
        "\n",
        "\t\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\n",
        "\t\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\t\tnew_pop_images.append(conc_images)\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\tpop_transformations = new_pop_transformations\n",
        "\t\t\tpop_levels = new_pop_levels\n",
        "\t\t\tpop_accuracies = new_pop_accuracies\n",
        "\n",
        "\t\t\tpop_images = new_pop_images\n",
        "\t\t\tpop_probabilities = (1. - np.array(pop_accuracies))/np.sum(1. - np.array(pop_accuracies)) \n",
        "\n",
        "\t\t\tif np.min(pop_accuracies) < current_minimum:\n",
        "\t\t\t\tcurrent_minimum = np.min(pop_accuracies)\n",
        "\t\t\t\tprint(str(step), '- Current minimum:', str(current_minimum), '#number fitness evals', str(number_fitness_evals))\n",
        "\t\t\t\tprint(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tprint(pop_levels[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\t\t\tnumber_fitness_needed = number_fitness_evals\n",
        "\n",
        "\t\t\t\tmin_accs.append(current_minimum)\n",
        "\t\t\t\tmin_transfs.append(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tmin_levels.append(pop_levels[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tmin_images.append(pop_images[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\tall_fitnesses.append(current_minimum)\n",
        "\n",
        "\t\tPIL.Image.fromarray(pop_images[np.argmin(pop_accuracies)].astype('uint8')).save(save_file_name+'_acc_%.3f.png'%(current_minimum))\n",
        "\t\t\n",
        "\t\twith open(save_file_name+'_acc_%.3f.pkl'%(current_minimum), 'wb') as f:\n",
        "\t\t\tcPickle.dump((min_accs,min_transfs, min_levels, number_fitness_needed, all_fitnesses), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\t\treturn min_accs[np.argmin(min_accs)], min_transfs[np.argmin(min_accs)], min_levels[np.argmin(min_accs)], min_images[np.argmin(min_accs)]\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    print('...')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjXMPhX3bTl-",
        "outputId": "b2216358-715f-4fed-dfc2-72939e3905bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tranf ops"
      ],
      "metadata": {
        "id": "uESW4nkibRuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import PIL\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageEnhance\n",
        "import PIL.Image\n",
        "import matplotlib\n",
        "\n",
        "class TransfOps(object):\n",
        "\n",
        "\t'''\n",
        "\tClass to handle the decoding of the strings used with the genetic\n",
        "\talgorithm and all the data transformations.\n",
        "\t'''\n",
        "\t\n",
        "\tdef __init__(self):\n",
        "\t\t\t\t\n",
        "\t\tself.transformation_list = ['autocontrast', 'brightness', 'color', 'contrast', 'sharpness', 'solarize', 'grayscale', 'Renhancer', 'Genhancer', 'Benhancer']\n",
        "\t\tself.define_code_correspondances()\n",
        "\t\t\n",
        "\tdef decode_string(self, transf_string):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tCode to decode the string used by the genetic algorithm\n",
        "\t\tString example: 't1,l1_3,t4,l4_0,t0,l0_1'. First transformation is the one \n",
        "\t\tassociated with index '1', with level set to '3', and so on.\n",
        "\t\t'random_N' with N integer gives N rnd transformations with rnd levels.\n",
        "\t\t'''\n",
        "\t\t\n",
        "\t\tif 'random' in transf_string:\n",
        "\t\t\ttransformations = npr.choice(self.transformation_list, int(transf_string.split('_')[-1])) # the string is 'random_N'\n",
        "\t\t\tlevels = [npr.choice(list(self.code_to_level_dict[t].values()), 1)[0] for t in transformations] # list() to make it compatible with Python3\n",
        "\t\telse:\n",
        "\t\t\ttransformation_codes = transf_string.split(',')[0::2] \n",
        "\t\t\tlevel_codes = transf_string.split(',')[1::2]\n",
        "\t\t\t\n",
        "\t\t\ttransformations = [self.code_to_transf(code) for code in transformation_codes] \t\n",
        "\t\t\tlevels = [self.code_to_level(transf,level) for transf,level in zip(transformations, level_codes)] \t\n",
        "\n",
        "\t\treturn transformations, levels\t\t\n",
        "\n",
        "\tdef transform_dataset(self, dataset, transf_string = 't0,l0_0', transformations=None, levels=None):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tdataset: set of images, shape should be N x width x height x #channels\n",
        "\t\ttransf_string: transformations and levels encoded in a string \n",
        "\t\t'''\n",
        "\n",
        "\t\t#print 'Dataset size:',dataset.shape\n",
        "\t\t\n",
        "\t\tif len(dataset.shape) == 3: # if 'dataset' is a single image\n",
        "\t\t\tdataset = np.expand_dims(dataset, 0) \n",
        "\t\t\n",
        "\t\tif dataset.shape[-1] != 3:\n",
        "\t\t\tprint('Input shape:', str(dataset.shape))\n",
        "\t\t\traise Exception('The images must be in RGB format')\n",
        "\n",
        "\t\ttr_dataset = np.zeros((dataset.shape))\n",
        "\t\t\n",
        "\t\tif transformations is None:\n",
        "\t\t\t# decoding transformation string\n",
        "\t\t\ttransformations, levels = self.decode_string(transf_string)\t\n",
        "\t\t\n",
        "\t\tfor n,img in enumerate(dataset):\n",
        "\t\t\tpil_img = PIL.Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "\t\t\tfor transf,level in zip(transformations, levels): \n",
        "\t\t\t\tpil_img = self.apply_transformation(pil_img, transf, level)\n",
        "\t\t\ttr_dataset[n] = np.array(pil_img)\n",
        "\n",
        "\t\treturn tr_dataset, transformations, levels\n",
        "\n",
        "\tdef apply_transformation(self, image, transformation, level):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\timage: image to be tranformed, shape should be 1 x width x height x #channels\n",
        "\t\ttransformation: type of transformation to be applied\n",
        "\t\tlevel: level of the perturbation to be applied \n",
        "\t\t'''\n",
        "\n",
        "\t\tif transformation == 'identity':\n",
        "\t\t\treturn image \n",
        "\n",
        "\t\telif transformation == 'autocontrast':\n",
        "\t\t\treturn PIL.ImageOps.autocontrast(image, cutoff=level)\n",
        "\n",
        "\t\telif transformation == 'brightness':\n",
        "\t\t\treturn PIL.ImageEnhance.Brightness(image).enhance(level)\n",
        "\n",
        "\t\telif transformation == 'color':\n",
        "\t\t\treturn PIL.ImageEnhance.Color(image).enhance(level)\n",
        "\t\t\t\n",
        "\t\telif transformation == 'contrast':\n",
        "\t\t\treturn PIL.ImageEnhance.Contrast(image).enhance(level)\n",
        "\n",
        "\t\telif transformation == 'sharpness':\n",
        "\t\t\treturn PIL.ImageEnhance.Sharpness(image).enhance(level)\n",
        "\t\t\t\n",
        "\t\telif transformation == 'solarize':\n",
        "\t\t\treturn PIL.ImageOps.solarize(image, threshold=level)\n",
        "\n",
        "\t\telif transformation == 'grayscale':\n",
        "\t\t\timage = PIL.ImageOps.grayscale(image).convert('RGB')\n",
        "\t\t\treturn image\t\t\n",
        "\n",
        "\t\telif transformation == 'Renhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,0] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\t\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\t\telif transformation == 'Genhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,1] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\t\telif transformation == 'Benhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,2] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\tdef code_to_transf(self, code):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tTakes in input a code (e.g., 't0', 't1', ...) and gives in output \n",
        "\t\tthe related transformation.\n",
        "\t\t'''\n",
        "\n",
        "\t\treturn self.code_to_transf_dict[code]\n",
        "\n",
        "\n",
        "\tdef code_to_level(self, transformation, code):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tTakes in input a transfotmation (e.g., 'invert', 'colorize', ...) and \n",
        "\t\ta level code (e.g., 'l0_1', 'l1_3', ...) and gives in output the related level.\n",
        "\t\t'''\n",
        "\t\t\n",
        "\t\treturn self.code_to_level_dict[transformation][code]\n",
        "\t\t\t\t\n",
        "\tdef define_code_correspondances(self):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tDefine the correpondances between transformation/level codes\n",
        "\t\tand the actual types and values.\n",
        "\t\t'''\n",
        "\t\t\t\n",
        "\t\tself.code_to_transf_dict = dict()\n",
        "\t\t\n",
        "\t\tself.code_to_transf_dict['t1'] = 'autocontrast'\n",
        "\t\tself.code_to_transf_dict['t2'] = 'brightness'\n",
        "\t\tself.code_to_transf_dict['t3'] = 'color'\n",
        "\t\tself.code_to_transf_dict['t4'] = 'contrast'\n",
        "\t\tself.code_to_transf_dict['t5'] = 'sharpness'\n",
        "\t\tself.code_to_transf_dict['t6'] = 'solarize'\n",
        "\t\tself.code_to_transf_dict['t7'] = 'grayscale'\n",
        "\t\tself.code_to_transf_dict['t8'] = 'Renhancer'\n",
        "\t\tself.code_to_transf_dict['t9'] = 'Genhancer'\n",
        "\t\tself.code_to_transf_dict['t10'] = 'Benhancer'\n",
        "\n",
        "\t\tself.code_to_level_dict = dict()\n",
        "\t\t\n",
        "\t\tfor k in self.transformation_list:\n",
        "\t\t\tself.code_to_level_dict[k] = dict()\n",
        "\t\t\t\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['autocontrast'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.0,0.3,20)):\n",
        "\t\t\tself.code_to_level_dict['autocontrast']['l1_'+str(n)] = l\n",
        "\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['brightness'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['brightness']['l2_'+str(n)] = l\n",
        "\t\t\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['color'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['color']['l3_'+str(n)] = l\n",
        "\t\t\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['contrast'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['contrast']['l4_'+str(n)] = l\n",
        "\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['sharpness'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['sharpness']['l5_'+str(n)] = l\n",
        "\t\t\n",
        "\t\tself.code_to_level_dict['solarize'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0,20,20).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['solarize']['l6_'+str(n)] = l\n",
        "\n",
        "\t\tself.code_to_level_dict['grayscale']['l7_0'] = None\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Renhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Renhancer']['l8_'+str(n)] = l\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Genhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Genhancer']['l9_'+str(n)] = l\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Benhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Benhancer']['l10_'+str(n)] = l\n",
        "\n",
        "if __name__=='__main__':\n",
        "\tpass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ofPhxacqbHjM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "from configparser import *\n",
        "import os\n",
        "#import cPickle\n",
        "import scipy.io\n",
        "import sys\n",
        "import glob\n",
        "from numpy.linalg import norm\n",
        "from scipy import misc\n",
        "import skimage.transform\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "sys.path.insert(0,'../')\n",
        "\n",
        "\n",
        "class TrainOps(object):\n",
        "\n",
        "\tdef __init__(self, model, exp_dir):\n",
        "\n",
        "\t\tself.model = model\n",
        "\t\tself.exp_dir = exp_dir\n",
        "\n",
        "\t\tself.config = tf.ConfigProto()\n",
        "\t\tself.config.gpu_options.allow_growth=False\n",
        "\n",
        "\t\tself.data_dir = './data'\n",
        "\n",
        "\tdef load_exp_config(self):\n",
        "\n",
        "\t\tprint(self.exp_dir)\n",
        "\n",
        "\t\tconfig = ConfigParser()\n",
        "\n",
        "\t\tprint('LOADING CONFIG FILE')\n",
        "\t\tconfig.read(os.path.join(self.exp_dir,'exp_config'))\n",
        "\t\tself.source_dataset = config.get('EXPERIMENT_SETTINGS', 'source_dataset')\n",
        "\n",
        "\t\tself.model.source_dataset = self.source_dataset\n",
        "\t\t\t\n",
        "\t\tself.model.no_classes = 10\n",
        "\t\tself.model.img_size = 32\n",
        "\n",
        "\t\tself.log_dir = os.path.join(self.exp_dir,'logs')\n",
        "\t\tself.model_save_path = os.path.join(self.exp_dir,'model')\n",
        "\t\tself.images_dir = os.path.join(self.exp_dir,'images')\n",
        "\n",
        "\t\tif not os.path.exists(self.log_dir):\n",
        "\t\t\tos.makedirs(self.log_dir)\n",
        "\n",
        "\t\tif not os.path.exists(self.model_save_path):\n",
        "\t\t\tos.makedirs(self.model_save_path)\n",
        "\n",
        "\t\tif not os.path.exists(os.path.join(self.images_dir)):\n",
        "\t\t\tos.makedirs(os.path.join(self.images_dir))\n",
        "\n",
        "\n",
        "\t\tself.train_iters = config.getint('MAIN_SETTINGS', 'train_iters')\n",
        "\t\tself.batch_size = config.getint('MAIN_SETTINGS', 'batch_size')\n",
        "\t\tself.model.batch_size = self.batch_size\n",
        "\t\tself.model.learning_rate = config.getfloat('MAIN_SETTINGS', 'learning_rate')\n",
        "\n",
        "\t\tself.transf_string = config.get('MAIN_SETTINGS', 'transf_string')\n",
        "\t\tself.sub_train_iters = config.getint('MAIN_SETTINGS', 'sub_train_iters')\n",
        "\t\tself.string_length = config.getint('MAIN_SETTINGS', 'string_length')\n",
        "\n",
        "\t\tself.transf_ops = TransfOps()\n",
        "\t\tself.search_ops = SearchOps()\n",
        "\n",
        "\tdef load_svhn(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading SVHN dataset.')\n",
        "\n",
        "\t\timage_file = 'train_32x32.mat' if split=='train' else 'test_32x32.mat'\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir, 'svhn', image_file)\n",
        "\t\tsvhn = scipy.io.loadmat(image_dir)\n",
        "\t\timages = np.transpose(svhn['X'], [3, 0, 1, 2])\n",
        "\t\tlabels = svhn['y'].reshape(-1)\n",
        "\t\tlabels[np.where(labels==10)] = 0\n",
        "\t\timages = images/255.\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_mnist(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading MNIST dataset.')\n",
        "\t\timage_file = 'train.pkl' if split=='train' else 'test.pkl'\n",
        "\t\timage_dir = os.path.join(self.data_dir, 'mnist', image_file)\n",
        "\t\twith open(image_dir, 'rb') as f:\n",
        "\t\t\tmnist = cPickle.load(f)\n",
        "\t\t\n",
        "\t\timages = mnist['X'] \n",
        "\t\tlabels = mnist['y']\n",
        "\n",
        "\t\timages = images\n",
        "\t\timages = images/255. # better generalization performance if [0,1]\n",
        "\n",
        "\t\timages = np.stack((images,images,images), axis=3) # grayscale to rgb\n",
        "\n",
        "\t\treturn np.squeeze(images), labels\n",
        "\n",
        "\tdef load_mnist_m(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading MNIST_M dataset.')\n",
        "\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir,'mnist_m')\n",
        "\n",
        "\t\tif split == 'train':\n",
        "\t\t\tdata_dir = os.path.join(image_dir,'mnist_m_train')\n",
        "\t\t\twith open(os.path.join(image_dir,'mnist_m_train_labels.txt')) as f:\n",
        "\t\t\t\tcontent = f.readlines()\n",
        "\t\t\t\t\n",
        "\t\telif split == 'test':\n",
        "\t\t\tdata_dir = os.path.join(image_dir,'mnist_m_test')\n",
        "\t\t\twith open(os.path.join(image_dir,'mnist_m_test_labels.txt')) as f:\n",
        "\t\t\t\tcontent = f.readlines()\n",
        "\n",
        "\n",
        "\t\tcontent = [c.split('\\n')[0] for c in content]\n",
        "\t\timages_files = [c.split(' ')[0] for c in content]\n",
        "\t\tlabels = np.array([int(c.split(' ')[1]) for c in content]).reshape(-1)\n",
        "\n",
        "\t\timages = np.zeros((len(labels), 32, 32, 3))\n",
        "\n",
        "\t\tfor no_img,img in enumerate(images_files):\n",
        "\t\t\timg_dir = os.path.join(data_dir, img)\n",
        "\t\t\tim = misc.imread(img_dir)\n",
        "\t\t\tim = np.expand_dims(im, axis=0)\n",
        "\t\t\timages[no_img] = im\n",
        "\n",
        "\t\timages = images \n",
        "\t\timages = images/255.\n",
        "\t\t\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_syn(self, split='train'):\n",
        "\t\tprint ('Loading SYN dataset.')\n",
        "\n",
        "\t\timage_file = 'synth_train_32x32.mat' if split=='train' else 'synth_test_32x32.mat'\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir,'syn', image_file)\n",
        "\t\tsyn = scipy.io.loadmat(image_dir)\n",
        "\t\timages = np.transpose(syn['X'], [3, 0, 1, 2])\n",
        "\t\tlabels = syn['y'].reshape(-1)\n",
        "\t\tlabels[np.where(labels==10)] = 0\n",
        "\t\t\n",
        "\t\timages = images/255.\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_usps(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading USPS dataset.')\n",
        "\t\timage_file = 'usps_32x32.pkl'\n",
        "\t\timage_dir = os.path.join(self.data_dir,'usps', image_file)\n",
        "\t\t\n",
        "\t\twith open(image_dir, 'rb') as f:\n",
        "\t\t\tusps = cPickle.load(f)\n",
        "\t\t\n",
        "\t\timages = usps['X']\n",
        "\t\tlabels = usps['y']\n",
        "\t\tlabels -= 1\n",
        "\t\tlabels[labels==255] = 9\n",
        "\n",
        "\t\timages=np.squeeze(images)\n",
        "\t\timages = np.stack((images,images,images), axis=3) # grayscale to rgb\n",
        "\t\timages = images/255.\n",
        "\n",
        "\t\tif split == 'train':\n",
        "\t\t\treturn images[:6562], np.squeeze(labels[:6562]).astype(int)\n",
        "\t\telif split == 'validation':\n",
        "\t\t\treturn images[6562:7291], np.squeeze(labels[6562:7291]).astype(int)\n",
        "\t\telif split == 'test':\t    \n",
        "\t\t\treturn images[7291:], np.squeeze(labels[7291:]).astype(int)\n",
        "\t\n",
        "\tdef load_test_data(self, target):\n",
        "\n",
        "\t\tif target=='mnist_m':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_mnist_m(split='test')\n",
        "\t\telif target=='svhn':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_svhn(split='test')\n",
        "\t\telif target=='syn':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_syn(split='test')\n",
        "\t\telif target=='usps':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_usps(split='test')\n",
        "\t\telif target=='mnist':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\treturn self.target_test_images,self.target_test_labels\n",
        "\n",
        "\tdef train(self, random_transf=False): \n",
        "\n",
        "\t\t'''\n",
        "\t\tThis method allows to train ERM and RDA models.\n",
        "\t\t\n",
        "\t\t\trandom_transf: if set to True, RDA is used, o.w. ERM.\n",
        "\t\t\n",
        "\t\tThe number of transformations to be concatenated needs be to\n",
        "\t\tset in the file exp_config.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tprint('Loading data')\n",
        "\n",
        "\t\tsource_train_images, source_train_labels = self.load_mnist(split='train')\n",
        "\t\ttarget_test_images, target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\twith tf.Session(config=self.config) as sess:\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n",
        "\n",
        "\t\t\tprint('Training')\n",
        "\t\t\t\n",
        "\t\t\tfor t in range(self.train_iters):\n",
        "\n",
        "\t\t\t\ti = t % int(source_train_images.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\t\t#current batch of images and labels\n",
        "\t\t\t\tbatch_images = source_train_images[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\t\t\t\tbatch_labels = source_train_labels[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\n",
        "\t\t\t\tif random_transf:\n",
        "\t\t\t\t\tbatch_images, _, _ = self.transf_ops.transform_dataset(batch_images * 255., transf_string = self.transf_string)\n",
        "\t\t\t\t\tbatch_images /= 255.\n",
        "\t\t\t\t\n",
        "\t\t\t\tfeed_dict = {self.model.images: batch_images, self.model.labels: batch_labels} \n",
        "\n",
        "\t\t\t\t#running a step of gradient descent\n",
        "\t\t\t\tsess.run([self.model.min_train_op, self.model.min_loss], feed_dict) \n",
        "\n",
        "\t\t\t\t#evaluating the model\n",
        "\t\t\t\tif t % 2500 == 0:\n",
        "\n",
        "\t\t\t\t\tsummary, min_l, acc = sess.run([self.model.summary_op, self.model.min_loss, self.model.accuracy], feed_dict)\n",
        "\n",
        "\t\t\t\t\ttrain_rand_idxs = np.random.permutation(source_train_images.shape[0])[:100]\n",
        "\t\t\t\t\ttest_rand_idxs = np.random.permutation(target_test_images.shape[0])[:100]\n",
        "\n",
        "\t\t\t\t\ttrain_acc, train_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: source_train_images[train_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: source_train_labels[train_rand_idxs]})\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\ttest_acc, test_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: target_test_images[test_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: target_test_labels[test_rand_idxs]})\n",
        "\t\t\t\t\t  \n",
        "\t\t\t\t\tsummary_writer.add_summary(summary, t)\n",
        "\t\t\t\t\tprint ('Step: [%d/%d] train_min_loss: [%.4f] train_acc: [%.4f] test_min_loss: [%.4f] test_acc: [%.4f]'%(t+1, self.train_iters, train_min_loss, train_acc, test_min_loss, test_acc))\n",
        "\t\t\t\n",
        "\t\t\t\tif t % 10000 == 0:\n",
        "\t\t\t\t\tprint('Saving')\n",
        "\t\t\t\t\tsaver.save(sess, os.path.join(self.model_save_path, 'encoder'))\n",
        "\n",
        "\tdef train_search(self, search_algorithm='random_search'): \n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tThis method allows to train models using RSDA and ESDA algorithms.\n",
        "\t\tReferring to the paper, this is Algorithm 3.\n",
        "\n",
        "\t\t\tsearch_algorithm: 'random_search' or 'evolution_search', \n",
        "\t\t\t\t\t\t\t  accordingly to the desired search procedure.\n",
        "\n",
        "\t\tThe number of transformations to be concatenated needs be to\n",
        "\t\tset in the file exp_config.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tprint('Loading data')\n",
        "\n",
        "\t\tsource_train_images, source_train_labels = self.load_mnist(split='train')\n",
        "\t\ttarget_test_images, target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\t# initializing the set of data augmentation rules.\n",
        "\n",
        "\t\ttransformations = [['identity']]\n",
        "\t\tlevels = [[None]]\t\t\n",
        "\n",
        "\t\twith tf.Session(config=self.config) as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n",
        "\n",
        "\t\t\tprint('Training')\n",
        "\t\t\t\n",
        "\t\t\tfor t in range(self.train_iters):\n",
        "\n",
        "\t\t\t\ti = t % int(source_train_images.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\t\t# current batch of images and labels\n",
        "\t\t\t\tbatch_images = source_train_images[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\t\t\t\tbatch_labels = source_train_labels[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\n",
        "\t\t\t\t# sampling uniformly a transformation and its level, and applying it to the batch\n",
        "\t\t\t\trnd_transf_idx = npr.randint(len(transformations))\n",
        "\t\t\t\t\n",
        "\t\t\t\tif transformations[rnd_transf_idx] == ['identity']: # do nothing for 'identity', namely use original images\n",
        "\t\t\t\t\tpass\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t# TransfOps requires [0,255] pixel ranges, while here images [0,1]\n",
        "\t\t\t\t\tbatch_images, _, _ = self.transf_ops.transform_dataset(batch_images * 255., transformations=transformations[rnd_transf_idx], levels=levels[rnd_transf_idx])\n",
        "\t\t\t\t\tbatch_images /= 255.\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t# running a step of gradient descent\n",
        "\t\t\t\tfeed_dict = {self.model.images: batch_images, self.model.labels: batch_labels} \n",
        "\t\t\t\tsess.run([self.model.min_train_op, self.model.min_loss], feed_dict) \n",
        "\n",
        "\t\t\t\t#evaluating the model\n",
        "\t\t\t\tif t % 2500 == 0:\n",
        "\n",
        "\t\t\t\t\tsummary, min_l, acc = sess.run([self.model.summary_op, self.model.min_loss, self.model.accuracy], feed_dict)\n",
        "\n",
        "\t\t\t\t\ttrain_rand_idxs = np.random.permutation(source_train_images.shape[0])[:100]\n",
        "\t\t\t\t\ttest_rand_idxs = np.random.permutation(target_test_images.shape[0])[:100]\n",
        "\n",
        "\t\t\t\t\ttrain_acc, train_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: source_train_images[train_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: source_train_labels[train_rand_idxs]})\n",
        "\t\t\t\t\ttest_acc, test_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: target_test_images[test_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: target_test_labels[test_rand_idxs]})\n",
        "\t\t\t\t\t  \n",
        "\t\t\t\t\tsummary_writer.add_summary(summary, t)\n",
        "\t\t\t\t\tprint('Step: [%d/%d] train_min_loss: [%.4f] train_acc: [%.4f] test_min_loss: [%.4f] test_acc: [%.4f]'%(t+1, self.train_iters, train_min_loss, train_acc, test_min_loss, test_acc))\n",
        "\n",
        "\t\t\t\tif (t+1)%self.sub_train_iters == 0:\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif search_algorithm == 'random_search':\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tprint('\\n\\nRunning Random Search')\n",
        "\t\t\t\t\t\tsave_file_name=os.path.join(self.images_dir,'Random_string_length_'+str(self.string_length)+'_iter_'+str(t+1))\n",
        "\t\t\t\t\t\tmin_tr_accuracy, _transformations, _levels, _image = self.search_ops.random_search(100, self.string_length, save_file_name,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.test, source_train_images[:1000],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_train_labels[:1000], sess) \n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\telif search_algorithm == 'evolution_search':\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tprint('\\n\\nRunning Evolution Search')\n",
        "\t\t\t\t\t\tsave_file_name=os.path.join(self.images_dir,'Evolution_string_length_'+str(self.string_length)+'_iter_'+str(t+1))\n",
        "\t\t\t\t\t\tmin_tr_accuracy, _transformations, _levels, _image = self.search_ops.genetic_algorithm(10, 10, self.string_length, 0.1,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsave_file_name, self.test, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_train_images[:1000],\tsource_train_labels[:1000], sess) \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\ttransformations.append(_transformations)\n",
        "\t\t\t\t\tlevels.append(_levels)\n",
        "\n",
        "\t\t\t\t\tprint('Target accuracy: [%.4f]'%(min_tr_accuracy))\n",
        "\t\t\t\t\tprint('_'.join(_transformations))\n",
        "\t\t\t\t\tprint('\\n\\n')\t\t\n",
        "\n",
        "\t\t\t\tif (t+1) % 25000 == 0:\n",
        "\t\t\t\t\tprint('Saving')\n",
        "\t\t\t\t\tsaver.save(sess, os.path.join(self.model_save_path, 'encoder'))\n",
        "\n",
        "\n",
        "\tdef test(self, images, labels, sess):\n",
        "\n",
        "\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\ttarget_accuracy = 0\n",
        "\t\ttarget_loss = 0\n",
        "\t\tpreds = []\n",
        "\n",
        "\t\tfor test_images_batch, test_labels_batch in zip(np.array_split(images, N), np.array_split(labels, N)):\n",
        "\t\t\tfeed_dict = {self.model.images: test_images_batch, self.model.labels: test_labels_batch} \n",
        "\t\t\ttarget_accuracy_tmp, target_loss_tmp, pred = sess.run([self.model.accuracy, self.model.min_loss, self.model.pred], feed_dict) \n",
        "\t\t\ttarget_accuracy += target_accuracy_tmp/float(N)\n",
        "\t\t\ttarget_loss += target_loss_tmp/float(N)\n",
        "\t\t\tpreds.append(pred.tolist())\n",
        "\n",
        "\t\tcorrect_guesses = (np.array(preds)==labels).astype(int)[0]\n",
        "\t\t\n",
        "\t\treturn target_accuracy, correct_guesses\n",
        "\t\n",
        "\tdef test_all(self):\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tres_dict = dict()\n",
        "\t\tres_dict['exp_dir'] = self.exp_dir\n",
        "\n",
        "\t\tprint('Testing ALL')\n",
        "\n",
        "\t\ttargets = ['mnist', 'svhn']# add 'usps', 'syn', 'mnist_m'\n",
        "\n",
        "\t\tfor target in targets:\n",
        "\n",
        "\t\t\tprint('\\n\\n\\n...........................................................................')\n",
        "\n",
        "\t\t\ttest_images, test_labels = self.load_test_data(target=target)\n",
        "\n",
        "\t\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\t\tprint('...........................................................................')\n",
        "\n",
        "\t\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\t\tprint('Loading pre-trained model.')\n",
        "\t\t\t\tvariables_to_restore = slim.get_model_variables()\n",
        "\t\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\t\t\t\t\n",
        "\t\t\t\tN = 100\n",
        "\t\t\t\ttarget_accuracy = 0\n",
        "\t\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\t\tprint('Calculating accuracy')\n",
        "\n",
        "\t\t\t\tfor test_images_batch, test_labels_batch in zip(np.array_split(test_images, N), np.array_split(test_labels, N)):\n",
        "\t\t\t\t\tfeed_dict = {self.model.images: test_images_batch, self.model.labels: test_labels_batch} \n",
        "\t\t\t\t\ttarget_accuracy_tmp, target_loss_tmp, target_pred = sess.run([self.model.accuracy, self.model.min_loss, self.model.pred], feed_dict) \n",
        "\t\t\t\t\ttarget_accuracy += target_accuracy_tmp/float(N)\n",
        "\t\t\t\t\ttarget_loss += target_loss_tmp/float(N)\n",
        "\n",
        "\t\t\tprint('Target accuracy: [%.4f] target loss: [%.4f]'%(target_accuracy, target_loss))\n",
        "\n",
        "\t\t\tres_dict[target] = target_accuracy\n",
        "\n",
        "\t\twith open(os.path.join(self.exp_dir, 'domain_generalization_performance.pkl'), 'w') as f:\n",
        "\t\t\tcPickle.dump(res_dict, f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "\tdef test_random_search(self, run, seed, no_iters, string_length):\n",
        "\n",
        "\t\ttest_images, test_labels = self.load_test_data(target='mnist')\n",
        "\t\t\n",
        "\t\tnpr.seed(213)\n",
        "\t\trnd_idx = range(len(test_images))\n",
        "\t\tnpr.shuffle(rnd_idx)\t\t\n",
        "\n",
        "\t\ttest_images = test_images[rnd_idx]\n",
        "\t\ttest_labels = test_labels[rnd_idx]\n",
        "\n",
        "\t\ttest_images = test_images[:1000]\n",
        "\t\ttest_labels = test_labels[:1000]\n",
        "\n",
        "\t\tnpr.seed(seed)\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.mode='train_encoder'\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tprint ('Loading pre-trained model.')\n",
        "\t\t\tvariables_to_restore = slim.get_model_variables(scope='encoder')\n",
        "\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\n",
        "\t\t\tif not os.path.exists(os.path.join(self.exp_dir,'images')):\n",
        "\t\t\t\tos.makedirs(os.path.join(self.exp_dir,'images'))\n",
        "\n",
        "\t\t\t# perform random search\n",
        "\t\t\t\n",
        "\t\t\tsave_search_file_name=os.path.join(self.images_dir,'TEST_Random_test_string_length_'+str(string_length))\n",
        "\n",
        "\t\t\tall_accuracies, all_transformations, all_levels, all_images = self.search_ops.random_search(5000, string_length, save_search_file_name,\tself.test, test_images, test_labels, sess) \n",
        "\t\t\t# save output\n",
        "\n",
        "\t\t\twith open(os.path.join(self.exp_dir, 'worst_case_accuracies.pkl'), 'w') as f:\n",
        "\t\t\t\tcPickle.dump((all_accuracies, all_transformations, all_levels), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\tdef test_evolution_search(self, run='0', seed=123, no_iters=100, string_length=3, pop_size=10, mutation_rate=0.1):\n",
        "\n",
        "\t\ttest_images, test_labels = self.load_mnist(split='test')\n",
        "\t\t\n",
        "\t\tnpr.seed(213)\n",
        "\t\trnd_idx = range(len(test_images))\n",
        "\t\tnpr.shuffle(rnd_idx)\t\t\n",
        "\n",
        "\t\ttest_images = test_images[rnd_idx]\n",
        "\t\ttest_labels = test_labels[rnd_idx]\n",
        "\n",
        "\t\ttest_images = test_images[:1000]\n",
        "\t\ttest_labels = test_labels[:1000]\n",
        "\n",
        "\t\tnpr.seed(seed)\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.mode='train_encoder'\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tprint ('Loading pre-trained model.')\n",
        "\t\t\tvariables_to_restore = slim.get_model_variables()\n",
        "\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\n",
        "\t\t\tif not os.path.exists(os.path.join(self.exp_dir,'GA_images')):\n",
        "\t\t\t\tos.makedirs(os.path.join(self.exp_dir,'GA_images'))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\tsave_search_file_name=os.path.join(self.images_dir,'TEST_Evolution_test_string_length_'+str(string_length))\n",
        "\n",
        "\t\t\tself.search_ops.genetic_algorithm(100, pop_size, string_length, mutation_rate, save_search_file_name, self.test, test_images, test_labels, sess)\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    print('...')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqJtmrzJVslw",
        "outputId": "45afcd2e-3f0d-426e-f01a-6caf662a10fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "    \n",
        "    def __init__(self, mode='train'):\n",
        "\n",
        "        self.no_classes = 10\n",
        "        self.img_size = 32\n",
        "        self.no_channels = 3\n",
        "\n",
        "    def encoder(self, images, reuse=False):\n",
        "\n",
        "        with tf.variable_scope('encoder', reuse=reuse):\n",
        "            with slim.arg_scope([slim.fully_connected], activation_fn=tf.nn.relu):\n",
        "                with slim.arg_scope([slim.conv2d], activation_fn=tf.nn.relu, padding='VALID'):\n",
        "\n",
        "                    net = slim.conv2d(images, 64, 5, scope='conv1')\n",
        "                    net = slim.max_pool2d(net, 2, stride=2, scope='pool1')\n",
        "                    net = slim.conv2d(net, 128, 5, scope='conv2')\n",
        "                    net = slim.max_pool2d(net, 2, stride=2, scope='pool2')\n",
        "                    net = tf.contrib.layers.flatten(net)\n",
        "                    net = slim.fully_connected(net, 1024, scope='fc1')\n",
        "                    net = slim.fully_connected(net, 1024, scope='fc2')\n",
        "                    net = slim.fully_connected(net, self.no_classes, activation_fn=None, scope='fco')\n",
        "                    \n",
        "                    return net\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        # images placeholder\n",
        "        self.images = tf.placeholder(tf.float32, [None, self.img_size, self.img_size, self.no_channels], 'images')\n",
        "        # labels placeholder\n",
        "        self.labels = tf.placeholder(tf.int64, [None], 'labels')\n",
        "                \n",
        "        self.logits = tf.squeeze(self.encoder(self.images))\n",
        "\n",
        "        #for evaluation\n",
        "        self.pred = tf.argmax(self.logits, 1)\n",
        "        self.correct_pred = tf.equal(self.pred, self.labels)\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
        "\n",
        "        #variables for the minimizer are the net weights, variables for the maxmizer are the images' pixels\n",
        "        min_vars = tf.trainable_variables()\n",
        "                \n",
        "        #loss for the minimizer\n",
        "        self.min_loss = slim.losses.sparse_softmax_cross_entropy(self.logits, self.labels)\n",
        "\n",
        "        #we use Adam for the minimizer and vanilla gradient ascent for the maximizer \n",
        "        self.min_optimizer = tf.train.AdamOptimizer(self.learning_rate) \n",
        "\n",
        "        #minimizer\n",
        "        self.min_train_op = slim.learning.create_train_op(self.min_loss, self.min_optimizer, variables_to_train = min_vars)\n",
        "\n",
        "        min_loss_summary = tf.summary.scalar('min_loss', self.min_loss)\n",
        "\n",
        "        accuracy_summary = tf.summary.scalar('accuracy', self.accuracy)\n",
        "        self.summary_op = tf.summary.merge([min_loss_summary, accuracy_summary])\t\t\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N-KLrXpcAKqr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.py"
      ],
      "metadata": {
        "id": "pYq44fphcnvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy.random as npr\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('gpu', '0', \"GPU to used\")\n",
        "flags.DEFINE_string('exp_dir', 'exp_dir', \"Experiment directory\")\n",
        "flags.DEFINE_string('mode', 'mode', \"Experiment directory\")\n",
        "flags.DEFINE_string('run', '0', \"Experiment run\")\n",
        "flags.DEFINE_string('seed', '123', \"Random seed\")\n",
        "\n",
        "flags.DEFINE_string('transf_string_length', '5', \"Number of transformations to be concatenated\")\n",
        "\n",
        "flags.DEFINE_string('search_no_iters', '100', \"Number of search iterations\")\n",
        "flags.DEFINE_string('pop_size', '10', \"Number of individuals in the population -- for evolution search\")\n",
        "flags.DEFINE_string('mutation_rate', '0.1', \"Mutation rate -- for evolution search\")\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "def main(_):\n",
        "\n",
        "\t#npr.seed(int(FLAGS.seed))\n",
        "\n",
        "\tGPU_ID = FLAGS.gpu\n",
        "\tos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152 on stackoverflow\n",
        "\tos.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_ID)\n",
        "\n",
        "\tEXP_DIR = FLAGS.exp_dir\n",
        "\n",
        "\tmodel = Model()\n",
        "\ttr_ops = TrainOps(model, EXP_DIR)\n",
        "\n",
        "\tif 'train' in FLAGS.mode:\n",
        "\t\tnpr.seed(int(FLAGS.seed))\n",
        "\n",
        "\t\n",
        "\tif FLAGS.mode=='train_ERM':\n",
        "\t\tprint('Training model with standard ERM')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train()      \n",
        "\t\t\n",
        "\tif FLAGS.mode=='train_RDA':\n",
        "\t\tprint('Training model with RDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train(random_transf=True)\n",
        "\t\t\n",
        "\tif FLAGS.mode=='train_RSDA':\n",
        "\t\tprint('Training model with RSDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train_search(search_algorithm='random_search')\n",
        "\t\t\n",
        "\tif FLAGS.mode=='train_ESDA':\n",
        "\t\tprint('Training model with ESDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train_search(search_algorithm='evolution_search')\n",
        "\n",
        "\t\t\n",
        "\telif FLAGS.mode=='test_all':\n",
        "\t\tprint('Testing all')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_all()\n",
        "\n",
        "\telif FLAGS.mode=='test_RS':\n",
        "\t\tprint('Random search')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_random_search(run=str(FLAGS.run), seed=int(FLAGS.seed), no_iters=int(FLAGS.search_no_iters), string_length=int(FLAGS.transf_string_length)) \n",
        "\n",
        "\telif FLAGS.mode=='test_ES':\n",
        "\t\tprint('Evolution search')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_evolution_search(run=str(FLAGS.run), seed=int(FLAGS.seed), no_iters=int(FLAGS.search_no_iters),string_length=int(FLAGS.transf_string_length), \n",
        "\t\t\t\t\t\t\t\t\t\tpop_size=int(FLAGS.pop_size), mutation_rate=float(FLAGS.mutation_rate))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttf.app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "esz-jEkt_1hs",
        "outputId": "c8d9bdaa-c694-4e7c-e532-b66349127f7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DuplicateFlagError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b15d67794083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GPU to used\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exp_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exp_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Experiment directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Experiment directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Experiment run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/platform/flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;34m'Use of the keyword argument names (flag_name, default_value, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           'docstring) is deprecated, please use (name, default, help) instead.')\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_string\u001b[0;34m(name, default, help, flag_values, required, **args)\u001b[0m\n\u001b[1;32m    292\u001b[0m       \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mrequired\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequired\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m       **args)\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[0;34m(parser, name, default, help, flag_values, serializer, module_name, required, **args)\u001b[0m\n\u001b[1;32m    104\u001b[0m   return DEFINE_flag(\n\u001b[1;32m    105\u001b[0m       \u001b[0m_flag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       module_name, required)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name, required)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'exp_dir' is defined twice. First from /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py.  Description from first occurrence: Experiment directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "LNTEhAdVchGF",
        "outputId": "b7fa1bdd-c3d6-4bb2-d890-8e4ebf4139f1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-73447179de55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: "
          ]
        }
      ]
    }
  ]
}