{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "domain_shift_robustness.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saptarshidatta96/MTech_Sem3/blob/main/domain_shift_robustness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0AhMQL3ujEk",
        "outputId": "1ae557f9-ca2e-4680-8954-b83984a71015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.12.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"User Current Version:-\", sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiiuj1boZ6aY",
        "outputId": "5db22312-9a4a-411b-ef1c-6a05c7d51be6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Current Version:- 3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1akyQFlGurwB",
        "outputId": "47e706cf-5cdf-453c-a292-4d4cda58f30b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "jzYL8jNBhPzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4d596c-54b5-4228-e387-3ceaa8a25ea3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib import slim"
      ],
      "metadata": {
        "id": "orc7I9m8iDwz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import _pickle as cPickle"
      ],
      "metadata": {
        "id": "ISSqwKuFahEn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def resize_images(image_arrays, size=[32,32]):\n",
        "    image_arrays = (image_arrays * 255).astype('uint8')\n",
        "    \n",
        "    resized_image_arrays = np.zeros([image_arrays.shape[0]]+size)\n",
        "    for i, image_array in enumerate(image_arrays):\n",
        "        image = Image.fromarray(image_array)\n",
        "        resized_image = image.resize(size=size, resample=Image.ANTIALIAS)\n",
        "        \n",
        "        resized_image_arrays[i] = np.asarray(resized_image)\n",
        "    \n",
        "    return np.expand_dims(resized_image_arrays, 3)  \n",
        "\n",
        "def download_and_process_mnist():\n",
        "    \n",
        "    \n",
        "    if not os.path.exists('./data/mnist'):\n",
        "      os.makedirs('./data/mnist')\n",
        "    \n",
        "    mnist = input_data.read_data_sets(train_dir='./data/mnist')\n",
        "\n",
        "    train = {'X': resize_images(mnist.train.images.reshape(-1, 28, 28)),\n",
        "             'y': mnist.train.labels}\n",
        "    \n",
        "    test = {'X': resize_images(mnist.test.images.reshape(-1, 28, 28)),\n",
        "            'y': mnist.test.labels}\n",
        "        \n",
        "    with open('./data/mnist/train.pkl','wb') as f:\n",
        "      cPickle.dump(train,f)\n",
        "    \n",
        "    with open('./data/mnist/test.pkl','wb') as f:\n",
        "      cPickle.dump(test,f)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    download_and_process_mnist()\n",
        "    \n"
      ],
      "metadata": {
        "id": "9fc7b-jb6xdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f873a10f-ec53-432e-b395-e5513a047d00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-8ea67d6d525b>:27: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "search ops"
      ],
      "metadata": {
        "id": "KKYjUm2lbVkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "from configparser import *\n",
        "import os\n",
        "\n",
        "import scipy.io\n",
        "import sys\n",
        "import glob\n",
        "from numpy.linalg import norm\n",
        "from scipy import misc\n",
        "import skimage.transform\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "\n",
        "\n",
        "class SearchOps(object):\n",
        "\t\n",
        "\t'''\n",
        "\tClass to handle all the search procedures.\n",
        "\tCurrently implemented: random search and evolution search\n",
        "\t'''\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.transf_ops = TransfOps()\n",
        "\n",
        "\tdef random_search(self, no_iters, string_length, save_file_name, compute_fitness_f, original_images, *args):\n",
        "\n",
        "\t\t'''\n",
        "\t\tSampling random image transformations and testing them on a provided model.\n",
        "\t\tReferring to the paper, this is Algorithm 1.\n",
        "\t\t\n",
        "\t\t\tno_iters: number of iterations.\n",
        "\t\t\tstring_length: number of transformations to be concatenated.\n",
        "\t\t\tsave_file_name: file name used to save .png and .pkl outputs.\n",
        "\t\t\tcompute_fitness_f: test function associated with the desired model.\n",
        "\t\t\toriginal_images: images to give in input to compute_fitness_f.\n",
        "\t\t\targs: other input eventually required by compute_fitness_f (e.g., ground truth labels, sess, etc.)\n",
        "\n",
        "\t\t'''\n",
        "\n",
        "\t\tall_accuracies = []\n",
        "\t\tall_best_accuracies = []\n",
        "\t\tall_transformations = []\n",
        "\t\tall_levels = []\n",
        "\t\tall_images = []\n",
        "\t\tcurrent_minimum = 1.\n",
        "\t\t\n",
        "\t\tnumber_fitness_evals = 0\t\t\n",
        "\t\t\n",
        "\t\tfor t in range(no_iters):\n",
        "\n",
        "\t\t\tif (t%100)==0:\n",
        "\t\t\t\tprint('Iter #',str(t))\n",
        "\n",
        "\t\t\ttr_images, transformations, levels = self.transf_ops.transform_dataset(original_images * 255., transf_string='random_'+str(string_length))\n",
        "\t\t\t\n",
        "\t\t\ttr_images /= 255.\n",
        "\t\t\t\n",
        "\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\ttarget_accuracy = 0\n",
        "\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\tnumber_fitness_evals += 1\n",
        "\n",
        "\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\n",
        "\t\t\tall_accuracies.append(target_accuracy)\n",
        "\n",
        "\t\t\tif target_accuracy < current_minimum:\n",
        "\t\t\t\tprint ('%d Current minimum: [%.4f], # fitness evals: [%d]'%(t, target_accuracy, number_fitness_evals))\n",
        "\t\t\t\tcurrent_minimum=target_accuracy\t\t\t\t\n",
        "\t\t\t\n",
        "\t\t\t\tall_best_accuracies.append(target_accuracy)\n",
        "\t\t\t\tall_transformations.append(transformations)\n",
        "\t\t\t\tall_levels.append(levels)\n",
        "\n",
        "\t\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\t\tall_images.append(conc_images)\n",
        "\n",
        "\n",
        "\t\tprint('Saving output in \"images\" folder')\n",
        "\t\tPIL.Image.fromarray(conc_images.astype('uint8')).save(save_file_name+'_acc_%.3f.png'%(current_minimum))\n",
        "\t\t\t\t\n",
        "\t\twith open(save_file_name+'_acc_%.3f.pkl'%(current_minimum), 'wb') as f:\n",
        "\t\t\tcPickle.dump((all_accuracies, all_best_accuracies, all_transformations, all_levels, number_fitness_evals), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\t\treturn all_best_accuracies[-1], all_transformations[-1].tolist(), all_levels[-1], all_images[-1]\n",
        "\t\t\t\n",
        "\tdef genetic_algorithm(self, no_iters, pop_size, string_length, mutation_rate, save_file_name, compute_fitness_f, original_images, *args):\n",
        "\n",
        "\t\t'''\n",
        "\t\tSampling random image transformations and testing them on a provided model.\n",
        "\t\tReferring to the paper, this is Algorithm 2.\n",
        "\t\t\n",
        "\t\t\tno_iters: number of iterations.\n",
        "\t\t\tstring_length: number of transformations to be concatenated.\n",
        "\t\t\tmutation_rate: a value in [0.0,1.0]\n",
        "\t\t\tsave_file_name: file name used to save .png and .pkl outputs.\n",
        "\t\t\tcompute_fitness_f: test function associated with the desired model.\n",
        "\t\t\toriginal_images: images to give in input to compute_fitness_f.\n",
        "\t\t\targs: other input eventually required by compute_fitness_f (e.g., ground truth labels, sess, etc.)\n",
        "\n",
        "\t\t'''\n",
        "\n",
        "\t\tmin_accuracy = 1.0 # initialized with the maximum value\n",
        "\t\tcurrent_minimum = 1.0 # initialized with the maximum value\n",
        "\n",
        "\t\tnumber_fitness_evals = 0\n",
        "\t\tnumber_fitness_needed = pop_size\n",
        "\n",
        "\t\tpop_accuracies = []\n",
        "\t\tpop_probabilities = []\n",
        "\t\tpop_transformations = []\n",
        "\t\tpop_levels = []\n",
        "\t\tpop_images = []\n",
        "\n",
        "\t\tmin_accs = []\n",
        "\t\tmin_transfs = []\n",
        "\t\tmin_levels = []\n",
        "\t\tmin_images = []\n",
        "\n",
        "\t\tall_fitnesses = []\n",
        "\n",
        "\t\tprint('Initializing population')\n",
        "\t\t\t\n",
        "\t\tfor p in range(pop_size): # number of items in the population\n",
        "\n",
        "\t\t\ttr_images, transformations, levels = self.transf_ops.transform_dataset(original_images * 255., transf_string='random_'+str(string_length))\n",
        "\t\t\ttr_images /= 255.\n",
        "\n",
        "\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\ttarget_accuracy = 0\n",
        "\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\tnumber_fitness_evals += 1\n",
        "\t\t\t\n",
        "\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\n",
        "\t\t\tpop_accuracies.append(target_accuracy)\n",
        "\t\t\tpop_transformations.append(transformations)\n",
        "\t\t\tpop_levels.append(levels)\n",
        "\t\t\t\n",
        "\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\t\t\t\n",
        "\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\tpop_images.append(conc_images)\n",
        "\t\t\t\n",
        "\t\tpop_probabilities = (1. - np.array(pop_accuracies))/np.sum(1. - np.array(pop_accuracies)) \n",
        "\n",
        "\t\tcurrent_minimum = np.min(pop_accuracies)\n",
        "\t\tprint('Current minimum:',str(current_minimum), '# fitness evals', str(number_fitness_evals))\n",
        "\n",
        "\t\tmin_accs.append(current_minimum)\n",
        "\n",
        "\t\tall_fitnesses.append(current_minimum)\n",
        "\t\t\n",
        "\t\tpop_transformations = [arr.tolist() for arr in pop_transformations]\t\t\t\n",
        "\n",
        "\t\tmin_transfs.append(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\tmin_levels.append(pop_levels[np.argmin(pop_accuracies)])\n",
        "\t\tmin_images.append(pop_images[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\tprint('Running evolution search')\n",
        "\n",
        "\t\tfor step in range(no_iters): # number of iters for the evolution search\n",
        "\n",
        "\t\t\tif current_minimum == 0.0:\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\t\tnew_pop_accuracies = []\n",
        "\t\t\tnew_pop_images = []\n",
        "\t\t\tnew_pop_transformations = [None for i in range(pop_size)]\n",
        "\t\t\tnew_pop_levels = [None for i in range(pop_size)]\n",
        "\n",
        "\t\t\tfor p in range(pop_size/2):\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t# randomly choose two parents to be mated <3\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tidx_1 = npr.choice(pop_size, p=pop_probabilities)\n",
        "\t\t\t\tidx_2 = npr.choice(pop_size, p=pop_probabilities)\n",
        "\n",
        "\t\t\t\ttransformations_1 = pop_transformations[idx_1]\n",
        "\t\t\t\ttransformations_2 = pop_transformations[idx_2]\n",
        "\t\t\t\tlevels_1 = pop_levels[idx_1]\n",
        "\t\t\t\tlevels_2 = pop_levels[idx_2]\n",
        "\t\t\t\t\n",
        "\t\t\t\t# cutting transformations/levels on a random point and \n",
        "\t\t\t\t\t\n",
        "\t\t\t\tcrossover_point = npr.randint(string_length)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tnew_transformations_1 = transformations_1[:crossover_point] + transformations_2[crossover_point:]\n",
        "\t\t\t\tnew_levels_1 = levels_1[:crossover_point] + levels_2[crossover_point:]\n",
        "\t\t\t\tnew_transformations_2 = transformations_2[:crossover_point] + transformations_1[crossover_point:]\n",
        "\t\t\t\tnew_levels_2 = levels_2[:crossover_point] + levels_1[crossover_point:]\n",
        "\t\t\t\t\n",
        "\t\t\t\t# adding the new offspring to the new population\t\t\t\t\n",
        "\n",
        "\t\t\t\tnew_pop_transformations[p] = new_transformations_1\n",
        "\t\t\t\tnew_pop_levels[p] = new_levels_1\n",
        "\t\t\t\tnew_pop_transformations[p+pop_size/2] = new_transformations_2\n",
        "\t\t\t\tnew_pop_levels[p+pop_size/2] = new_levels_2\n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t# mutating some genes\n",
        "\t\t\t\t\n",
        "\t\t\tfor i, transformations in enumerate(new_pop_transformations):\n",
        "\t\t\t\tfor j, transf in enumerate(transformations):\n",
        "\t\t\t\t\tif npr.rand() < mutation_rate: \n",
        "\t\t\t\t\t\tnew_pop_transformations[i][j] = npr.choice(self.transf_ops.transformation_list, 1)[0]\n",
        "\t\t\t\t\t\tnew_pop_levels[i][j] = npr.choice(self.transf_ops.code_to_level_dict[new_pop_transformations[i][j]].values(), 1)[0]\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t# computing accuracies (\"fitness\" values)\n",
        "\n",
        "\t\t\tfor transformations, levels in zip(new_pop_transformations, new_pop_levels): \n",
        "\n",
        "\t\t\t\ttr_images, _, _ = self.transf_ops.transform_dataset(original_images * 255., transformations=transformations, levels=levels)\n",
        "\t\t\t\ttr_images /= 255.\n",
        "\t\t\t\t\n",
        "\t\t\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\t\t\ttarget_accuracy = 0\n",
        "\t\t\t\ttarget_loss = 0\n",
        "\t\t\t\n",
        "\t\t\t\tnumber_fitness_evals += 1\n",
        "\t\t\t\n",
        "\t\t\t\t(target_accuracy, preds) = compute_fitness_f(tr_images, *args)\n",
        "\t\t\t\t\n",
        "\t\t\t\tnew_pop_accuracies.append(target_accuracy)\n",
        "\n",
        "\n",
        "\t\t\t\tfor n, pred in enumerate(preds):\n",
        "\t\t\t\t\ttr_images[n][:5,:5,:] = 0.\n",
        "\t\t\t\t\ttr_images[n][:5,:5,1] = pred\n",
        "\t\t\t\t\ttr_images[n][:5,:5,0] = (1.-pred)\n",
        "\n",
        "\t\t\t\tconc_images=np.vstack((np.hstack((tr_images[i]*255. for i in range(j*20, (j+1)*20))) for j in range(10)))\n",
        "\t\t\t\tnew_pop_images.append(conc_images)\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\tpop_transformations = new_pop_transformations\n",
        "\t\t\tpop_levels = new_pop_levels\n",
        "\t\t\tpop_accuracies = new_pop_accuracies\n",
        "\n",
        "\t\t\tpop_images = new_pop_images\n",
        "\t\t\tpop_probabilities = (1. - np.array(pop_accuracies))/np.sum(1. - np.array(pop_accuracies)) \n",
        "\n",
        "\t\t\tif np.min(pop_accuracies) < current_minimum:\n",
        "\t\t\t\tcurrent_minimum = np.min(pop_accuracies)\n",
        "\t\t\t\tprint(str(step), '- Current minimum:', str(current_minimum), '#number fitness evals', str(number_fitness_evals))\n",
        "\t\t\t\tprint(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tprint(pop_levels[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\t\t\tnumber_fitness_needed = number_fitness_evals\n",
        "\n",
        "\t\t\t\tmin_accs.append(current_minimum)\n",
        "\t\t\t\tmin_transfs.append(pop_transformations[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tmin_levels.append(pop_levels[np.argmin(pop_accuracies)])\n",
        "\t\t\t\tmin_images.append(pop_images[np.argmin(pop_accuracies)])\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\tall_fitnesses.append(current_minimum)\n",
        "\n",
        "\t\tPIL.Image.fromarray(pop_images[np.argmin(pop_accuracies)].astype('uint8')).save(save_file_name+'_acc_%.3f.png'%(current_minimum))\n",
        "\t\t\n",
        "\t\twith open(save_file_name+'_acc_%.3f.pkl'%(current_minimum), 'wb') as f:\n",
        "\t\t\tcPickle.dump((min_accs,min_transfs, min_levels, number_fitness_needed, all_fitnesses), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\t\treturn min_accs[np.argmin(min_accs)], min_transfs[np.argmin(min_accs)], min_levels[np.argmin(min_accs)], min_images[np.argmin(min_accs)]\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    print('...')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjXMPhX3bTl-",
        "outputId": "a9623ba0-3172-4018-b47b-c2025f15c1ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tranf ops"
      ],
      "metadata": {
        "id": "uESW4nkibRuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import PIL\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageEnhance\n",
        "import PIL.Image\n",
        "import matplotlib\n",
        "\n",
        "class TransfOps(object):\n",
        "\n",
        "\t'''\n",
        "\tClass to handle the decoding of the strings used with the genetic\n",
        "\talgorithm and all the data transformations.\n",
        "\t'''\n",
        "\t\n",
        "\tdef __init__(self):\n",
        "\t\t\t\t\n",
        "\t\tself.transformation_list = ['autocontrast', 'brightness', 'color', 'contrast', 'sharpness', 'solarize', 'grayscale', 'Renhancer', 'Genhancer', 'Benhancer']\n",
        "\t\tself.define_code_correspondances()\n",
        "\t\t\n",
        "\tdef decode_string(self, transf_string):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tCode to decode the string used by the genetic algorithm\n",
        "\t\tString example: 't1,l1_3,t4,l4_0,t0,l0_1'. First transformation is the one \n",
        "\t\tassociated with index '1', with level set to '3', and so on.\n",
        "\t\t'random_N' with N integer gives N rnd transformations with rnd levels.\n",
        "\t\t'''\n",
        "\t\t\n",
        "\t\tif 'random' in transf_string:\n",
        "\t\t\ttransformations = npr.choice(self.transformation_list, int(transf_string.split('_')[-1])) # the string is 'random_N'\n",
        "\t\t\tlevels = [npr.choice(list(self.code_to_level_dict[t].values()), 1)[0] for t in transformations] # list() to make it compatible with Python3\n",
        "\t\telse:\n",
        "\t\t\ttransformation_codes = transf_string.split(',')[0::2] \n",
        "\t\t\tlevel_codes = transf_string.split(',')[1::2]\n",
        "\t\t\t\n",
        "\t\t\ttransformations = [self.code_to_transf(code) for code in transformation_codes] \t\n",
        "\t\t\tlevels = [self.code_to_level(transf,level) for transf,level in zip(transformations, level_codes)] \t\n",
        "\n",
        "\t\treturn transformations, levels\t\t\n",
        "\n",
        "\tdef transform_dataset(self, dataset, transf_string = 't0,l0_0', transformations=None, levels=None):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tdataset: set of images, shape should be N x width x height x #channels\n",
        "\t\ttransf_string: transformations and levels encoded in a string \n",
        "\t\t'''\n",
        "\n",
        "\t\t#print 'Dataset size:',dataset.shape\n",
        "\t\t\n",
        "\t\tif len(dataset.shape) == 3: # if 'dataset' is a single image\n",
        "\t\t\tdataset = np.expand_dims(dataset, 0) \n",
        "\t\t\n",
        "\t\tif dataset.shape[-1] != 3:\n",
        "\t\t\tprint('Input shape:', str(dataset.shape))\n",
        "\t\t\traise Exception('The images must be in RGB format')\n",
        "\n",
        "\t\ttr_dataset = np.zeros((dataset.shape))\n",
        "\t\t\n",
        "\t\tif transformations is None:\n",
        "\t\t\t# decoding transformation string\n",
        "\t\t\ttransformations, levels = self.decode_string(transf_string)\t\n",
        "\t\t\n",
        "\t\tfor n,img in enumerate(dataset):\n",
        "\t\t\tpil_img = PIL.Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "\t\t\tfor transf,level in zip(transformations, levels): \n",
        "\t\t\t\tpil_img = self.apply_transformation(pil_img, transf, level)\n",
        "\t\t\ttr_dataset[n] = np.array(pil_img)\n",
        "\n",
        "\t\treturn tr_dataset, transformations, levels\n",
        "\n",
        "\tdef apply_transformation(self, image, transformation, level):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\timage: image to be tranformed, shape should be 1 x width x height x #channels\n",
        "\t\ttransformation: type of transformation to be applied\n",
        "\t\tlevel: level of the perturbation to be applied \n",
        "\t\t'''\n",
        "\n",
        "\t\tif transformation == 'identity':\n",
        "\t\t\treturn image \n",
        "\n",
        "\t\telif transformation == 'autocontrast':\n",
        "\t\t\treturn PIL.ImageOps.autocontrast(image, cutoff=level)\n",
        "\n",
        "\t\telif transformation == 'brightness':\n",
        "\t\t\treturn PIL.ImageEnhance.Brightness(image).enhance(level)\n",
        "\n",
        "\t\telif transformation == 'color':\n",
        "\t\t\treturn PIL.ImageEnhance.Color(image).enhance(level)\n",
        "\t\t\t\n",
        "\t\telif transformation == 'contrast':\n",
        "\t\t\treturn PIL.ImageEnhance.Contrast(image).enhance(level)\n",
        "\n",
        "\t\telif transformation == 'sharpness':\n",
        "\t\t\treturn PIL.ImageEnhance.Sharpness(image).enhance(level)\n",
        "\t\t\t\n",
        "\t\telif transformation == 'solarize':\n",
        "\t\t\treturn PIL.ImageOps.solarize(image, threshold=level)\n",
        "\n",
        "\t\telif transformation == 'grayscale':\n",
        "\t\t\timage = PIL.ImageOps.grayscale(image).convert('RGB')\n",
        "\t\t\treturn image\t\t\n",
        "\n",
        "\t\telif transformation == 'Renhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,0] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\t\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\t\telif transformation == 'Genhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,1] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\t\telif transformation == 'Benhancer':\n",
        "\t\t\timage = np.array(image).astype(int)\n",
        "\t\t\timage[:,:,2] += level\n",
        "\t\t\timage[image>255] = 255\n",
        "\t\t\timage[image<0] = 0\n",
        "\t\t\timage = PIL.Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\t\t\treturn image\n",
        "\n",
        "\tdef code_to_transf(self, code):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tTakes in input a code (e.g., 't0', 't1', ...) and gives in output \n",
        "\t\tthe related transformation.\n",
        "\t\t'''\n",
        "\n",
        "\t\treturn self.code_to_transf_dict[code]\n",
        "\n",
        "\n",
        "\tdef code_to_level(self, transformation, code):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tTakes in input a transfotmation (e.g., 'invert', 'colorize', ...) and \n",
        "\t\ta level code (e.g., 'l0_1', 'l1_3', ...) and gives in output the related level.\n",
        "\t\t'''\n",
        "\t\t\n",
        "\t\treturn self.code_to_level_dict[transformation][code]\n",
        "\t\t\t\t\n",
        "\tdef define_code_correspondances(self):\n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tDefine the correpondances between transformation/level codes\n",
        "\t\tand the actual types and values.\n",
        "\t\t'''\n",
        "\t\t\t\n",
        "\t\tself.code_to_transf_dict = dict()\n",
        "\t\t\n",
        "\t\tself.code_to_transf_dict['t1'] = 'autocontrast'\n",
        "\t\tself.code_to_transf_dict['t2'] = 'brightness'\n",
        "\t\tself.code_to_transf_dict['t3'] = 'color'\n",
        "\t\tself.code_to_transf_dict['t4'] = 'contrast'\n",
        "\t\tself.code_to_transf_dict['t5'] = 'sharpness'\n",
        "\t\tself.code_to_transf_dict['t6'] = 'solarize'\n",
        "\t\tself.code_to_transf_dict['t7'] = 'grayscale'\n",
        "\t\tself.code_to_transf_dict['t8'] = 'Renhancer'\n",
        "\t\tself.code_to_transf_dict['t9'] = 'Genhancer'\n",
        "\t\tself.code_to_transf_dict['t10'] = 'Benhancer'\n",
        "\n",
        "\t\tself.code_to_level_dict = dict()\n",
        "\t\t\n",
        "\t\tfor k in self.transformation_list:\n",
        "\t\t\tself.code_to_level_dict[k] = dict()\n",
        "\t\t\t\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['autocontrast'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.0,0.3,20)):\n",
        "\t\t\tself.code_to_level_dict['autocontrast']['l1_'+str(n)] = l\n",
        "\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['brightness'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['brightness']['l2_'+str(n)] = l\n",
        "\t\t\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['color'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['color']['l3_'+str(n)] = l\n",
        "\t\t\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['contrast'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['contrast']['l4_'+str(n)] = l\n",
        "\n",
        "\t\t# factors\n",
        "\t\tself.code_to_level_dict['sharpness'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0.6,1.4,20)):\n",
        "\t\t\tself.code_to_level_dict['sharpness']['l5_'+str(n)] = l\n",
        "\t\t\n",
        "\t\tself.code_to_level_dict['solarize'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(0,20,20).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['solarize']['l6_'+str(n)] = l\n",
        "\n",
        "\t\tself.code_to_level_dict['grayscale']['l7_0'] = None\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Renhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Renhancer']['l8_'+str(n)] = l\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Genhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Genhancer']['l9_'+str(n)] = l\n",
        "\n",
        "\t\t# percentages\n",
        "\t\tself.code_to_level_dict['Benhancer'] = dict()\n",
        "\t\tfor n,l in enumerate(np.linspace(-120,120,30).astype(int)):\n",
        "\t\t\tself.code_to_level_dict['Benhancer']['l10_'+str(n)] = l\n",
        "\n",
        "if __name__=='__main__':\n",
        "\tpass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ofPhxacqbHjM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import configparser\n",
        "import os\n",
        "#import cPickle\n",
        "import scipy.io\n",
        "import sys\n",
        "import glob\n",
        "from numpy.linalg import norm\n",
        "from scipy import misc\n",
        "import skimage.transform\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "sys.path.insert(0,'../')\n",
        "\n",
        "\n",
        "class TrainOps(object):\n",
        "\n",
        "\tdef __init__(self, model, exp_dir):\n",
        "\n",
        "\t\tself.model = model\n",
        "\t\tself.exp_dir = exp_dir\n",
        "\n",
        "\t\tself.config = tf.ConfigProto()\n",
        "\t\tself.config.gpu_options.allow_growth=False\n",
        "\n",
        "\t\tself.data_dir = './data'\n",
        "\n",
        "\tdef load_exp_config(self):\n",
        "\n",
        "\t\tprint(self.exp_dir)\n",
        "\n",
        "\t\tconfig = configparser.ConfigParser()\n",
        "\n",
        "\t\tprint('LOADING CONFIG FILE')\n",
        "\t\tconfig.read(os.path.join(self.exp_dir,'exp_config'))\n",
        "\t\tself.source_dataset = config.get('EXPERIMENT_SETTINGS', 'source_dataset')\n",
        "\n",
        "\t\tself.model.source_dataset = self.source_dataset\n",
        "\t\t\t\n",
        "\t\tself.model.no_classes = 10\n",
        "\t\tself.model.img_size = 32\n",
        "\n",
        "\t\tself.log_dir = os.path.join(self.exp_dir,'logs')\n",
        "\t\tself.model_save_path = os.path.join(self.exp_dir,'model')\n",
        "\t\tself.images_dir = os.path.join(self.exp_dir,'images')\n",
        "\n",
        "\t\tif not os.path.exists(self.log_dir):\n",
        "\t\t\tos.makedirs(self.log_dir)\n",
        "\n",
        "\t\tif not os.path.exists(self.model_save_path):\n",
        "\t\t\tos.makedirs(self.model_save_path)\n",
        "\n",
        "\t\tif not os.path.exists(os.path.join(self.images_dir)):\n",
        "\t\t\tos.makedirs(os.path.join(self.images_dir))\n",
        "\n",
        "\n",
        "\t\tself.train_iters = config.getint('MAIN_SETTINGS', 'train_iters')\n",
        "\t\tself.batch_size = config.getint('MAIN_SETTINGS', 'batch_size')\n",
        "\t\tself.model.batch_size = self.batch_size\n",
        "\t\tself.model.learning_rate = config.getfloat('MAIN_SETTINGS', 'learning_rate')\n",
        "\n",
        "\t\tself.transf_string = config.get('MAIN_SETTINGS', 'transf_string')\n",
        "\t\tself.sub_train_iters = config.getint('MAIN_SETTINGS', 'sub_train_iters')\n",
        "\t\tself.string_length = config.getint('MAIN_SETTINGS', 'string_length')\n",
        "\n",
        "\t\tself.transf_ops = TransfOps()\n",
        "\t\tself.search_ops = SearchOps()\n",
        "\n",
        "\tdef load_svhn(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading SVHN dataset.')\n",
        "\n",
        "\t\timage_file = 'train_32x32.mat' if split=='train' else 'test_32x32.mat'\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir, 'svhn', image_file)\n",
        "\t\tsvhn = scipy.io.loadmat(image_dir)\n",
        "\t\timages = np.transpose(svhn['X'], [3, 0, 1, 2])\n",
        "\t\tlabels = svhn['y'].reshape(-1)\n",
        "\t\tlabels[np.where(labels==10)] = 0\n",
        "\t\timages = images/255.\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_mnist(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading MNIST dataset.')\n",
        "\t\timage_file = 'train.pkl' if split=='train' else 'test.pkl'\n",
        "\t\timage_dir = os.path.join(self.data_dir, 'mnist', image_file)\n",
        "\t\twith open(image_dir, 'rb') as f:\n",
        "\t\t\tmnist = cPickle.load(f)\n",
        "\t\t\n",
        "\t\timages = mnist['X'] \n",
        "\t\tlabels = mnist['y']\n",
        "\n",
        "\t\timages = images\n",
        "\t\timages = images/255. # better generalization performance if [0,1]\n",
        "\n",
        "\t\timages = np.stack((images,images,images), axis=3) # grayscale to rgb\n",
        "\n",
        "\t\treturn np.squeeze(images), labels\n",
        "\n",
        "\tdef load_mnist_m(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading MNIST_M dataset.')\n",
        "\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir,'mnist_m')\n",
        "\n",
        "\t\tif split == 'train':\n",
        "\t\t\tdata_dir = os.path.join(image_dir,'mnist_m_train')\n",
        "\t\t\twith open(os.path.join(image_dir,'mnist_m_train_labels.txt')) as f:\n",
        "\t\t\t\tcontent = f.readlines()\n",
        "\t\t\t\t\n",
        "\t\telif split == 'test':\n",
        "\t\t\tdata_dir = os.path.join(image_dir,'mnist_m_test')\n",
        "\t\t\twith open(os.path.join(image_dir,'mnist_m_test_labels.txt')) as f:\n",
        "\t\t\t\tcontent = f.readlines()\n",
        "\n",
        "\n",
        "\t\tcontent = [c.split('\\n')[0] for c in content]\n",
        "\t\timages_files = [c.split(' ')[0] for c in content]\n",
        "\t\tlabels = np.array([int(c.split(' ')[1]) for c in content]).reshape(-1)\n",
        "\n",
        "\t\timages = np.zeros((len(labels), 32, 32, 3))\n",
        "\n",
        "\t\tfor no_img,img in enumerate(images_files):\n",
        "\t\t\timg_dir = os.path.join(data_dir, img)\n",
        "\t\t\tim = misc.imread(img_dir)\n",
        "\t\t\tim = np.expand_dims(im, axis=0)\n",
        "\t\t\timages[no_img] = im\n",
        "\n",
        "\t\timages = images \n",
        "\t\timages = images/255.\n",
        "\t\t\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_syn(self, split='train'):\n",
        "\t\tprint ('Loading SYN dataset.')\n",
        "\n",
        "\t\timage_file = 'synth_train_32x32.mat' if split=='train' else 'synth_test_32x32.mat'\n",
        "\n",
        "\t\timage_dir = os.path.join(self.data_dir,'syn', image_file)\n",
        "\t\tsyn = scipy.io.loadmat(image_dir)\n",
        "\t\timages = np.transpose(syn['X'], [3, 0, 1, 2])\n",
        "\t\tlabels = syn['y'].reshape(-1)\n",
        "\t\tlabels[np.where(labels==10)] = 0\n",
        "\t\t\n",
        "\t\timages = images/255.\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef load_usps(self, split='train'):\n",
        "\n",
        "\t\tprint ('Loading USPS dataset.')\n",
        "\t\timage_file = 'usps_32x32.pkl'\n",
        "\t\timage_dir = os.path.join(self.data_dir,'usps', image_file)\n",
        "\t\t\n",
        "\t\twith open(image_dir, 'rb') as f:\n",
        "\t\t\tusps = cPickle.load(f)\n",
        "\t\t\n",
        "\t\timages = usps['X']\n",
        "\t\tlabels = usps['y']\n",
        "\t\tlabels -= 1\n",
        "\t\tlabels[labels==255] = 9\n",
        "\n",
        "\t\timages=np.squeeze(images)\n",
        "\t\timages = np.stack((images,images,images), axis=3) # grayscale to rgb\n",
        "\t\timages = images/255.\n",
        "\n",
        "\t\tif split == 'train':\n",
        "\t\t\treturn images[:6562], np.squeeze(labels[:6562]).astype(int)\n",
        "\t\telif split == 'validation':\n",
        "\t\t\treturn images[6562:7291], np.squeeze(labels[6562:7291]).astype(int)\n",
        "\t\telif split == 'test':\t    \n",
        "\t\t\treturn images[7291:], np.squeeze(labels[7291:]).astype(int)\n",
        "\t\n",
        "\tdef load_test_data(self, target):\n",
        "\n",
        "\t\tif target=='mnist_m':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_mnist_m(split='test')\n",
        "\t\telif target=='svhn':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_svhn(split='test')\n",
        "\t\telif target=='syn':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_syn(split='test')\n",
        "\t\telif target=='usps':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_usps(split='test')\n",
        "\t\telif target=='mnist':\n",
        "\t\t\tself.target_test_images, self.target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\treturn self.target_test_images,self.target_test_labels\n",
        "\n",
        "\tdef train(self, random_transf=False): \n",
        "\n",
        "\t\t'''\n",
        "\t\tThis method allows to train ERM and RDA models.\n",
        "\t\t\n",
        "\t\t\trandom_transf: if set to True, RDA is used, o.w. ERM.\n",
        "\t\t\n",
        "\t\tThe number of transformations to be concatenated needs be to\n",
        "\t\tset in the file exp_config.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tprint('Loading data')\n",
        "\n",
        "\t\tsource_train_images, source_train_labels = self.load_mnist(split='train')\n",
        "\t\ttarget_test_images, target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\twith tf.Session(config=self.config) as sess:\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n",
        "\n",
        "\t\t\tprint('Training')\n",
        "\t\t\t\n",
        "\t\t\tfor t in range(self.train_iters):\n",
        "\n",
        "\t\t\t\ti = t % int(source_train_images.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\t\t#current batch of images and labels\n",
        "\t\t\t\tbatch_images = source_train_images[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\t\t\t\tbatch_labels = source_train_labels[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\n",
        "\t\t\t\tif random_transf:\n",
        "\t\t\t\t\tbatch_images, _, _ = self.transf_ops.transform_dataset(batch_images * 255., transf_string = self.transf_string)\n",
        "\t\t\t\t\tbatch_images /= 255.\n",
        "\t\t\t\t\n",
        "\t\t\t\tfeed_dict = {self.model.images: batch_images, self.model.labels: batch_labels} \n",
        "\n",
        "\t\t\t\t#running a step of gradient descent\n",
        "\t\t\t\tsess.run([self.model.min_train_op, self.model.min_loss], feed_dict) \n",
        "\n",
        "\t\t\t\t#evaluating the model\n",
        "\t\t\t\tif t % 2500 == 0:\n",
        "\n",
        "\t\t\t\t\tsummary, min_l, acc = sess.run([self.model.summary_op, self.model.min_loss, self.model.accuracy], feed_dict)\n",
        "\n",
        "\t\t\t\t\ttrain_rand_idxs = np.random.permutation(source_train_images.shape[0])[:100]\n",
        "\t\t\t\t\ttest_rand_idxs = np.random.permutation(target_test_images.shape[0])[:100]\n",
        "\n",
        "\t\t\t\t\ttrain_acc, train_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: source_train_images[train_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: source_train_labels[train_rand_idxs]})\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\ttest_acc, test_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: target_test_images[test_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: target_test_labels[test_rand_idxs]})\n",
        "\t\t\t\t\t  \n",
        "\t\t\t\t\tsummary_writer.add_summary(summary, t)\n",
        "\t\t\t\t\tprint ('Step: [%d/%d] train_min_loss: [%.4f] train_acc: [%.4f] test_min_loss: [%.4f] test_acc: [%.4f]'%(t+1, self.train_iters, train_min_loss, train_acc, test_min_loss, test_acc))\n",
        "\t\t\t\n",
        "\t\t\t\tif t % 10000 == 0:\n",
        "\t\t\t\t\tprint('Saving')\n",
        "\t\t\t\t\tsaver.save(sess, os.path.join(self.model_save_path, 'encoder'))\n",
        "\n",
        "\tdef train_search(self, search_algorithm='random_search'): \n",
        "\t\t\n",
        "\t\t'''\n",
        "\t\tThis method allows to train models using RSDA and ESDA algorithms.\n",
        "\t\tReferring to the paper, this is Algorithm 3.\n",
        "\n",
        "\t\t\tsearch_algorithm: 'random_search' or 'evolution_search', \n",
        "\t\t\t\t\t\t\t  accordingly to the desired search procedure.\n",
        "\n",
        "\t\tThe number of transformations to be concatenated needs be to\n",
        "\t\tset in the file exp_config.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tprint('Loading data')\n",
        "\n",
        "\t\tsource_train_images, source_train_labels = self.load_mnist(split='train')\n",
        "\t\ttarget_test_images, target_test_labels = self.load_mnist(split='test')\n",
        "\n",
        "\t\t# initializing the set of data augmentation rules.\n",
        "\n",
        "\t\ttransformations = [['identity']]\n",
        "\t\tlevels = [[None]]\t\t\n",
        "\n",
        "\t\twith tf.Session(config=self.config) as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(logdir=self.log_dir, graph=tf.get_default_graph())\n",
        "\n",
        "\t\t\tprint('Training')\n",
        "\t\t\t\n",
        "\t\t\tfor t in range(self.train_iters):\n",
        "\n",
        "\t\t\t\ti = t % int(source_train_images.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\t\t# current batch of images and labels\n",
        "\t\t\t\tbatch_images = source_train_images[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\t\t\t\tbatch_labels = source_train_labels[i*self.batch_size:(i+1)*self.batch_size]\n",
        "\n",
        "\t\t\t\t# sampling uniformly a transformation and its level, and applying it to the batch\n",
        "\t\t\t\trnd_transf_idx = npr.randint(len(transformations))\n",
        "\t\t\t\t\n",
        "\t\t\t\tif transformations[rnd_transf_idx] == ['identity']: # do nothing for 'identity', namely use original images\n",
        "\t\t\t\t\tpass\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t# TransfOps requires [0,255] pixel ranges, while here images [0,1]\n",
        "\t\t\t\t\tbatch_images, _, _ = self.transf_ops.transform_dataset(batch_images * 255., transformations=transformations[rnd_transf_idx], levels=levels[rnd_transf_idx])\n",
        "\t\t\t\t\tbatch_images /= 255.\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t# running a step of gradient descent\n",
        "\t\t\t\tfeed_dict = {self.model.images: batch_images, self.model.labels: batch_labels} \n",
        "\t\t\t\tsess.run([self.model.min_train_op, self.model.min_loss], feed_dict) \n",
        "\n",
        "\t\t\t\t#evaluating the model\n",
        "\t\t\t\tif t % 2500 == 0:\n",
        "\n",
        "\t\t\t\t\tsummary, min_l, acc = sess.run([self.model.summary_op, self.model.min_loss, self.model.accuracy], feed_dict)\n",
        "\n",
        "\t\t\t\t\ttrain_rand_idxs = np.random.permutation(source_train_images.shape[0])[:100]\n",
        "\t\t\t\t\ttest_rand_idxs = np.random.permutation(target_test_images.shape[0])[:100]\n",
        "\n",
        "\t\t\t\t\ttrain_acc, train_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: source_train_images[train_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: source_train_labels[train_rand_idxs]})\n",
        "\t\t\t\t\ttest_acc, test_min_loss = sess.run(fetches=[self.model.accuracy, self.model.min_loss], \n",
        "\t\t\t\t\tfeed_dict={self.model.images: target_test_images[test_rand_idxs], \n",
        "\t\t\t\t\tself.model.labels: target_test_labels[test_rand_idxs]})\n",
        "\t\t\t\t\t  \n",
        "\t\t\t\t\tsummary_writer.add_summary(summary, t)\n",
        "\t\t\t\t\tprint('Step: [%d/%d] train_min_loss: [%.4f] train_acc: [%.4f] test_min_loss: [%.4f] test_acc: [%.4f]'%(t+1, self.train_iters, train_min_loss, train_acc, test_min_loss, test_acc))\n",
        "\n",
        "\t\t\t\tif (t+1)%self.sub_train_iters == 0:\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif search_algorithm == 'random_search':\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tprint('\\n\\nRunning Random Search')\n",
        "\t\t\t\t\t\tsave_file_name=os.path.join(self.images_dir,'Random_string_length_'+str(self.string_length)+'_iter_'+str(t+1))\n",
        "\t\t\t\t\t\tmin_tr_accuracy, _transformations, _levels, _image = self.search_ops.random_search(100, self.string_length, save_file_name,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.test, source_train_images[:1000],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_train_labels[:1000], sess) \n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\telif search_algorithm == 'evolution_search':\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tprint('\\n\\nRunning Evolution Search')\n",
        "\t\t\t\t\t\tsave_file_name=os.path.join(self.images_dir,'Evolution_string_length_'+str(self.string_length)+'_iter_'+str(t+1))\n",
        "\t\t\t\t\t\tmin_tr_accuracy, _transformations, _levels, _image = self.search_ops.genetic_algorithm(10, 10, self.string_length, 0.1,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsave_file_name, self.test, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_train_images[:1000],\tsource_train_labels[:1000], sess) \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\ttransformations.append(_transformations)\n",
        "\t\t\t\t\tlevels.append(_levels)\n",
        "\n",
        "\t\t\t\t\tprint('Target accuracy: [%.4f]'%(min_tr_accuracy))\n",
        "\t\t\t\t\tprint('_'.join(_transformations))\n",
        "\t\t\t\t\tprint('\\n\\n')\t\t\n",
        "\n",
        "\t\t\t\tif (t+1) % 25000 == 0:\n",
        "\t\t\t\t\tprint('Saving')\n",
        "\t\t\t\t\tsaver.save(sess, os.path.join(self.model_save_path, 'encoder'))\n",
        "\n",
        "\n",
        "\tdef test(self, images, labels, sess):\n",
        "\n",
        "\t\tN = 1 #set accordingly to GPU memory\n",
        "\t\ttarget_accuracy = 0\n",
        "\t\ttarget_loss = 0\n",
        "\t\tpreds = []\n",
        "\n",
        "\t\tfor test_images_batch, test_labels_batch in zip(np.array_split(images, N), np.array_split(labels, N)):\n",
        "\t\t\tfeed_dict = {self.model.images: test_images_batch, self.model.labels: test_labels_batch} \n",
        "\t\t\ttarget_accuracy_tmp, target_loss_tmp, pred = sess.run([self.model.accuracy, self.model.min_loss, self.model.pred], feed_dict) \n",
        "\t\t\ttarget_accuracy += target_accuracy_tmp/float(N)\n",
        "\t\t\ttarget_loss += target_loss_tmp/float(N)\n",
        "\t\t\tpreds.append(pred.tolist())\n",
        "\n",
        "\t\tcorrect_guesses = (np.array(preds)==labels).astype(int)[0]\n",
        "\t\t\n",
        "\t\treturn target_accuracy, correct_guesses\n",
        "\t\n",
        "\tdef test_all(self):\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\tres_dict = dict()\n",
        "\t\tres_dict['exp_dir'] = self.exp_dir\n",
        "\n",
        "\t\tprint('Testing ALL')\n",
        "\n",
        "\t\ttargets = ['mnist', 'svhn']# add 'usps', 'syn', 'mnist_m'\n",
        "\n",
        "\t\tfor target in targets:\n",
        "\n",
        "\t\t\tprint('\\n\\n\\n...........................................................................')\n",
        "\n",
        "\t\t\ttest_images, test_labels = self.load_test_data(target=target)\n",
        "\n",
        "\t\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\t\tprint('...........................................................................')\n",
        "\n",
        "\t\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\t\tprint('Loading pre-trained model.')\n",
        "\t\t\t\tvariables_to_restore = slim.get_model_variables()\n",
        "\t\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\t\t\t\t\n",
        "\t\t\t\tN = 100\n",
        "\t\t\t\ttarget_accuracy = 0\n",
        "\t\t\t\ttarget_loss = 0\n",
        "\n",
        "\t\t\t\tprint('Calculating accuracy')\n",
        "\n",
        "\t\t\t\tfor test_images_batch, test_labels_batch in zip(np.array_split(test_images, N), np.array_split(test_labels, N)):\n",
        "\t\t\t\t\tfeed_dict = {self.model.images: test_images_batch, self.model.labels: test_labels_batch} \n",
        "\t\t\t\t\ttarget_accuracy_tmp, target_loss_tmp, target_pred = sess.run([self.model.accuracy, self.model.min_loss, self.model.pred], feed_dict) \n",
        "\t\t\t\t\ttarget_accuracy += target_accuracy_tmp/float(N)\n",
        "\t\t\t\t\ttarget_loss += target_loss_tmp/float(N)\n",
        "\n",
        "\t\t\tprint('Target accuracy: [%.4f] target loss: [%.4f]'%(target_accuracy, target_loss))\n",
        "\n",
        "\t\t\tres_dict[target] = target_accuracy\n",
        "\n",
        "\t\twith open(os.path.join(self.exp_dir, 'domain_generalization_performance.pkl'), 'w') as f:\n",
        "\t\t\tcPickle.dump(res_dict, f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "\tdef test_random_search(self, run, seed, no_iters, string_length):\n",
        "\n",
        "\t\ttest_images, test_labels = self.load_test_data(target='mnist')\n",
        "\t\t\n",
        "\t\tnpr.seed(213)\n",
        "\t\trnd_idx = range(len(test_images))\n",
        "\t\tnpr.shuffle(rnd_idx)\t\t\n",
        "\n",
        "\t\ttest_images = test_images[rnd_idx]\n",
        "\t\ttest_labels = test_labels[rnd_idx]\n",
        "\n",
        "\t\ttest_images = test_images[:1000]\n",
        "\t\ttest_labels = test_labels[:1000]\n",
        "\n",
        "\t\tnpr.seed(seed)\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.mode='train_encoder'\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tprint ('Loading pre-trained model.')\n",
        "\t\t\tvariables_to_restore = slim.get_model_variables(scope='encoder')\n",
        "\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\n",
        "\t\t\tif not os.path.exists(os.path.join(self.exp_dir,'images')):\n",
        "\t\t\t\tos.makedirs(os.path.join(self.exp_dir,'images'))\n",
        "\n",
        "\t\t\t# perform random search\n",
        "\t\t\t\n",
        "\t\t\tsave_search_file_name=os.path.join(self.images_dir,'TEST_Random_test_string_length_'+str(string_length))\n",
        "\n",
        "\t\t\tall_accuracies, all_transformations, all_levels, all_images = self.search_ops.random_search(5000, string_length, save_search_file_name,\tself.test, test_images, test_labels, sess) \n",
        "\t\t\t# save output\n",
        "\n",
        "\t\t\twith open(os.path.join(self.exp_dir, 'worst_case_accuracies.pkl'), 'w') as f:\n",
        "\t\t\t\tcPickle.dump((all_accuracies, all_transformations, all_levels), f, cPickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\tdef test_evolution_search(self, run='0', seed=123, no_iters=100, string_length=3, pop_size=10, mutation_rate=0.1):\n",
        "\n",
        "\t\ttest_images, test_labels = self.load_mnist(split='test')\n",
        "\t\t\n",
        "\t\tnpr.seed(213)\n",
        "\t\trnd_idx = range(len(test_images))\n",
        "\t\tnpr.shuffle(rnd_idx)\t\t\n",
        "\n",
        "\t\ttest_images = test_images[rnd_idx]\n",
        "\t\ttest_labels = test_labels[rnd_idx]\n",
        "\n",
        "\t\ttest_images = test_images[:1000]\n",
        "\t\ttest_labels = test_labels[:1000]\n",
        "\n",
        "\t\tnpr.seed(seed)\n",
        "\n",
        "\t\t# build a graph\n",
        "\t\tprint('Building model')\n",
        "\t\tself.model.mode='train_encoder'\n",
        "\t\tself.model.build_model()\n",
        "\t\tprint('Built')\n",
        "\n",
        "\t\twith tf.Session() as sess:\n",
        "\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\n",
        "\t\t\tprint ('Loading pre-trained model.')\n",
        "\t\t\tvariables_to_restore = slim.get_model_variables()\n",
        "\t\t\trestorer = tf.train.Saver(variables_to_restore)\n",
        "\t\t\trestorer.restore(sess, os.path.join(self.model_save_path,'encoder'))\n",
        "\n",
        "\t\t\tif not os.path.exists(os.path.join(self.exp_dir,'GA_images')):\n",
        "\t\t\t\tos.makedirs(os.path.join(self.exp_dir,'GA_images'))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\tsave_search_file_name=os.path.join(self.images_dir,'TEST_Evolution_test_string_length_'+str(string_length))\n",
        "\n",
        "\t\t\tself.search_ops.genetic_algorithm(100, pop_size, string_length, mutation_rate, save_search_file_name, self.test, test_images, test_labels, sess)\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    print('...')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqJtmrzJVslw",
        "outputId": "a01ec335-39b4-4800-c50e-d232a3f0eb0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "    \n",
        "    def __init__(self, mode='train'):\n",
        "\n",
        "        self.no_classes = 10\n",
        "        self.img_size = 32\n",
        "        self.no_channels = 3\n",
        "\n",
        "    def encoder(self, images, reuse=False):\n",
        "\n",
        "        with tf.variable_scope('encoder', reuse=reuse):\n",
        "            with slim.arg_scope([slim.fully_connected], activation_fn=tf.nn.relu):\n",
        "                with slim.arg_scope([slim.conv2d], activation_fn=tf.nn.relu, padding='VALID'):\n",
        "\n",
        "                    net = slim.conv2d(images, 64, 5, scope='conv1')\n",
        "                    net = slim.max_pool2d(net, 2, stride=2, scope='pool1')\n",
        "                    net = slim.conv2d(net, 128, 5, scope='conv2')\n",
        "                    net = slim.max_pool2d(net, 2, stride=2, scope='pool2')\n",
        "                    net = tf.layers.flatten(net)\n",
        "                    net = slim.fully_connected(net, 1024, scope='fc1')\n",
        "                    net = slim.fully_connected(net, 1024, scope='fc2')\n",
        "                    net = slim.fully_connected(net, self.no_classes, activation_fn=None, scope='fco')\n",
        "                    \n",
        "                    return net\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        # images placeholder\n",
        "        self.images = tf.placeholder(tf.float32, [None, self.img_size, self.img_size, self.no_channels], 'images')\n",
        "        # labels placeholder\n",
        "        self.labels = tf.placeholder(tf.int64, [None], 'labels')\n",
        "                \n",
        "        self.logits = tf.squeeze(self.encoder(self.images))\n",
        "\n",
        "        #for evaluation\n",
        "        self.pred = tf.argmax(self.logits, 1)\n",
        "        self.correct_pred = tf.equal(self.pred, self.labels)\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
        "\n",
        "        #variables for the minimizer are the net weights, variables for the maxmizer are the images' pixels\n",
        "        min_vars = tf.trainable_variables()\n",
        "                \n",
        "        #loss for the minimizer\n",
        "        self.min_loss = slim.losses.sparse_softmax_cross_entropy(self.logits, self.labels)\n",
        "\n",
        "        #we use Adam for the minimizer and vanilla gradient ascent for the maximizer \n",
        "        self.min_optimizer = tf.train.AdamOptimizer(self.learning_rate) \n",
        "\n",
        "        #minimizer\n",
        "        self.min_train_op = slim.learning.create_train_op(self.min_loss, self.min_optimizer, variables_to_train = min_vars)\n",
        "\n",
        "        min_loss_summary = tf.summary.scalar('min_loss', self.min_loss)\n",
        "\n",
        "        accuracy_summary = tf.summary.scalar('accuracy', self.accuracy)\n",
        "        self.summary_op = tf.summary.merge([min_loss_summary, accuracy_summary])\t\t\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N-KLrXpcAKqr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.py"
      ],
      "metadata": {
        "id": "pYq44fphcnvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = 0\n",
        "exp_dir = '/content/'\n",
        "mode = 'train_ERM'\n",
        "run = 0\n",
        "seed = 123\n",
        "transf_string_length = 5\n",
        "search_no_iters = 100\n",
        "pop_size = 10\n",
        "mutation_rate = 0.1"
      ],
      "metadata": {
        "id": "8DdlcOBxAP2w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy.random as npr\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "\n",
        "def main(_):\n",
        "\n",
        "\n",
        "\tGPU_ID = gpu\n",
        "\tos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152 on stackoverflow\n",
        "\tos.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU_ID)\n",
        "\n",
        "\tEXP_DIR = exp_dir\n",
        "\n",
        "\tmodel = Model()\n",
        "\ttr_ops = TrainOps(model, EXP_DIR)\n",
        "\n",
        "\tif 'train' in mode:\n",
        "\t\tnpr.seed(int(seed))\n",
        "\n",
        "\t\n",
        "\tif mode=='train_ERM':\n",
        "\t\tprint('Training model with standard ERM')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train()      \n",
        "\t\t\n",
        "\tif mode=='train_RDA':\n",
        "\t\tprint('Training model with RDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train(random_transf=True)\n",
        "\t\t\n",
        "\tif mode=='train_RSDA':\n",
        "\t\tprint('Training model with RSDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train_search(search_algorithm='random_search')\n",
        "\t\t\n",
        "\tif mode=='train_ESDA':\n",
        "\t\tprint('Training model with ESDA')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.train_search(search_algorithm='evolution_search')\n",
        "\n",
        "\t\t\n",
        "\telif mode=='test_all':\n",
        "\t\tprint('Testing all')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_all()\n",
        "\n",
        "\telif mode=='test_RS':\n",
        "\t\tprint('Random search')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_random_search(run=str(run), seed=int(seed), no_iters=int(search_no_iters), string_length=int(transf_string_length)) \n",
        "\n",
        "\telif mode=='test_ES':\n",
        "\t\tprint('Evolution search')\n",
        "\t\ttr_ops.load_exp_config()\n",
        "\t\ttr_ops.test_evolution_search(run=str(run), seed=int(seed), no_iters=int(search_no_iters),string_length=int(transf_string_length), \n",
        "\t\t\t\t\t\t\t\t\t\tpop_size=int(pop_size), mutation_rate=float(mutation_rate))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttf.app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esz-jEkt_1hs",
        "outputId": "0c752f6d-6521-4a3a-d02d-d4fe3e198c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with standard ERM\n",
            "/content/\n",
            "LOADING CONFIG FILE\n",
            "Building model\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 07:05:15.196529 140221453285248 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-905eaf5cb5a2>:22: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 07:05:15.268467 140221453285248 deprecation.py:323] From <ipython-input-11-905eaf5cb5a2>:22: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-905eaf5cb5a2>:47: sparse_softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.sparse_softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 07:05:15.344462 140221453285248 deprecation.py:323] From <ipython-input-11-905eaf5cb5a2>:47: sparse_softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.sparse_softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:409: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.compute_weighted_loss instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 07:05:15.511263 140221453285248 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:409: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.compute_weighted_loss instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 07:05:15.529069 140221453285248 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:154: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 07:05:15.537699 140221453285248 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:154: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.add_loss instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0430 07:05:15.557658 140221453285248 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.add_loss instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built\n",
            "Loading data\n",
            "Loading MNIST dataset.\n",
            "Loading MNIST dataset.\n",
            "Training\n",
            "Step: [1/100001] train_min_loss: [2.2514] train_acc: [0.2200] test_min_loss: [2.2590] test_acc: [0.2600]\n",
            "Saving\n",
            "Step: [2501/100001] train_min_loss: [0.0282] train_acc: [0.9800] test_min_loss: [0.0143] test_acc: [1.0000]\n",
            "Step: [5001/100001] train_min_loss: [0.0022] train_acc: [1.0000] test_min_loss: [0.0674] test_acc: [0.9600]\n",
            "Step: [7501/100001] train_min_loss: [0.0541] train_acc: [0.9600] test_min_loss: [0.0240] test_acc: [0.9900]\n",
            "Step: [10001/100001] train_min_loss: [0.0012] train_acc: [1.0000] test_min_loss: [0.0850] test_acc: [0.9900]\n",
            "Saving\n",
            "Step: [12501/100001] train_min_loss: [0.0007] train_acc: [1.0000] test_min_loss: [0.0557] test_acc: [0.9900]\n",
            "Step: [15001/100001] train_min_loss: [0.0059] train_acc: [1.0000] test_min_loss: [0.0001] test_acc: [1.0000]\n",
            "Step: [17501/100001] train_min_loss: [0.0010] train_acc: [1.0000] test_min_loss: [0.0351] test_acc: [0.9900]\n",
            "Step: [20001/100001] train_min_loss: [0.0018] train_acc: [1.0000] test_min_loss: [0.0174] test_acc: [0.9900]\n",
            "Saving\n",
            "Step: [22501/100001] train_min_loss: [0.0063] train_acc: [1.0000] test_min_loss: [0.0886] test_acc: [0.9900]\n",
            "Step: [25001/100001] train_min_loss: [0.0001] train_acc: [1.0000] test_min_loss: [0.0505] test_acc: [0.9900]\n",
            "Step: [27501/100001] train_min_loss: [0.0013] train_acc: [1.0000] test_min_loss: [0.0810] test_acc: [0.9900]\n",
            "Step: [30001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0001] test_acc: [1.0000]\n",
            "Saving\n",
            "Step: [32501/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0559] test_acc: [0.9900]\n",
            "Step: [35001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0002] test_acc: [1.0000]\n",
            "Step: [37501/100001] train_min_loss: [0.0006] train_acc: [1.0000] test_min_loss: [0.1075] test_acc: [0.9900]\n",
            "Step: [40001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0002] test_acc: [1.0000]\n",
            "Saving\n",
            "Step: [42501/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0024] test_acc: [1.0000]\n",
            "Step: [45001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0034] test_acc: [1.0000]\n",
            "Step: [47501/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.2928] test_acc: [0.9600]\n",
            "Step: [50001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0462] test_acc: [0.9800]\n",
            "Saving\n",
            "Step: [52501/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0992] test_acc: [0.9900]\n",
            "Step: [55001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0143] test_acc: [0.9900]\n",
            "Step: [57501/100001] train_min_loss: [0.0023] train_acc: [1.0000] test_min_loss: [0.0000] test_acc: [1.0000]\n",
            "Step: [60001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0001] test_acc: [1.0000]\n",
            "Saving\n",
            "Step: [62501/100001] train_min_loss: [0.0003] train_acc: [1.0000] test_min_loss: [0.1453] test_acc: [0.9700]\n",
            "Step: [65001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0000] test_acc: [1.0000]\n",
            "Step: [67501/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0001] test_acc: [1.0000]\n",
            "Step: [70001/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0127] test_acc: [0.9900]\n",
            "Saving\n",
            "Step: [72501/100001] train_min_loss: [0.0000] train_acc: [1.0000] test_min_loss: [0.0000] test_acc: [1.0000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tb"
      ],
      "metadata": {
        "id": "NfeZu-985IRV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}