{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU-ASSIGNMENT 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFxT/HJrMc+nJ6l6OV/G2b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saptarshidatta96/MTech_Sem3/blob/main/NLU_ASSIGNMENT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from scipy.sparse import csr_matrix\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing import text\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras import models\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Attention, Flatten, Activation, RepeatVector, Permute, Multiply\n",
        "from keras.layers import CuDNNLSTM\n",
        "from keras.layers import Dropout, Multiply, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "k9wpPfdU5pKc"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Kl42783JJX",
        "outputId": "46c67e79-d1ef-46b1-9e21-b150d1d50a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import io\n",
        "import xml.dom.minidom\n",
        "\n",
        "def iter_docs(author):\n",
        "  author_attr = author.attrib\n",
        "  for doc in author.iter('sentence'):\n",
        "    doc_dict = author_attr.copy()\n",
        "    for text in doc.iter('text'):\n",
        "      doc_dict['text'] = text.text\n",
        "      for cat in doc.iter('aspectCategory'):\n",
        "        doc_dict.update(cat.attrib)\n",
        "      yield doc_dict\n",
        "\n",
        "\n",
        "etree = ET.parse(\"/content/gdrive/MyDrive/train.xml\")\n",
        "doc_df = pd.DataFrame(list(iter_docs(etree.getroot())))"
      ],
      "metadata": {
        "id": "9a2RlAJbX6AG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CjWruD22YJgi",
        "outputId": "880675f4-ed10-47a3-be4f-1c41a2b725b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c0924fcb-8cee-42f6-9996-26621ae6e669\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It might be the best sit down food I've had in...</td>\n",
              "      <td>place</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hostess was extremely accommodating when we ar...</td>\n",
              "      <td>miscellaneous</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We were a couple of minutes late for our reser...</td>\n",
              "      <td>staff</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Though the service might be a little slow, the...</td>\n",
              "      <td>staff</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Although we arrived at the restaurant 10 min l...</td>\n",
              "      <td>miscellaneous</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0924fcb-8cee-42f6-9996-26621ae6e669')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0924fcb-8cee-42f6-9996-26621ae6e669 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0924fcb-8cee-42f6-9996-26621ae6e669');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text       category  polarity\n",
              "0  It might be the best sit down food I've had in...          place   neutral\n",
              "1  Hostess was extremely accommodating when we ar...  miscellaneous   neutral\n",
              "2  We were a couple of minutes late for our reser...          staff  negative\n",
              "3  Though the service might be a little slow, the...          staff  positive\n",
              "4  Although we arrived at the restaurant 10 min l...  miscellaneous   neutral"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHdsdJghIaaM",
        "outputId": "f09daa8a-aeb3-47c5-cee8-6d23124853af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3134, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_df['category'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo4mItemcFiQ",
        "outputId": "b923ef44-6648-4a66-9b91-727c1dcae927"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['place', 'miscellaneous', 'staff', 'food', 'ambience', 'service',\n",
              "       'menu', 'price'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_df['polarity'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S18gS9-6EB6X",
        "outputId": "5559db87-9f95-42aa-85e5-9d402fe55a68"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'negative', 'positive'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_category = pd.get_dummies(doc_df['category'], columns = ['food', 'place', 'staff', 'miscellaneous', 'service', 'price', 'menu', 'ambience'])"
      ],
      "metadata": {
        "id": "qJIUIDStbJYi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_polarity = pd.get_dummies(doc_df['polarity'], columns = ['neutral', 'negative', 'positive'])"
      ],
      "metadata": {
        "id": "r3viKwtgFJBw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_category, df_polarity], axis=1)"
      ],
      "metadata": {
        "id": "UDREQmUhEf6E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([doc_df['text'], df], axis=1)"
      ],
      "metadata": {
        "id": "bQi967VvdRVj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FQnqT6POdD5s",
        "outputId": "2d6496d9-ec2e-4f8f-8cee-522e4b002884"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-75265d15-e1fb-48d6-b32c-3777186dd453\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ambience</th>\n",
              "      <th>food</th>\n",
              "      <th>menu</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>place</th>\n",
              "      <th>price</th>\n",
              "      <th>service</th>\n",
              "      <th>staff</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It might be the best sit down food I've had in...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hostess was extremely accommodating when we ar...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We were a couple of minutes late for our reser...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Though the service might be a little slow, the...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Although we arrived at the restaurant 10 min l...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75265d15-e1fb-48d6-b32c-3777186dd453')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75265d15-e1fb-48d6-b32c-3777186dd453 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75265d15-e1fb-48d6-b32c-3777186dd453');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ...  positive\n",
              "0  It might be the best sit down food I've had in...  ...         0\n",
              "1  Hostess was extremely accommodating when we ar...  ...         0\n",
              "2  We were a couple of minutes late for our reser...  ...         0\n",
              "3  Though the service might be a little slow, the...  ...         1\n",
              "4  Although we arrived at the restaurant 10 min l...  ...         0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df['text']\n",
        "data = list(data)\n",
        "labels = df.drop(['text'], axis = 1)"
      ],
      "metadata": {
        "id": "HeAOZHTUd2Dr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_training_and_validation_sets(data, labels, validation_split):\n",
        "\n",
        "    num_training_samples = int((1 - validation_split) * len(data))\n",
        "    return ((data[:num_training_samples], labels[:num_training_samples]),\n",
        "            (data[num_training_samples:], labels[num_training_samples:]))\n",
        "    \n",
        "(train_data, train_label), (valid_data, valid_label) = split_training_and_validation_sets(data, labels, 0.1)\n"
      ],
      "metadata": {
        "id": "eHMCF8Dgiav6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9IpycIWN95t",
        "outputId": "fb04f09a-c353-4f26-c817-1b33f2c46fb4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ambience  food  menu  miscellaneous  ...  staff  negative  neutral  positive\n",
            "2820         0     1     0              0  ...      0         0        0         1\n",
            "2821         0     0     0              0  ...      0         1        0         0\n",
            "2822         0     0     1              0  ...      0         0        1         0\n",
            "2823         0     1     0              0  ...      0         1        0         0\n",
            "2824         0     1     0              0  ...      0         0        1         0\n",
            "...        ...   ...   ...            ...  ...    ...       ...      ...       ...\n",
            "3129         0     0     0              0  ...      1         1        0         0\n",
            "3130         0     0     1              0  ...      0         0        1         0\n",
            "3131         0     0     0              0  ...      0         0        1         0\n",
            "3132         0     0     0              0  ...      0         0        0         1\n",
            "3133         0     0     0              0  ...      1         1        0         0\n",
            "\n",
            "[314 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = tf.convert_to_tensor(train_label, dtype=tf.float32)\n",
        "valid_label = tf.convert_to_tensor(valid_label, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "k62-OybCjSyy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_vectorizer(train_data, valid_data):\n",
        "\n",
        "    # Create vocabulary with training texts.\n",
        "    tokenizer = text.Tokenizer(num_words=20000)\n",
        "    tokenizer.fit_on_texts(train_data)\n",
        "\n",
        "    # Vectorize training and validation texts.\n",
        "    x_train = tokenizer.texts_to_sequences(train_data)\n",
        "    x_val = tokenizer.texts_to_sequences(valid_data)\n",
        "\n",
        "    # Get max sequence length.\n",
        "    max_length = len(max(x_train, key=len))\n",
        "    if max_length > 50:\n",
        "        max_length = 50\n",
        "\n",
        "    # Fix sequence length to max value. Sequences shorter than the length are\n",
        "    # padded in the beginning and sequences longer are truncated\n",
        "    # at the beginning.\n",
        "    x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "    x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n",
        "\n",
        "    x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
        "    x_val = tf.convert_to_tensor(x_val, dtype=tf.float32)\n",
        "\n",
        "    return x_train, x_val, tokenizer.word_index"
      ],
      "metadata": {
        "id": "l4VmxGU1Mm3g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, word_index = sequence_vectorizer(train_data, valid_data)"
      ],
      "metadata": {
        "id": "ZqNhrBt0M9xp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ts9HSGGNwGR",
        "outputId": "b7ac8ace-4c87-4afe-c1a3-04d18a196f76"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6269"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCLOJE0R9U6U",
        "outputId": "55d8cb71-35c8-432e-b1b2-ef4224aef552"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2820, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/glove.42B.300d.zip\" -d \"/content\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMP4Tx-XdvD4",
        "outputId": "6fe01aaa-7658-471e-f698-9613432f0444"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/glove.42B.300d.zip\n",
            "  inflating: /content/glove.42B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file = \"glove.42B.300d.txt\"\n",
        "import tqdm\n",
        "\n",
        "EMBEDDING_VECTOR_LENGTH = 50 # <=200\n",
        "def construct_embedding_matrix(glove_file, word_index):\n",
        "    embedding_dict = {}\n",
        "    with open(glove_file,'r') as f:\n",
        "        for line in f:\n",
        "            values=line.split()\n",
        "            # get the word\n",
        "            word=values[0]\n",
        "            if word in word_index.keys():\n",
        "                # get the vector\n",
        "                vector = np.asarray(values[1:], 'float32')\n",
        "                embedding_dict[word] = vector\n",
        "    ###  oov words (out of vacabulary words) will be mapped to 0 vectors\n",
        "\n",
        "    num_words=len(word_index)+1\n",
        "    #initialize it to 0\n",
        "    embedding_matrix=np.zeros((num_words, EMBEDDING_VECTOR_LENGTH))\n",
        "\n",
        "    for word,i in tqdm.tqdm(word_index.items()):\n",
        "        if i < num_words:\n",
        "            vect=embedding_dict.get(word, [])\n",
        "            if len(vect)>0:\n",
        "                embedding_matrix[i] = vect[:EMBEDDING_VECTOR_LENGTH]\n",
        "    return embedding_matrix\n",
        "  \n",
        "embedding_matrix =  construct_embedding_matrix(glove_file, word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol5qYhC3fRZg",
        "outputId": "28e2f0ca-03ce-45e2-8069-89b200105215"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6269/6269 [00:00<00:00, 359032.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNXhnuTmpUc8",
        "outputId": "7359cbf1-89f3-4f3a-f551-d7f3249ca207"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6270, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "-tV9vkzHmvT6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class attention(Layer):\n",
        "    \n",
        "    def __init__(self, return_sequences=True):\n",
        "        self.return_sequences = return_sequences\n",
        "        super(attention,self).__init__()\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \n",
        "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
        "                               initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
        "                               initializer=\"zeros\")\n",
        "        \n",
        "        super(attention,self).build(input_shape)\n",
        "        \n",
        "    def call(self, x):\n",
        "        \n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x*a\n",
        "        \n",
        "        if self.return_sequences:\n",
        "            return output\n",
        "        \n",
        "        return K.sum(output, axis=1)"
      ],
      "metadata": {
        "id": "_BRPvdbMunDa"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_out = 512\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_VECTOR_LENGTH,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=50,\n",
        "                            trainable=True)\n",
        "\n",
        "\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(lstm_out,return_sequences=True)))\n",
        "#model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(attention(return_sequences=True))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(11, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJQMvfP-lm5z",
        "outputId": "b58646a0-ef87-4eff-e6be-a124fbd3b0e8"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_26 (Embedding)    (None, 50, 50)            313500    \n",
            "                                                                 \n",
            " bidirectional_29 (Bidirecti  (None, 50, 1024)         2306048   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " attention_5 (attention)     (None, 50, 1024)          1074      \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 51200)             0         \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 51200)             0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 11)                563211    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,183,833\n",
            "Trainable params: 3,183,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]"
      ],
      "metadata": {
        "id": "-loDwqQf9tJN"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, train_label,\n",
        "            epochs=200,\n",
        "            #callbacks=callbacks,\n",
        "            validation_data=(x_val, valid_label),\n",
        "            verbose=2,\n",
        "            batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJKdYTKhpesS",
        "outputId": "852b5853-3172-47ae-db29-93916efaa2c9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "23/23 - 7s - loss: 0.4721 - accuracy: 0.0929 - val_loss: 0.4126 - val_accuracy: 0.0000e+00 - 7s/epoch - 318ms/step\n",
            "Epoch 2/200\n",
            "23/23 - 2s - loss: 0.4167 - accuracy: 0.0000e+00 - val_loss: 0.4105 - val_accuracy: 0.0000e+00 - 2s/epoch - 93ms/step\n",
            "Epoch 3/200\n",
            "23/23 - 2s - loss: 0.4221 - accuracy: 0.0000e+00 - val_loss: 0.4127 - val_accuracy: 0.0000e+00 - 2s/epoch - 93ms/step\n",
            "Epoch 4/200\n",
            "23/23 - 2s - loss: 0.4151 - accuracy: 0.0000e+00 - val_loss: 0.4092 - val_accuracy: 0.0000e+00 - 2s/epoch - 93ms/step\n",
            "Epoch 5/200\n",
            "23/23 - 2s - loss: 0.4139 - accuracy: 3.5461e-04 - val_loss: 0.4103 - val_accuracy: 0.0000e+00 - 2s/epoch - 93ms/step\n",
            "Epoch 6/200\n",
            "23/23 - 2s - loss: 0.4116 - accuracy: 3.5461e-04 - val_loss: 0.4051 - val_accuracy: 0.0000e+00 - 2s/epoch - 93ms/step\n",
            "Epoch 7/200\n",
            "23/23 - 2s - loss: 0.4046 - accuracy: 3.5461e-04 - val_loss: 0.4021 - val_accuracy: 0.0000e+00 - 2s/epoch - 93ms/step\n",
            "Epoch 8/200\n",
            "23/23 - 2s - loss: 0.3995 - accuracy: 3.5461e-04 - val_loss: 0.4007 - val_accuracy: 0.0000e+00 - 2s/epoch - 93ms/step\n",
            "Epoch 9/200\n",
            "23/23 - 2s - loss: 0.3912 - accuracy: 7.0922e-04 - val_loss: 0.3976 - val_accuracy: 0.0032 - 2s/epoch - 93ms/step\n",
            "Epoch 10/200\n",
            "23/23 - 2s - loss: 0.3781 - accuracy: 0.0074 - val_loss: 0.3906 - val_accuracy: 0.0032 - 2s/epoch - 93ms/step\n",
            "Epoch 11/200\n",
            "23/23 - 2s - loss: 0.3645 - accuracy: 0.0096 - val_loss: 0.3932 - val_accuracy: 0.0764 - 2s/epoch - 96ms/step\n",
            "Epoch 12/200\n",
            "23/23 - 2s - loss: 0.3498 - accuracy: 0.0493 - val_loss: 0.3802 - val_accuracy: 0.0764 - 2s/epoch - 94ms/step\n",
            "Epoch 13/200\n",
            "23/23 - 2s - loss: 0.3325 - accuracy: 0.0954 - val_loss: 0.3886 - val_accuracy: 0.1433 - 2s/epoch - 94ms/step\n",
            "Epoch 14/200\n",
            "23/23 - 2s - loss: 0.3123 - accuracy: 0.1181 - val_loss: 0.3772 - val_accuracy: 0.1146 - 2s/epoch - 94ms/step\n",
            "Epoch 15/200\n",
            "23/23 - 2s - loss: 0.2927 - accuracy: 0.1043 - val_loss: 0.3819 - val_accuracy: 0.1815 - 2s/epoch - 94ms/step\n",
            "Epoch 16/200\n",
            "23/23 - 2s - loss: 0.2842 - accuracy: 0.1418 - val_loss: 0.3901 - val_accuracy: 0.1975 - 2s/epoch - 94ms/step\n",
            "Epoch 17/200\n",
            "23/23 - 2s - loss: 0.2834 - accuracy: 0.1574 - val_loss: 0.3724 - val_accuracy: 0.2357 - 2s/epoch - 94ms/step\n",
            "Epoch 18/200\n",
            "23/23 - 2s - loss: 0.2687 - accuracy: 0.1738 - val_loss: 0.3888 - val_accuracy: 0.1115 - 2s/epoch - 95ms/step\n",
            "Epoch 19/200\n",
            "23/23 - 2s - loss: 0.2540 - accuracy: 0.1787 - val_loss: 0.3874 - val_accuracy: 0.1943 - 2s/epoch - 94ms/step\n",
            "Epoch 20/200\n",
            "23/23 - 2s - loss: 0.2357 - accuracy: 0.1816 - val_loss: 0.3973 - val_accuracy: 0.1879 - 2s/epoch - 95ms/step\n",
            "Epoch 21/200\n",
            "23/23 - 2s - loss: 0.2255 - accuracy: 0.1897 - val_loss: 0.4079 - val_accuracy: 0.2484 - 2s/epoch - 95ms/step\n",
            "Epoch 22/200\n",
            "23/23 - 2s - loss: 0.2087 - accuracy: 0.2230 - val_loss: 0.4157 - val_accuracy: 0.2357 - 2s/epoch - 94ms/step\n",
            "Epoch 23/200\n",
            "23/23 - 2s - loss: 0.2025 - accuracy: 0.2287 - val_loss: 0.4288 - val_accuracy: 0.2197 - 2s/epoch - 95ms/step\n",
            "Epoch 24/200\n",
            "23/23 - 2s - loss: 0.1890 - accuracy: 0.2784 - val_loss: 0.4441 - val_accuracy: 0.2611 - 2s/epoch - 95ms/step\n",
            "Epoch 25/200\n",
            "23/23 - 2s - loss: 0.1859 - accuracy: 0.2791 - val_loss: 0.4395 - val_accuracy: 0.1911 - 2s/epoch - 94ms/step\n",
            "Epoch 26/200\n",
            "23/23 - 2s - loss: 0.1805 - accuracy: 0.2858 - val_loss: 0.4370 - val_accuracy: 0.2739 - 2s/epoch - 94ms/step\n",
            "Epoch 27/200\n",
            "23/23 - 2s - loss: 0.1575 - accuracy: 0.2819 - val_loss: 0.4589 - val_accuracy: 0.2548 - 2s/epoch - 95ms/step\n",
            "Epoch 28/200\n",
            "23/23 - 2s - loss: 0.1424 - accuracy: 0.2855 - val_loss: 0.4641 - val_accuracy: 0.2357 - 2s/epoch - 94ms/step\n",
            "Epoch 29/200\n",
            "23/23 - 2s - loss: 0.1352 - accuracy: 0.2943 - val_loss: 0.4823 - val_accuracy: 0.2548 - 2s/epoch - 95ms/step\n",
            "Epoch 30/200\n",
            "23/23 - 2s - loss: 0.1241 - accuracy: 0.3142 - val_loss: 0.4983 - val_accuracy: 0.2580 - 2s/epoch - 93ms/step\n",
            "Epoch 31/200\n",
            "23/23 - 2s - loss: 0.1261 - accuracy: 0.3152 - val_loss: 0.4900 - val_accuracy: 0.2771 - 2s/epoch - 94ms/step\n",
            "Epoch 32/200\n",
            "23/23 - 2s - loss: 0.1087 - accuracy: 0.3326 - val_loss: 0.5393 - val_accuracy: 0.2548 - 2s/epoch - 94ms/step\n",
            "Epoch 33/200\n",
            "23/23 - 2s - loss: 0.0996 - accuracy: 0.3394 - val_loss: 0.5099 - val_accuracy: 0.2420 - 2s/epoch - 95ms/step\n",
            "Epoch 34/200\n",
            "23/23 - 2s - loss: 0.0930 - accuracy: 0.3372 - val_loss: 0.5777 - val_accuracy: 0.2834 - 2s/epoch - 96ms/step\n",
            "Epoch 35/200\n",
            "23/23 - 2s - loss: 0.0842 - accuracy: 0.3387 - val_loss: 0.5710 - val_accuracy: 0.3121 - 2s/epoch - 95ms/step\n",
            "Epoch 36/200\n",
            "23/23 - 2s - loss: 0.0787 - accuracy: 0.3567 - val_loss: 0.5890 - val_accuracy: 0.2580 - 2s/epoch - 95ms/step\n",
            "Epoch 37/200\n",
            "23/23 - 2s - loss: 0.0719 - accuracy: 0.3319 - val_loss: 0.5927 - val_accuracy: 0.2643 - 2s/epoch - 95ms/step\n",
            "Epoch 38/200\n",
            "23/23 - 2s - loss: 0.0637 - accuracy: 0.3319 - val_loss: 0.6487 - val_accuracy: 0.2675 - 2s/epoch - 95ms/step\n",
            "Epoch 39/200\n",
            "23/23 - 2s - loss: 0.0591 - accuracy: 0.3603 - val_loss: 0.6439 - val_accuracy: 0.2261 - 2s/epoch - 94ms/step\n",
            "Epoch 40/200\n",
            "23/23 - 2s - loss: 0.0566 - accuracy: 0.3450 - val_loss: 0.6705 - val_accuracy: 0.2357 - 2s/epoch - 95ms/step\n",
            "Epoch 41/200\n",
            "23/23 - 2s - loss: 0.0672 - accuracy: 0.3234 - val_loss: 0.6417 - val_accuracy: 0.2516 - 2s/epoch - 94ms/step\n",
            "Epoch 42/200\n",
            "23/23 - 2s - loss: 0.0615 - accuracy: 0.3759 - val_loss: 0.6347 - val_accuracy: 0.2803 - 2s/epoch - 94ms/step\n",
            "Epoch 43/200\n",
            "23/23 - 2s - loss: 0.0625 - accuracy: 0.3706 - val_loss: 0.6264 - val_accuracy: 0.2994 - 2s/epoch - 95ms/step\n",
            "Epoch 44/200\n",
            "23/23 - 2s - loss: 0.0478 - accuracy: 0.3855 - val_loss: 0.6605 - val_accuracy: 0.2898 - 2s/epoch - 95ms/step\n",
            "Epoch 45/200\n",
            "23/23 - 2s - loss: 0.0369 - accuracy: 0.3890 - val_loss: 0.7393 - val_accuracy: 0.2548 - 2s/epoch - 95ms/step\n",
            "Epoch 46/200\n",
            "23/23 - 2s - loss: 0.0340 - accuracy: 0.3777 - val_loss: 0.7264 - val_accuracy: 0.2834 - 2s/epoch - 95ms/step\n",
            "Epoch 47/200\n",
            "23/23 - 2s - loss: 0.0284 - accuracy: 0.3901 - val_loss: 0.7510 - val_accuracy: 0.2898 - 2s/epoch - 94ms/step\n",
            "Epoch 48/200\n",
            "23/23 - 2s - loss: 0.0261 - accuracy: 0.3957 - val_loss: 0.7641 - val_accuracy: 0.2834 - 2s/epoch - 95ms/step\n",
            "Epoch 49/200\n",
            "23/23 - 2s - loss: 0.0367 - accuracy: 0.4050 - val_loss: 0.7189 - val_accuracy: 0.3344 - 2s/epoch - 94ms/step\n",
            "Epoch 50/200\n",
            "23/23 - 2s - loss: 0.0350 - accuracy: 0.4259 - val_loss: 0.7602 - val_accuracy: 0.2962 - 2s/epoch - 95ms/step\n",
            "Epoch 51/200\n",
            "23/23 - 2s - loss: 0.0518 - accuracy: 0.4255 - val_loss: 0.7100 - val_accuracy: 0.2930 - 2s/epoch - 95ms/step\n",
            "Epoch 52/200\n",
            "23/23 - 2s - loss: 0.0329 - accuracy: 0.4039 - val_loss: 0.7544 - val_accuracy: 0.2707 - 2s/epoch - 94ms/step\n",
            "Epoch 53/200\n",
            "23/23 - 2s - loss: 0.0247 - accuracy: 0.3787 - val_loss: 0.7473 - val_accuracy: 0.3089 - 2s/epoch - 95ms/step\n",
            "Epoch 54/200\n",
            "23/23 - 2s - loss: 0.0184 - accuracy: 0.4035 - val_loss: 0.8055 - val_accuracy: 0.2516 - 2s/epoch - 95ms/step\n",
            "Epoch 55/200\n",
            "23/23 - 2s - loss: 0.0299 - accuracy: 0.3933 - val_loss: 0.7845 - val_accuracy: 0.3217 - 2s/epoch - 95ms/step\n",
            "Epoch 56/200\n",
            "23/23 - 2s - loss: 0.0290 - accuracy: 0.4493 - val_loss: 0.7947 - val_accuracy: 0.2707 - 2s/epoch - 96ms/step\n",
            "Epoch 57/200\n",
            "23/23 - 2s - loss: 0.0186 - accuracy: 0.4262 - val_loss: 0.7921 - val_accuracy: 0.2898 - 2s/epoch - 94ms/step\n",
            "Epoch 58/200\n",
            "23/23 - 2s - loss: 0.0154 - accuracy: 0.4156 - val_loss: 0.8280 - val_accuracy: 0.2803 - 2s/epoch - 97ms/step\n",
            "Epoch 59/200\n",
            "23/23 - 2s - loss: 0.0113 - accuracy: 0.4089 - val_loss: 0.8621 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 60/200\n",
            "23/23 - 2s - loss: 0.0108 - accuracy: 0.4227 - val_loss: 0.9106 - val_accuracy: 0.2452 - 2s/epoch - 94ms/step\n",
            "Epoch 61/200\n",
            "23/23 - 2s - loss: 0.0115 - accuracy: 0.3929 - val_loss: 0.8425 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 62/200\n",
            "23/23 - 2s - loss: 0.0110 - accuracy: 0.4422 - val_loss: 0.8762 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 63/200\n",
            "23/23 - 2s - loss: 0.0112 - accuracy: 0.4259 - val_loss: 0.8695 - val_accuracy: 0.2834 - 2s/epoch - 95ms/step\n",
            "Epoch 64/200\n",
            "23/23 - 2s - loss: 0.0113 - accuracy: 0.4245 - val_loss: 0.9035 - val_accuracy: 0.2866 - 2s/epoch - 93ms/step\n",
            "Epoch 65/200\n",
            "23/23 - 2s - loss: 0.0082 - accuracy: 0.4149 - val_loss: 0.9865 - val_accuracy: 0.2197 - 2s/epoch - 95ms/step\n",
            "Epoch 66/200\n",
            "23/23 - 2s - loss: 0.0490 - accuracy: 0.4883 - val_loss: 0.7944 - val_accuracy: 0.2611 - 2s/epoch - 97ms/step\n",
            "Epoch 67/200\n",
            "23/23 - 2s - loss: 0.0267 - accuracy: 0.4532 - val_loss: 0.7864 - val_accuracy: 0.3408 - 2s/epoch - 94ms/step\n",
            "Epoch 68/200\n",
            "23/23 - 2s - loss: 0.0167 - accuracy: 0.4262 - val_loss: 0.9134 - val_accuracy: 0.3025 - 2s/epoch - 94ms/step\n",
            "Epoch 69/200\n",
            "23/23 - 2s - loss: 0.0139 - accuracy: 0.4270 - val_loss: 0.8781 - val_accuracy: 0.3089 - 2s/epoch - 94ms/step\n",
            "Epoch 70/200\n",
            "23/23 - 2s - loss: 0.0099 - accuracy: 0.4216 - val_loss: 0.9487 - val_accuracy: 0.3121 - 2s/epoch - 94ms/step\n",
            "Epoch 71/200\n",
            "23/23 - 2s - loss: 0.0069 - accuracy: 0.4291 - val_loss: 0.9597 - val_accuracy: 0.3153 - 2s/epoch - 95ms/step\n",
            "Epoch 72/200\n",
            "23/23 - 2s - loss: 0.0053 - accuracy: 0.4273 - val_loss: 0.9883 - val_accuracy: 0.3025 - 2s/epoch - 94ms/step\n",
            "Epoch 73/200\n",
            "23/23 - 2s - loss: 0.0044 - accuracy: 0.4195 - val_loss: 1.0162 - val_accuracy: 0.3217 - 2s/epoch - 93ms/step\n",
            "Epoch 74/200\n",
            "23/23 - 2s - loss: 0.0041 - accuracy: 0.4089 - val_loss: 1.0349 - val_accuracy: 0.3089 - 2s/epoch - 94ms/step\n",
            "Epoch 75/200\n",
            "23/23 - 2s - loss: 0.0042 - accuracy: 0.4238 - val_loss: 1.0435 - val_accuracy: 0.3185 - 2s/epoch - 94ms/step\n",
            "Epoch 76/200\n",
            "23/23 - 2s - loss: 0.0029 - accuracy: 0.4195 - val_loss: 1.0663 - val_accuracy: 0.3344 - 2s/epoch - 93ms/step\n",
            "Epoch 77/200\n",
            "23/23 - 2s - loss: 0.0024 - accuracy: 0.4209 - val_loss: 1.0851 - val_accuracy: 0.3185 - 2s/epoch - 96ms/step\n",
            "Epoch 78/200\n",
            "23/23 - 2s - loss: 0.0020 - accuracy: 0.4074 - val_loss: 1.1005 - val_accuracy: 0.3185 - 2s/epoch - 94ms/step\n",
            "Epoch 79/200\n",
            "23/23 - 2s - loss: 0.0019 - accuracy: 0.4106 - val_loss: 1.1126 - val_accuracy: 0.3153 - 2s/epoch - 94ms/step\n",
            "Epoch 80/200\n",
            "23/23 - 2s - loss: 0.0017 - accuracy: 0.3996 - val_loss: 1.1283 - val_accuracy: 0.3057 - 2s/epoch - 93ms/step\n",
            "Epoch 81/200\n",
            "23/23 - 2s - loss: 0.0015 - accuracy: 0.4089 - val_loss: 1.1377 - val_accuracy: 0.3025 - 2s/epoch - 94ms/step\n",
            "Epoch 82/200\n",
            "23/23 - 2s - loss: 0.0013 - accuracy: 0.3986 - val_loss: 1.1521 - val_accuracy: 0.2962 - 2s/epoch - 94ms/step\n",
            "Epoch 83/200\n",
            "23/23 - 2s - loss: 0.0028 - accuracy: 0.4170 - val_loss: 1.1552 - val_accuracy: 0.3089 - 2s/epoch - 95ms/step\n",
            "Epoch 84/200\n",
            "23/23 - 2s - loss: 0.0021 - accuracy: 0.4248 - val_loss: 1.1503 - val_accuracy: 0.3025 - 2s/epoch - 94ms/step\n",
            "Epoch 85/200\n",
            "23/23 - 2s - loss: 0.0016 - accuracy: 0.3848 - val_loss: 1.1615 - val_accuracy: 0.3025 - 2s/epoch - 95ms/step\n",
            "Epoch 86/200\n",
            "23/23 - 2s - loss: 0.0014 - accuracy: 0.4004 - val_loss: 1.1604 - val_accuracy: 0.3089 - 2s/epoch - 95ms/step\n",
            "Epoch 87/200\n",
            "23/23 - 2s - loss: 0.0011 - accuracy: 0.3954 - val_loss: 1.1671 - val_accuracy: 0.2962 - 2s/epoch - 96ms/step\n",
            "Epoch 88/200\n",
            "23/23 - 2s - loss: 0.0011 - accuracy: 0.4021 - val_loss: 1.1835 - val_accuracy: 0.3089 - 2s/epoch - 95ms/step\n",
            "Epoch 89/200\n",
            "23/23 - 2s - loss: 9.3026e-04 - accuracy: 0.4035 - val_loss: 1.1943 - val_accuracy: 0.2994 - 2s/epoch - 94ms/step\n",
            "Epoch 90/200\n",
            "23/23 - 2s - loss: 8.6070e-04 - accuracy: 0.3887 - val_loss: 1.2088 - val_accuracy: 0.2994 - 2s/epoch - 93ms/step\n",
            "Epoch 91/200\n",
            "23/23 - 2s - loss: 7.7340e-04 - accuracy: 0.3929 - val_loss: 1.2134 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 92/200\n",
            "23/23 - 2s - loss: 7.2725e-04 - accuracy: 0.3890 - val_loss: 1.2235 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 93/200\n",
            "23/23 - 2s - loss: 6.6885e-04 - accuracy: 0.3844 - val_loss: 1.2316 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 94/200\n",
            "23/23 - 2s - loss: 6.3036e-04 - accuracy: 0.3858 - val_loss: 1.2383 - val_accuracy: 0.3025 - 2s/epoch - 94ms/step\n",
            "Epoch 95/200\n",
            "23/23 - 2s - loss: 6.0640e-04 - accuracy: 0.3865 - val_loss: 1.2461 - val_accuracy: 0.3057 - 2s/epoch - 95ms/step\n",
            "Epoch 96/200\n",
            "23/23 - 2s - loss: 5.6669e-04 - accuracy: 0.3869 - val_loss: 1.2534 - val_accuracy: 0.2962 - 2s/epoch - 96ms/step\n",
            "Epoch 97/200\n",
            "23/23 - 2s - loss: 5.6846e-04 - accuracy: 0.3887 - val_loss: 1.2564 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 98/200\n",
            "23/23 - 2s - loss: 5.3467e-04 - accuracy: 0.3872 - val_loss: 1.2666 - val_accuracy: 0.2994 - 2s/epoch - 95ms/step\n",
            "Epoch 99/200\n",
            "23/23 - 2s - loss: 5.1824e-04 - accuracy: 0.3876 - val_loss: 1.2684 - val_accuracy: 0.3025 - 2s/epoch - 94ms/step\n",
            "Epoch 100/200\n",
            "23/23 - 2s - loss: 4.7728e-04 - accuracy: 0.3872 - val_loss: 1.2754 - val_accuracy: 0.3025 - 2s/epoch - 94ms/step\n",
            "Epoch 101/200\n",
            "23/23 - 2s - loss: 4.4819e-04 - accuracy: 0.3897 - val_loss: 1.2837 - val_accuracy: 0.2994 - 2s/epoch - 94ms/step\n",
            "Epoch 102/200\n",
            "23/23 - 2s - loss: 4.4333e-04 - accuracy: 0.3840 - val_loss: 1.2878 - val_accuracy: 0.3025 - 2s/epoch - 94ms/step\n",
            "Epoch 103/200\n",
            "23/23 - 2s - loss: 4.0379e-04 - accuracy: 0.3840 - val_loss: 1.2948 - val_accuracy: 0.2962 - 2s/epoch - 94ms/step\n",
            "Epoch 104/200\n",
            "23/23 - 2s - loss: 3.9429e-04 - accuracy: 0.3826 - val_loss: 1.2993 - val_accuracy: 0.2994 - 2s/epoch - 94ms/step\n",
            "Epoch 105/200\n",
            "23/23 - 2s - loss: 3.8766e-04 - accuracy: 0.3819 - val_loss: 1.3016 - val_accuracy: 0.2962 - 2s/epoch - 94ms/step\n",
            "Epoch 106/200\n",
            "23/23 - 2s - loss: 3.6978e-04 - accuracy: 0.3816 - val_loss: 1.3076 - val_accuracy: 0.2994 - 2s/epoch - 94ms/step\n",
            "Epoch 107/200\n",
            "23/23 - 2s - loss: 3.4887e-04 - accuracy: 0.3833 - val_loss: 1.3145 - val_accuracy: 0.2962 - 2s/epoch - 97ms/step\n",
            "Epoch 108/200\n",
            "23/23 - 2s - loss: 3.4549e-04 - accuracy: 0.3883 - val_loss: 1.3221 - val_accuracy: 0.2994 - 2s/epoch - 94ms/step\n",
            "Epoch 109/200\n",
            "23/23 - 2s - loss: 3.3043e-04 - accuracy: 0.3869 - val_loss: 1.3243 - val_accuracy: 0.2994 - 2s/epoch - 94ms/step\n",
            "Epoch 110/200\n",
            "23/23 - 2s - loss: 3.1413e-04 - accuracy: 0.3784 - val_loss: 1.3283 - val_accuracy: 0.2962 - 2s/epoch - 95ms/step\n",
            "Epoch 111/200\n",
            "23/23 - 2s - loss: 3.0857e-04 - accuracy: 0.3872 - val_loss: 1.3330 - val_accuracy: 0.2962 - 2s/epoch - 95ms/step\n",
            "Epoch 112/200\n",
            "23/23 - 2s - loss: 2.9585e-04 - accuracy: 0.3826 - val_loss: 1.3364 - val_accuracy: 0.2962 - 2s/epoch - 94ms/step\n",
            "Epoch 113/200\n",
            "23/23 - 2s - loss: 2.9246e-04 - accuracy: 0.3890 - val_loss: 1.3399 - val_accuracy: 0.3025 - 2s/epoch - 95ms/step\n",
            "Epoch 114/200\n",
            "23/23 - 2s - loss: 2.7480e-04 - accuracy: 0.3837 - val_loss: 1.3456 - val_accuracy: 0.2994 - 2s/epoch - 94ms/step\n",
            "Epoch 115/200\n",
            "23/23 - 2s - loss: 2.6758e-04 - accuracy: 0.3851 - val_loss: 1.3506 - val_accuracy: 0.2994 - 2s/epoch - 94ms/step\n",
            "Epoch 116/200\n",
            "23/23 - 2s - loss: 2.7087e-04 - accuracy: 0.3879 - val_loss: 1.3568 - val_accuracy: 0.2898 - 2s/epoch - 95ms/step\n",
            "Epoch 117/200\n",
            "23/23 - 2s - loss: 2.5426e-04 - accuracy: 0.3830 - val_loss: 1.3610 - val_accuracy: 0.2930 - 2s/epoch - 94ms/step\n",
            "Epoch 118/200\n",
            "23/23 - 2s - loss: 2.4178e-04 - accuracy: 0.3918 - val_loss: 1.3647 - val_accuracy: 0.2994 - 2s/epoch - 95ms/step\n",
            "Epoch 119/200\n",
            "23/23 - 2s - loss: 2.4547e-04 - accuracy: 0.3830 - val_loss: 1.3669 - val_accuracy: 0.2930 - 2s/epoch - 94ms/step\n",
            "Epoch 120/200\n",
            "23/23 - 2s - loss: 2.3245e-04 - accuracy: 0.3812 - val_loss: 1.3694 - val_accuracy: 0.2866 - 2s/epoch - 94ms/step\n",
            "Epoch 121/200\n",
            "23/23 - 2s - loss: 2.2403e-04 - accuracy: 0.3833 - val_loss: 1.3784 - val_accuracy: 0.2930 - 2s/epoch - 95ms/step\n",
            "Epoch 122/200\n",
            "23/23 - 2s - loss: 2.1592e-04 - accuracy: 0.3947 - val_loss: 1.3812 - val_accuracy: 0.2962 - 2s/epoch - 95ms/step\n",
            "Epoch 123/200\n",
            "23/23 - 2s - loss: 2.4638e-04 - accuracy: 0.3805 - val_loss: 1.3830 - val_accuracy: 0.2898 - 2s/epoch - 95ms/step\n",
            "Epoch 124/200\n",
            "23/23 - 2s - loss: 4.7448e-04 - accuracy: 0.3745 - val_loss: 1.3427 - val_accuracy: 0.2834 - 2s/epoch - 94ms/step\n",
            "Epoch 125/200\n",
            "23/23 - 2s - loss: 0.0023 - accuracy: 0.3777 - val_loss: 1.3204 - val_accuracy: 0.2739 - 2s/epoch - 95ms/step\n",
            "Epoch 126/200\n",
            "23/23 - 2s - loss: 0.0100 - accuracy: 0.4131 - val_loss: 1.0643 - val_accuracy: 0.3153 - 2s/epoch - 94ms/step\n",
            "Epoch 127/200\n",
            "23/23 - 2s - loss: 0.0391 - accuracy: 0.4106 - val_loss: 0.8346 - val_accuracy: 0.2898 - 2s/epoch - 95ms/step\n",
            "Epoch 128/200\n",
            "23/23 - 2s - loss: 0.0293 - accuracy: 0.4486 - val_loss: 0.8620 - val_accuracy: 0.3185 - 2s/epoch - 94ms/step\n",
            "Epoch 129/200\n",
            "23/23 - 2s - loss: 0.0272 - accuracy: 0.3830 - val_loss: 0.8629 - val_accuracy: 0.2707 - 2s/epoch - 95ms/step\n",
            "Epoch 130/200\n",
            "23/23 - 2s - loss: 0.0207 - accuracy: 0.3947 - val_loss: 0.8935 - val_accuracy: 0.2834 - 2s/epoch - 95ms/step\n",
            "Epoch 131/200\n",
            "23/23 - 2s - loss: 0.0124 - accuracy: 0.4365 - val_loss: 0.9563 - val_accuracy: 0.3408 - 2s/epoch - 94ms/step\n",
            "Epoch 132/200\n",
            "23/23 - 2s - loss: 0.0063 - accuracy: 0.4270 - val_loss: 1.0004 - val_accuracy: 0.3121 - 2s/epoch - 94ms/step\n",
            "Epoch 133/200\n",
            "23/23 - 2s - loss: 0.0034 - accuracy: 0.4230 - val_loss: 0.9971 - val_accuracy: 0.3312 - 2s/epoch - 94ms/step\n",
            "Epoch 134/200\n",
            "23/23 - 2s - loss: 0.0033 - accuracy: 0.4660 - val_loss: 1.0561 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 135/200\n",
            "23/23 - 2s - loss: 0.0021 - accuracy: 0.4340 - val_loss: 1.0800 - val_accuracy: 0.2898 - 2s/epoch - 95ms/step\n",
            "Epoch 136/200\n",
            "23/23 - 2s - loss: 0.0014 - accuracy: 0.4202 - val_loss: 1.1239 - val_accuracy: 0.3153 - 2s/epoch - 94ms/step\n",
            "Epoch 137/200\n",
            "23/23 - 2s - loss: 0.0010 - accuracy: 0.4323 - val_loss: 1.1488 - val_accuracy: 0.3217 - 2s/epoch - 95ms/step\n",
            "Epoch 138/200\n",
            "23/23 - 2s - loss: 0.0018 - accuracy: 0.4340 - val_loss: 1.1463 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 139/200\n",
            "23/23 - 2s - loss: 0.0011 - accuracy: 0.4195 - val_loss: 1.1739 - val_accuracy: 0.3121 - 2s/epoch - 95ms/step\n",
            "Epoch 140/200\n",
            "23/23 - 2s - loss: 7.4832e-04 - accuracy: 0.4128 - val_loss: 1.1956 - val_accuracy: 0.3185 - 2s/epoch - 94ms/step\n",
            "Epoch 141/200\n",
            "23/23 - 2s - loss: 6.2334e-04 - accuracy: 0.4096 - val_loss: 1.2046 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 142/200\n",
            "23/23 - 2s - loss: 5.5093e-04 - accuracy: 0.4025 - val_loss: 1.2201 - val_accuracy: 0.3057 - 2s/epoch - 94ms/step\n",
            "Epoch 143/200\n",
            "23/23 - 2s - loss: 4.9070e-04 - accuracy: 0.3986 - val_loss: 1.2308 - val_accuracy: 0.3121 - 2s/epoch - 97ms/step\n",
            "Epoch 144/200\n",
            "23/23 - 2s - loss: 4.4426e-04 - accuracy: 0.4050 - val_loss: 1.2342 - val_accuracy: 0.3121 - 2s/epoch - 94ms/step\n",
            "Epoch 145/200\n",
            "23/23 - 2s - loss: 4.2195e-04 - accuracy: 0.4099 - val_loss: 1.2477 - val_accuracy: 0.3057 - 2s/epoch - 96ms/step\n",
            "Epoch 146/200\n",
            "23/23 - 2s - loss: 3.7761e-04 - accuracy: 0.4117 - val_loss: 1.2580 - val_accuracy: 0.3185 - 2s/epoch - 94ms/step\n",
            "Epoch 147/200\n",
            "23/23 - 2s - loss: 3.5482e-04 - accuracy: 0.4078 - val_loss: 1.2695 - val_accuracy: 0.3185 - 2s/epoch - 97ms/step\n",
            "Epoch 148/200\n",
            "23/23 - 2s - loss: 3.3779e-04 - accuracy: 0.4096 - val_loss: 1.2736 - val_accuracy: 0.3121 - 2s/epoch - 94ms/step\n",
            "Epoch 149/200\n",
            "23/23 - 2s - loss: 3.1914e-04 - accuracy: 0.4202 - val_loss: 1.2854 - val_accuracy: 0.3185 - 2s/epoch - 95ms/step\n",
            "Epoch 150/200\n",
            "23/23 - 2s - loss: 3.0219e-04 - accuracy: 0.4135 - val_loss: 1.2912 - val_accuracy: 0.3217 - 2s/epoch - 94ms/step\n",
            "Epoch 151/200\n",
            "23/23 - 2s - loss: 2.8870e-04 - accuracy: 0.4106 - val_loss: 1.3006 - val_accuracy: 0.3248 - 2s/epoch - 94ms/step\n",
            "Epoch 152/200\n",
            "23/23 - 2s - loss: 2.7085e-04 - accuracy: 0.4060 - val_loss: 1.3068 - val_accuracy: 0.3248 - 2s/epoch - 94ms/step\n",
            "Epoch 153/200\n",
            "23/23 - 2s - loss: 2.5850e-04 - accuracy: 0.4092 - val_loss: 1.3176 - val_accuracy: 0.3312 - 2s/epoch - 94ms/step\n",
            "Epoch 154/200\n",
            "23/23 - 2s - loss: 2.4928e-04 - accuracy: 0.4064 - val_loss: 1.3250 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 155/200\n",
            "23/23 - 2s - loss: 2.3347e-04 - accuracy: 0.4099 - val_loss: 1.3329 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n",
            "Epoch 156/200\n",
            "23/23 - 2s - loss: 2.2690e-04 - accuracy: 0.4167 - val_loss: 1.3351 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n",
            "Epoch 157/200\n",
            "23/23 - 2s - loss: 2.1509e-04 - accuracy: 0.4089 - val_loss: 1.3400 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n",
            "Epoch 158/200\n",
            "23/23 - 2s - loss: 2.0874e-04 - accuracy: 0.4043 - val_loss: 1.3434 - val_accuracy: 0.3344 - 2s/epoch - 94ms/step\n",
            "Epoch 159/200\n",
            "23/23 - 2s - loss: 2.0101e-04 - accuracy: 0.4011 - val_loss: 1.3516 - val_accuracy: 0.3248 - 2s/epoch - 94ms/step\n",
            "Epoch 160/200\n",
            "23/23 - 2s - loss: 1.9717e-04 - accuracy: 0.4011 - val_loss: 1.3576 - val_accuracy: 0.3248 - 2s/epoch - 94ms/step\n",
            "Epoch 161/200\n",
            "23/23 - 2s - loss: 1.9152e-04 - accuracy: 0.4032 - val_loss: 1.3610 - val_accuracy: 0.3248 - 2s/epoch - 94ms/step\n",
            "Epoch 162/200\n",
            "23/23 - 2s - loss: 1.8079e-04 - accuracy: 0.4043 - val_loss: 1.3666 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n",
            "Epoch 163/200\n",
            "23/23 - 2s - loss: 1.7229e-04 - accuracy: 0.4110 - val_loss: 1.3716 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n",
            "Epoch 164/200\n",
            "23/23 - 2s - loss: 1.6543e-04 - accuracy: 0.4039 - val_loss: 1.3808 - val_accuracy: 0.3280 - 2s/epoch - 95ms/step\n",
            "Epoch 165/200\n",
            "23/23 - 2s - loss: 1.6128e-04 - accuracy: 0.3986 - val_loss: 1.3828 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n",
            "Epoch 166/200\n",
            "23/23 - 2s - loss: 1.5525e-04 - accuracy: 0.4089 - val_loss: 1.3907 - val_accuracy: 0.3312 - 2s/epoch - 95ms/step\n",
            "Epoch 167/200\n",
            "23/23 - 2s - loss: 1.5964e-04 - accuracy: 0.3972 - val_loss: 1.3926 - val_accuracy: 0.3312 - 2s/epoch - 94ms/step\n",
            "Epoch 168/200\n",
            "23/23 - 2s - loss: 1.5465e-04 - accuracy: 0.4028 - val_loss: 1.3945 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 169/200\n",
            "23/23 - 2s - loss: 1.4124e-04 - accuracy: 0.4053 - val_loss: 1.4011 - val_accuracy: 0.3344 - 2s/epoch - 94ms/step\n",
            "Epoch 170/200\n",
            "23/23 - 2s - loss: 1.3939e-04 - accuracy: 0.4053 - val_loss: 1.4067 - val_accuracy: 0.3280 - 2s/epoch - 95ms/step\n",
            "Epoch 171/200\n",
            "23/23 - 2s - loss: 1.3200e-04 - accuracy: 0.4025 - val_loss: 1.4107 - val_accuracy: 0.3312 - 2s/epoch - 94ms/step\n",
            "Epoch 172/200\n",
            "23/23 - 2s - loss: 1.2826e-04 - accuracy: 0.4085 - val_loss: 1.4154 - val_accuracy: 0.3312 - 2s/epoch - 94ms/step\n",
            "Epoch 173/200\n",
            "23/23 - 2s - loss: 1.2731e-04 - accuracy: 0.4085 - val_loss: 1.4184 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 174/200\n",
            "23/23 - 2s - loss: 1.1955e-04 - accuracy: 0.4078 - val_loss: 1.4225 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 175/200\n",
            "23/23 - 2s - loss: 1.1942e-04 - accuracy: 0.4011 - val_loss: 1.4276 - val_accuracy: 0.3312 - 2s/epoch - 96ms/step\n",
            "Epoch 176/200\n",
            "23/23 - 2s - loss: 1.1366e-04 - accuracy: 0.4053 - val_loss: 1.4298 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 177/200\n",
            "23/23 - 2s - loss: 1.1146e-04 - accuracy: 0.4011 - val_loss: 1.4341 - val_accuracy: 0.3344 - 2s/epoch - 94ms/step\n",
            "Epoch 178/200\n",
            "23/23 - 2s - loss: 1.0903e-04 - accuracy: 0.4032 - val_loss: 1.4364 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 179/200\n",
            "23/23 - 2s - loss: 1.1938e-04 - accuracy: 0.3879 - val_loss: 1.4316 - val_accuracy: 0.3153 - 2s/epoch - 94ms/step\n",
            "Epoch 180/200\n",
            "23/23 - 2s - loss: 1.1058e-04 - accuracy: 0.3918 - val_loss: 1.4412 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n",
            "Epoch 181/200\n",
            "23/23 - 2s - loss: 1.0576e-04 - accuracy: 0.3972 - val_loss: 1.4474 - val_accuracy: 0.3312 - 2s/epoch - 94ms/step\n",
            "Epoch 182/200\n",
            "23/23 - 2s - loss: 9.8751e-05 - accuracy: 0.3901 - val_loss: 1.4521 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n",
            "Epoch 183/200\n",
            "23/23 - 2s - loss: 9.6470e-05 - accuracy: 0.3940 - val_loss: 1.4551 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 184/200\n",
            "23/23 - 2s - loss: 9.5444e-05 - accuracy: 0.3972 - val_loss: 1.4595 - val_accuracy: 0.3312 - 2s/epoch - 95ms/step\n",
            "Epoch 185/200\n",
            "23/23 - 2s - loss: 8.9882e-05 - accuracy: 0.4004 - val_loss: 1.4644 - val_accuracy: 0.3312 - 2s/epoch - 95ms/step\n",
            "Epoch 186/200\n",
            "23/23 - 2s - loss: 8.8824e-05 - accuracy: 0.4039 - val_loss: 1.4677 - val_accuracy: 0.3312 - 2s/epoch - 95ms/step\n",
            "Epoch 187/200\n",
            "23/23 - 2s - loss: 8.5889e-05 - accuracy: 0.4025 - val_loss: 1.4704 - val_accuracy: 0.3344 - 2s/epoch - 94ms/step\n",
            "Epoch 188/200\n",
            "23/23 - 2s - loss: 8.2415e-05 - accuracy: 0.3950 - val_loss: 1.4753 - val_accuracy: 0.3344 - 2s/epoch - 94ms/step\n",
            "Epoch 189/200\n",
            "23/23 - 2s - loss: 8.0672e-05 - accuracy: 0.3961 - val_loss: 1.4792 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 190/200\n",
            "23/23 - 2s - loss: 7.9463e-05 - accuracy: 0.3926 - val_loss: 1.4826 - val_accuracy: 0.3312 - 2s/epoch - 95ms/step\n",
            "Epoch 191/200\n",
            "23/23 - 2s - loss: 7.8386e-05 - accuracy: 0.3996 - val_loss: 1.4860 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 192/200\n",
            "23/23 - 2s - loss: 7.5685e-05 - accuracy: 0.4011 - val_loss: 1.4886 - val_accuracy: 0.3344 - 2s/epoch - 97ms/step\n",
            "Epoch 193/200\n",
            "23/23 - 2s - loss: 7.5183e-05 - accuracy: 0.3996 - val_loss: 1.4942 - val_accuracy: 0.3312 - 2s/epoch - 94ms/step\n",
            "Epoch 194/200\n",
            "23/23 - 2s - loss: 7.3995e-05 - accuracy: 0.4067 - val_loss: 1.4966 - val_accuracy: 0.3312 - 2s/epoch - 95ms/step\n",
            "Epoch 195/200\n",
            "23/23 - 2s - loss: 7.0994e-05 - accuracy: 0.4043 - val_loss: 1.4992 - val_accuracy: 0.3312 - 2s/epoch - 95ms/step\n",
            "Epoch 196/200\n",
            "23/23 - 2s - loss: 6.9924e-05 - accuracy: 0.3996 - val_loss: 1.5027 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 197/200\n",
            "23/23 - 2s - loss: 6.8723e-05 - accuracy: 0.4060 - val_loss: 1.5052 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 198/200\n",
            "23/23 - 2s - loss: 6.7094e-05 - accuracy: 0.4071 - val_loss: 1.5080 - val_accuracy: 0.3312 - 2s/epoch - 95ms/step\n",
            "Epoch 199/200\n",
            "23/23 - 2s - loss: 6.6128e-05 - accuracy: 0.4117 - val_loss: 1.5108 - val_accuracy: 0.3344 - 2s/epoch - 95ms/step\n",
            "Epoch 200/200\n",
            "23/23 - 2s - loss: 6.4508e-05 - accuracy: 0.4089 - val_loss: 1.5129 - val_accuracy: 0.3280 - 2s/epoch - 94ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82b7161bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    }
  ]
}